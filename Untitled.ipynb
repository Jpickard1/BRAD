{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c464496d-c66b-43fb-a4c0-25a7c031a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import chatbot\n",
    "importlib.reload(chatbot)\n",
    "from chatbot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33aaa5e-3fb3-4829-948b-562e2e11514c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /nfs/turbo/umms-indikar/shared/projects/RAG/models/llama-2-7b-chat.Q2_K.gguf (version GGUF V2)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q2_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:           blk.15.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.15.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:             blk.15.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:             blk.15.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:        blk.15.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:             blk.15.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:             blk.15.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:           blk.16.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.16.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:             blk.16.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:             blk.16.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:        blk.16.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.16.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:             blk.16.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:           blk.17.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.17.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.17.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:             blk.17.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:        blk.17.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.17.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:             blk.17.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:           blk.18.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.18.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.18.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.18.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:        blk.18.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:             blk.18.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.18.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.19.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.19.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:             blk.19.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.19.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:        blk.19.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:             blk.19.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:             blk.19.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.2.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:            blk.2.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:              blk.2.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.2.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:         blk.2.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.2.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:              blk.2.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.20.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.20.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.20.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.20.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.20.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.20.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.20.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.21.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.21.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.21.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.21.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.21.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.21.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.21.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.22.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.22.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.22.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.22.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.22.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.22.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.22.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.23.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.23.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.23.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.23.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.23.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.23.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.23.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:            blk.3.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:            blk.3.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:              blk.3.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:              blk.3.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:         blk.3.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:              blk.3.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:              blk.3.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:            blk.4.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:            blk.4.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:              blk.4.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:              blk.4.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:         blk.4.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:              blk.4.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:              blk.4.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:            blk.5.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:            blk.5.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:              blk.5.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:              blk.5.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:         blk.5.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:              blk.5.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:              blk.5.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:            blk.6.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:            blk.6.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:              blk.6.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:              blk.6.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:         blk.6.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:              blk.6.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:              blk.6.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:            blk.7.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:            blk.7.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:              blk.7.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:              blk.7.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:         blk.7.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:              blk.7.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:              blk.7.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:            blk.8.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:            blk.8.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:              blk.8.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:              blk.8.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:         blk.8.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:              blk.8.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:              blk.8.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:            blk.9.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:            blk.9.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:              blk.9.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:              blk.9.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:         blk.9.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:              blk.9.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:              blk.9.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:           blk.24.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:             blk.24.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:             blk.24.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:        blk.24.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.24.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:           blk.25.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:             blk.25.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:             blk.25.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:        blk.25.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.25.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:           blk.26.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:             blk.26.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:             blk.26.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:        blk.26.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.26.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:           blk.27.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:             blk.27.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:             blk.27.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:        blk.27.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.27.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:           blk.28.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:             blk.28.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:             blk.28.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:        blk.28.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.28.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:           blk.29.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:             blk.29.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:             blk.29.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:        blk.29.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.29.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:           blk.30.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:           blk.30.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:             blk.30.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:        blk.30.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:             blk.30.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.30.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q3_K     [ 11008,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q3_K     [  4096, 11008,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q2_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q3_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 10\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q2_K:   65 tensors\n",
      "llama_model_loader: - type q3_K:  160 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q2_K\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 2.63 GiB (3.35 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: mem required  = 2694.43 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4098\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  = 2049.00 MiB, K (f16): 1024.50 MiB, V (f16): 1024.50 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 7.69 MiB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
      "Sun May 19 13:51:01 2024 INFO Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "/home/jpic/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Sun May 19 13:51:04 2024 INFO Use pytorch device_name: cpu\n",
      "Sun May 19 13:51:04 2024 INFO Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Sun May 19 13:51:04 2024 INFO Collection DB_cosine_cSize_700_cOver_200 is not created.\n"
     ]
    }
   ],
   "source": [
    "model_path = '/nfs/turbo/umms-indikar/shared/projects/RAG/models/llama-2-7b-chat.Q2_K.gguf' # llama-2-7b-chat.Q8_0.gguf'\n",
    "persist_directory = \"/nfs/turbo/umms-indikar/shared/projects/RAG/databases/Transcription-Factors-5-10-2024/\"\n",
    "llm, callback_manager = load_llama(model_path)\n",
    "ragvectordb, embeddings_model = load_literature_db(persist_directory)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "479cf65b-df32-4586-9ab3-6c48b35d3325",
   "metadata": {},
   "source": [
    "load the data in RAG-gget-GO_Molecular_Function_2023-2024-05-1700:39:18.745507.csv\n",
    "save the this current table 1 to a file saved-data-v2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a12070-b5ca-451f-8f3c-5d6bc3184123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to RAG! The chat log from this conversation will be saved to RAG2024-05-19-14:03:09.646730.json. How can I help?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-05-19 14:03:09 INFO semantic_router.utils.logger local\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "I1:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  load the data in RAG-gget-GO_Molecular_Function_2023-2024-05-1700:39:18.745507.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun May 19 14:03:13 2024 INFO DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "O1:\n",
      "loading: RAG-gget-GO_Molecular_Function_2023-2024-05-1700:39:18.745507.csv as Table 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3c0e0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3c0e0_level0_col0\" class=\"col_heading level0 col0\" >Unnamed: 0</th>\n",
       "      <th id=\"T_3c0e0_level0_col1\" class=\"col_heading level0 col1\" >rank</th>\n",
       "      <th id=\"T_3c0e0_level0_col2\" class=\"col_heading level0 col2\" >path_name</th>\n",
       "      <th id=\"T_3c0e0_level0_col3\" class=\"col_heading level0 col3\" >p_val</th>\n",
       "      <th id=\"T_3c0e0_level0_col4\" class=\"col_heading level0 col4\" >z_score</th>\n",
       "      <th id=\"T_3c0e0_level0_col5\" class=\"col_heading level0 col5\" >combined_score</th>\n",
       "      <th id=\"T_3c0e0_level0_col6\" class=\"col_heading level0 col6\" >overlapping_genes</th>\n",
       "      <th id=\"T_3c0e0_level0_col7\" class=\"col_heading level0 col7\" >adj_p_val</th>\n",
       "      <th id=\"T_3c0e0_level0_col8\" class=\"col_heading level0 col8\" >database</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3c0e0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3c0e0_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_3c0e0_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_3c0e0_row0_col2\" class=\"data row0 col2\" >DNA Polymerase Binding (GO:0070182)</td>\n",
       "      <td id=\"T_3c0e0_row0_col3\" class=\"data row0 col3\" >0.000005</td>\n",
       "      <td id=\"T_3c0e0_row0_col4\" class=\"data row0 col4\" >1175.235294</td>\n",
       "      <td id=\"T_3c0e0_row0_col5\" class=\"data row0 col5\" >14316.198633</td>\n",
       "      <td id=\"T_3c0e0_row0_col6\" class=\"data row0 col6\" >['CDT1', 'PCNA']</td>\n",
       "      <td id=\"T_3c0e0_row0_col7\" class=\"data row0 col7\" >0.000133</td>\n",
       "      <td id=\"T_3c0e0_row0_col8\" class=\"data row0 col8\" >GO_Molecular_Function_2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c0e0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3c0e0_row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "      <td id=\"T_3c0e0_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_3c0e0_row1_col2\" class=\"data row1 col2\" >DNA Binding (GO:0003677)</td>\n",
       "      <td id=\"T_3c0e0_row1_col3\" class=\"data row1 col3\" >0.000292</td>\n",
       "      <td id=\"T_3c0e0_row1_col4\" class=\"data row1 col4\" >68.160142</td>\n",
       "      <td id=\"T_3c0e0_row1_col5\" class=\"data row1 col5\" >554.698813</td>\n",
       "      <td id=\"T_3c0e0_row1_col6\" class=\"data row1 col6\" >['CDT1', 'PCNA', 'MYC']</td>\n",
       "      <td id=\"T_3c0e0_row1_col7\" class=\"data row1 col7\" >0.003798</td>\n",
       "      <td id=\"T_3c0e0_row1_col8\" class=\"data row1 col8\" >GO_Molecular_Function_2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c0e0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3c0e0_row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "      <td id=\"T_3c0e0_row2_col1\" class=\"data row2 col1\" >3</td>\n",
       "      <td id=\"T_3c0e0_row2_col2\" class=\"data row2 col2\" >MutLalpha Complex Binding (GO:0032405)</td>\n",
       "      <td id=\"T_3c0e0_row2_col3\" class=\"data row2 col3\" >0.001200</td>\n",
       "      <td id=\"T_3c0e0_row2_col4\" class=\"data row2 col4\" >1332.733333</td>\n",
       "      <td id=\"T_3c0e0_row2_col5\" class=\"data row2 col5\" >8963.738321</td>\n",
       "      <td id=\"T_3c0e0_row2_col6\" class=\"data row2 col6\" >['PCNA']</td>\n",
       "      <td id=\"T_3c0e0_row2_col7\" class=\"data row2 col7\" >0.010396</td>\n",
       "      <td id=\"T_3c0e0_row2_col8\" class=\"data row2 col8\" >GO_Molecular_Function_2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c0e0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3c0e0_row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "      <td id=\"T_3c0e0_row3_col1\" class=\"data row3 col1\" >4</td>\n",
       "      <td id=\"T_3c0e0_row3_col2\" class=\"data row3 col2\" >Histone Acetyltransferase Binding (GO:0035035)</td>\n",
       "      <td id=\"T_3c0e0_row3_col3\" class=\"data row3 col3\" >0.003396</td>\n",
       "      <td id=\"T_3c0e0_row3_col4\" class=\"data row3 col4\" >416.250000</td>\n",
       "      <td id=\"T_3c0e0_row3_col5\" class=\"data row3 col5\" >2366.462633</td>\n",
       "      <td id=\"T_3c0e0_row3_col6\" class=\"data row3 col6\" >['PCNA']</td>\n",
       "      <td id=\"T_3c0e0_row3_col7\" class=\"data row3 col7\" >0.022073</td>\n",
       "      <td id=\"T_3c0e0_row3_col8\" class=\"data row3 col8\" >GO_Molecular_Function_2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c0e0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3c0e0_row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "      <td id=\"T_3c0e0_row4_col1\" class=\"data row4 col1\" >5</td>\n",
       "      <td id=\"T_3c0e0_row4_col2\" class=\"data row4 col2\" >Core Promoter Sequence-Specific DNA Binding (GO:0001046)</td>\n",
       "      <td id=\"T_3c0e0_row4_col3\" class=\"data row4 col3\" >0.006982</td>\n",
       "      <td id=\"T_3c0e0_row4_col4\" class=\"data row4 col4\" >195.705882</td>\n",
       "      <td id=\"T_3c0e0_row4_col5\" class=\"data row4 col5\" >971.563766</td>\n",
       "      <td id=\"T_3c0e0_row4_col6\" class=\"data row4 col6\" >['MYC']</td>\n",
       "      <td id=\"T_3c0e0_row4_col7\" class=\"data row4 col7\" >0.031980</td>\n",
       "      <td id=\"T_3c0e0_row4_col8\" class=\"data row4 col8\" >GO_Molecular_Function_2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c0e0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3c0e0_row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "      <td id=\"T_3c0e0_row5_col1\" class=\"data row5 col1\" >6</td>\n",
       "      <td id=\"T_3c0e0_row5_col2\" class=\"data row5 col2\" >Calcium Channel Regulator Activity (GO:0005246)</td>\n",
       "      <td id=\"T_3c0e0_row5_col3\" class=\"data row5 col3\" >0.007380</td>\n",
       "      <td id=\"T_3c0e0_row5_col4\" class=\"data row5 col4\" >184.814815</td>\n",
       "      <td id=\"T_3c0e0_row5_col5\" class=\"data row5 col5\" >907.253622</td>\n",
       "      <td id=\"T_3c0e0_row5_col6\" class=\"data row5 col6\" >['GEM']</td>\n",
       "      <td id=\"T_3c0e0_row5_col7\" class=\"data row5 col7\" >0.031980</td>\n",
       "      <td id=\"T_3c0e0_row5_col8\" class=\"data row5 col8\" >GO_Molecular_Function_2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3c0e0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3c0e0_row6_col0\" class=\"data row6 col0\" >6</td>\n",
       "      <td id=\"T_3c0e0_row6_col1\" class=\"data row6 col1\" >7</td>\n",
       "      <td id=\"T_3c0e0_row6_col2\" class=\"data row6 col2\" >Damaged DNA Binding (GO:0003684)</td>\n",
       "      <td id=\"T_3c0e0_row6_col3\" class=\"data row6 col3\" >0.008970</td>\n",
       "      <td id=\"T_3c0e0_row6_col4\" class=\"data row6 col4\" >151.151515</td>\n",
       "      <td id=\"T_3c0e0_row6_col5\" class=\"data row6 col5\" >712.504410</td>\n",
       "      <td id=\"T_3c0e0_row6_col6\" class=\"data row6 col6\" >['PCNA']</td>\n",
       "      <td id=\"T_3c0e0_row6_col7\" class=\"data row6 col7\" >0.033026</td>\n",
       "      <td id=\"T_3c0e0_row6_col8\" class=\"data row6 col8\" >GO_Molecular_Function_2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15367c203880>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun May 19 14:03:13 2024 INFO Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "/home/jpic/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Sun May 19 14:03:14 2024 INFO Use pytorch device_name: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "I2:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  save the this current table 1 to a file saved-data-v2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun May 19 14:03:22 2024 INFO DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "O2:\n",
      "saving the table to saved-data-v2.csv\n",
      "==================================================\n",
      "I3:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  save the this current table 1 to a file saved-data-v5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun May 19 14:03:27 2024 INFO DATA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "O3:\n",
      "saving the table to saved-data-v5.csv\n",
      "==================================================\n",
      "I4:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "O4:\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import chatbot\n",
    "import tables\n",
    "importlib.reload(chatbot)\n",
    "importlib.reload(tables)\n",
    "from chatbot import *\n",
    "from tables import *\n",
    "\n",
    "main(llm=llm, ragvectordb=ragvectordb, embeddings_model=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86900737-c1c0-420d-906e-008e78fb1ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching the following on arxiv: dynamical systems\n",
      "fetching up to  1000 records...\n",
      "fetching is completed in 6.2 seconds.\n",
      "Total number of records 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>variational design of sensory feedback for powerstroke-recovery systems</td>\n",
       "      <td>[zhuojun yu, peter j. thomas]</td>\n",
       "      <td>although the raison d'etre of the brain is the survival of the body, there are relatively few theoretical studies of closed-loop rhythmic motor control systems. in this paper we provide a unified framework, based on variational analysis, for investigating the dual goals of performance and robustness in powerstroke-recovery systems. we augment two previously published closed-loop motor control models by equipping each model with a performance measure based on the rate of progress of the system relative to a spatially extended external substrate -- such as progress relative to the ground for a locomotor task. the sensitivity measure quantifies the ability of the system to maintain performance in response to external perturbations. motivated by a search for optimal design principles for feedback control achieving the complementary requirements of efficiency and robustness, we discuss the performance-sensitivity patterns of the systems featuring different sensory feedback architectures. in a paradigmatic half-center oscillator (hco)-motor system, we observe that the excitation-inhibition property of feedback mechanisms determines the sensitivity pattern while the activation-inactivation property determines the performance pattern. moreover, we show that the nonlinearity of the sigmoid activation of feedback signals allows the existence of optimal combinations of performance and sensitivity. in a detailed hindlimb locomotor system, we find that a force-dependent feedback can simultaneously optimize both performance and robustness, while length-dependent feedback variations result in significant performance-versus-sensitivity tradeoffs. thus, this work provides an analytical framework for studying feedback control of oscillations in nonlinear dynamical systems, leading to several insights that have the potential to inform the design of control or rehabilitation systems.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chemical mass-action systems as analog computers: implementing   arithmetic computations at specified speed</td>\n",
       "      <td>[david f. anderson, badal joshi]</td>\n",
       "      <td>recent technological advances allow us to view chemical mass-action systems as analog computers. in this context, the inputs to a computation are encoded as initial values of certain chemical species while the outputs are the limiting values of other chemical species. in this paper, we design chemical systems that carry out the elementary arithmetic computations of: identification, inversion, $m$th roots (for $m \\ge 2$), addition, multiplication, absolute difference, rectified subtraction over non-negative real numbers, and partial real inversion over real numbers. we prove that these ``elementary modules'' have a speed of computation that is independent of the inputs to the computation. moreover, we prove that finite sequences of such elementary modules, running in parallel, can carry out composite arithmetic over real numbers, also at a rate that is independent of inputs. furthermore, we show that the speed of a composite computation is precisely the speed of the slowest elementary step. specifically, the scale of the composite computation, i.e. the number of elementary steps involved in the composite, does not affect the overall asymptotic speed -- a feature of the parallel computing nature of our algorithm. our proofs require the careful mathematical analysis of certain non-autonomous systems, and we believe this analysis will be useful in different areas of applied mathematics, dynamical systems, and the theory of computation. we close with a discussion on future research directions, including numerous important open theoretical questions pertaining to the field of computation with reaction networks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>antifragile control systems in neuronal processing: a sensorimotor   perspective</td>\n",
       "      <td>[cristian axenie]</td>\n",
       "      <td>the stability--robustness--resilience--adaptiveness continuum in neuronal processing follows a hierarchical structure that explains interactions and information processing among the different time scales. interestingly, using \"canonical\" neuronal computational circuits, such as homeostatic activity regulation, winner-take-all, and hebbian temporal correlation learning, one can extend the behaviour spectrum towards antifragility. cast already in both probability theory and dynamical systems, antifragility can explain and define the interesting interplay among neural circuits, found, for instance, in sensorimotor control in the face of uncertainty and volatility. this perspective proposes a new framework to analyse and describe closed-loop neuronal processing using principles of antifragility, targeting sensorimotor control. our objective is two-fold. first, we introduce antifragile control as a conceptual framework to quantify closed-loop neuronal network behaviours that gain from uncertainty and volatility. second, we introduce neuronal network design principles, opening the path to neuromorphic implementations and transfer to technical systems.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on hybrid gene regulatory networks</td>\n",
       "      <td>[adrian wurm, honglu sun]</td>\n",
       "      <td>in this work, we study a class of hybrid dynamical systems called hybrid gene regulatory networks (hgrns) which was proposed to model gene regulatory networks. in hgrns, there exist well-behaved trajectories that reach a fixed point or converge to a limit cycle, as well as chaotic trajectories that behave non-periodic or indeterministic. in our work, we investigate these irregular behaviors of hgrns and present theoretical results about the decidability of the reachability problem, the probability of indeterministic behavior of hgrns, and chaos especially in 2-dimensional hgrns.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linocs: lookahead inference of networked operators for continuous   stability</td>\n",
       "      <td>[noga mudrik, eva yezerets, yenho chen, christopher rozell, adam charles]</td>\n",
       "      <td>identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. for instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. existing dynamical system identification methods often yield operators that accurately capture short-term behavior but fail to predict long-term trends, suggesting an incomplete capture of the underlying process. methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. here we introduce lookahead-driven inference of networked operators for continuous stability (linocs), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. linocs integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. we demonstrate linocs' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including linear, piece-wise linear, time-changing linear systems' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         title  \\\n",
       "0                                      variational design of sensory feedback for powerstroke-recovery systems   \n",
       "1  chemical mass-action systems as analog computers: implementing   arithmetic computations at specified speed   \n",
       "2                             antifragile control systems in neuronal processing: a sensorimotor   perspective   \n",
       "3                                                                           on hybrid gene regulatory networks   \n",
       "4                                linocs: lookahead inference of networked operators for continuous   stability   \n",
       "\n",
       "                                                                     authors  \\\n",
       "0                                              [zhuojun yu, peter j. thomas]   \n",
       "1                                           [david f. anderson, badal joshi]   \n",
       "2                                                          [cristian axenie]   \n",
       "3                                                  [adrian wurm, honglu sun]   \n",
       "4  [noga mudrik, eva yezerets, yenho chen, christopher rozell, adam charles]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   abstract  \n",
       "0  although the raison d'etre of the brain is the survival of the body, there are relatively few theoretical studies of closed-loop rhythmic motor control systems. in this paper we provide a unified framework, based on variational analysis, for investigating the dual goals of performance and robustness in powerstroke-recovery systems. we augment two previously published closed-loop motor control models by equipping each model with a performance measure based on the rate of progress of the system relative to a spatially extended external substrate -- such as progress relative to the ground for a locomotor task. the sensitivity measure quantifies the ability of the system to maintain performance in response to external perturbations. motivated by a search for optimal design principles for feedback control achieving the complementary requirements of efficiency and robustness, we discuss the performance-sensitivity patterns of the systems featuring different sensory feedback architectures. in a paradigmatic half-center oscillator (hco)-motor system, we observe that the excitation-inhibition property of feedback mechanisms determines the sensitivity pattern while the activation-inactivation property determines the performance pattern. moreover, we show that the nonlinearity of the sigmoid activation of feedback signals allows the existence of optimal combinations of performance and sensitivity. in a detailed hindlimb locomotor system, we find that a force-dependent feedback can simultaneously optimize both performance and robustness, while length-dependent feedback variations result in significant performance-versus-sensitivity tradeoffs. thus, this work provides an analytical framework for studying feedback control of oscillations in nonlinear dynamical systems, leading to several insights that have the potential to inform the design of control or rehabilitation systems.  \n",
       "1                                                                                                                                                                                                                                                                          recent technological advances allow us to view chemical mass-action systems as analog computers. in this context, the inputs to a computation are encoded as initial values of certain chemical species while the outputs are the limiting values of other chemical species. in this paper, we design chemical systems that carry out the elementary arithmetic computations of: identification, inversion, $m$th roots (for $m \\ge 2$), addition, multiplication, absolute difference, rectified subtraction over non-negative real numbers, and partial real inversion over real numbers. we prove that these ``elementary modules'' have a speed of computation that is independent of the inputs to the computation. moreover, we prove that finite sequences of such elementary modules, running in parallel, can carry out composite arithmetic over real numbers, also at a rate that is independent of inputs. furthermore, we show that the speed of a composite computation is precisely the speed of the slowest elementary step. specifically, the scale of the composite computation, i.e. the number of elementary steps involved in the composite, does not affect the overall asymptotic speed -- a feature of the parallel computing nature of our algorithm. our proofs require the careful mathematical analysis of certain non-autonomous systems, and we believe this analysis will be useful in different areas of applied mathematics, dynamical systems, and the theory of computation. we close with a discussion on future research directions, including numerous important open theoretical questions pertaining to the field of computation with reaction networks.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               the stability--robustness--resilience--adaptiveness continuum in neuronal processing follows a hierarchical structure that explains interactions and information processing among the different time scales. interestingly, using \"canonical\" neuronal computational circuits, such as homeostatic activity regulation, winner-take-all, and hebbian temporal correlation learning, one can extend the behaviour spectrum towards antifragility. cast already in both probability theory and dynamical systems, antifragility can explain and define the interesting interplay among neural circuits, found, for instance, in sensorimotor control in the face of uncertainty and volatility. this perspective proposes a new framework to analyse and describe closed-loop neuronal processing using principles of antifragility, targeting sensorimotor control. our objective is two-fold. first, we introduce antifragile control as a conceptual framework to quantify closed-loop neuronal network behaviours that gain from uncertainty and volatility. second, we introduce neuronal network design principles, opening the path to neuromorphic implementations and transfer to technical systems.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 in this work, we study a class of hybrid dynamical systems called hybrid gene regulatory networks (hgrns) which was proposed to model gene regulatory networks. in hgrns, there exist well-behaved trajectories that reach a fixed point or converge to a limit cycle, as well as chaotic trajectories that behave non-periodic or indeterministic. in our work, we investigate these irregular behaviors of hgrns and present theoretical results about the decidability of the reachability problem, the probability of indeterministic behavior of hgrns, and chaos especially in 2-dimensional hgrns.  \n",
       "4                                                             identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. for instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. existing dynamical system identification methods often yield operators that accurately capture short-term behavior but fail to predict long-term trends, suggesting an incomplete capture of the underlying process. methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. here we introduce lookahead-driven inference of networked operators for continuous stability (linocs), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. linocs integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. we demonstrate linocs' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including linear, piece-wise linear, time-changing linear systems' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would you like to download these articles [Y/N]?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/jpic/RAG-DEV/specialized_docs' created successfully\n",
      "https://arxiv.org/pdf/2404.00111 --> /home/jpic/RAG-DEV/specialized_docs/2404.00111.pdf\n",
      "https://arxiv.org/pdf/2404.04396 --> /home/jpic/RAG-DEV/specialized_docs/2404.04396.pdf\n",
      "https://arxiv.org/pdf/2404.14799 --> /home/jpic/RAG-DEV/specialized_docs/2404.14799.pdf\n",
      "https://arxiv.org/pdf/2404.16197 --> /home/jpic/RAG-DEV/specialized_docs/2404.16197.pdf\n",
      "https://arxiv.org/pdf/2404.18267 --> /home/jpic/RAG-DEV/specialized_docs/2404.18267.pdf\n"
     ]
    }
   ],
   "source": [
    "def arxiv(query):\n",
    "    \"\"\"\n",
    "    Search for articles on arXiv, display results, and optionally download the articles as PDFs.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query for arXiv.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the output message (str) and a process dictionary (dict).\n",
    "    \"\"\"\n",
    "    process = {}\n",
    "    output = 'searching the following on arxiv: ' + query\n",
    "    print(output)\n",
    "    df = arxiv_search(query)\n",
    "    process['search results'] = df\n",
    "    displayDf = df[['title', 'authors', 'abstract']]\n",
    "    display(displayDf)\n",
    "    output += '\\n would you like to download these articles [Y/N]?'\n",
    "    print('would you like to download these articles [Y/N]?')\n",
    "    download = input().strip().upper()\n",
    "    process['download'] = (download == 'Y')\n",
    "    if download == 'Y':\n",
    "        id_list = df['id'].to_list()\n",
    "        output += arxiv_scrape(id_list)\n",
    "    return output, process\n",
    "\n",
    "def arxiv_search(query):\n",
    "    \"\"\"\n",
    "    Search for articles on arXiv based on the given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query for arXiv.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the search results with columns 'id', 'title', 'categories', \n",
    "                      'abstract', 'doi', 'created', 'updated', and 'authors'.\n",
    "    \"\"\"\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    scraper = arxivscraper.Scraper(category='q-bio', date_from='2024-04-01',date_until='2024-05-01',t=10, filters={'abstract':[query]})\n",
    "    output = scraper.scrape()\n",
    "    cols = ('id', 'title', 'categories', 'abstract', 'doi', 'created', 'updated', 'authors')\n",
    "    df = pd.DataFrame(output,columns=cols)\n",
    "    return df\n",
    "\n",
    "def arxiv_scrape(id_list):\n",
    "    \"\"\"\n",
    "    Download articles from arXiv as PDFs based on the given list of IDs.\n",
    "\n",
    "    Args:\n",
    "        id_list (list): A list of article IDs to download from arXiv.\n",
    "\n",
    "    Returns:\n",
    "        str: A string indicating the outcome of the download process.\n",
    "    \"\"\"\n",
    "    output = ''\n",
    "    session = HTMLSession()\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'}\n",
    "    try:\n",
    "        path = os.path.join(os.getcwd(), 'specialized_docs')\n",
    "        os.makedirs(path, exist_ok = True) \n",
    "        output = f\"Directory '{path}' created successfully\"\n",
    "    except OSError:\n",
    "        output = f\"Directory '{path}' could not be created\"\n",
    "    print(output)\n",
    "\n",
    "    #Scrape arxiv and\n",
    "    for arxiv_id  in id_list:\n",
    "        try:\n",
    "            pdf_url = f'https://arxiv.org/pdf/{arxiv_id}'\n",
    "            local_path = os.path.join(path, f'{arxiv_id}.pdf')\n",
    "            print(f'{pdf_url} --> {local_path}')\n",
    "            output += f'\\n{pdf_url} --> {local_path}'\n",
    "\n",
    "            response = session.get(pdf_url, stream=True)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            with open(os.path.join(path, ids + '.pdf'), 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size = 1024):\n",
    "                    f.write(chunk)\n",
    "        except (ConnectionError, requests.exceptions.RequestException) as e:\n",
    "            print(f\"{arxiv_id} could not be gathered: {e}\")\n",
    "            output += f\"\\n{arxiv_id} could not be gathered.\"\n",
    "    return output\n",
    "\n",
    "output, process = arxiv('dynamical systems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87732953-9629-4219-9057-75b7c98097c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search results':            id  \\\n",
       " 0  2404.00111   \n",
       " 1  2404.04396   \n",
       " 2  2404.14799   \n",
       " 3  2404.16197   \n",
       " 4  2404.18267   \n",
       " \n",
       "                                                                                                          title  \\\n",
       " 0                                      variational design of sensory feedback for powerstroke-recovery systems   \n",
       " 1  chemical mass-action systems as analog computers: implementing   arithmetic computations at specified speed   \n",
       " 2                             antifragile control systems in neuronal processing: a sensorimotor   perspective   \n",
       " 3                                                                           on hybrid gene regulatory networks   \n",
       " 4                                linocs: lookahead inference of networked operators for continuous   stability   \n",
       " \n",
       "                      categories  \\\n",
       " 0                      q-bio.nc   \n",
       " 1              math.ds q-bio.mn   \n",
       " 2        q-bio.nc cs.sy eess.sy   \n",
       " 3                q-bio.mn cs.ce   \n",
       " 4  eess.sy cs.lg cs.sy q-bio.qm   \n",
       " \n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    abstract  \\\n",
       " 0  although the raison d'etre of the brain is the survival of the body, there are relatively few theoretical studies of closed-loop rhythmic motor control systems. in this paper we provide a unified framework, based on variational analysis, for investigating the dual goals of performance and robustness in powerstroke-recovery systems. we augment two previously published closed-loop motor control models by equipping each model with a performance measure based on the rate of progress of the system relative to a spatially extended external substrate -- such as progress relative to the ground for a locomotor task. the sensitivity measure quantifies the ability of the system to maintain performance in response to external perturbations. motivated by a search for optimal design principles for feedback control achieving the complementary requirements of efficiency and robustness, we discuss the performance-sensitivity patterns of the systems featuring different sensory feedback architectures. in a paradigmatic half-center oscillator (hco)-motor system, we observe that the excitation-inhibition property of feedback mechanisms determines the sensitivity pattern while the activation-inactivation property determines the performance pattern. moreover, we show that the nonlinearity of the sigmoid activation of feedback signals allows the existence of optimal combinations of performance and sensitivity. in a detailed hindlimb locomotor system, we find that a force-dependent feedback can simultaneously optimize both performance and robustness, while length-dependent feedback variations result in significant performance-versus-sensitivity tradeoffs. thus, this work provides an analytical framework for studying feedback control of oscillations in nonlinear dynamical systems, leading to several insights that have the potential to inform the design of control or rehabilitation systems.   \n",
       " 1                                                                                                                                                                                                                                                                          recent technological advances allow us to view chemical mass-action systems as analog computers. in this context, the inputs to a computation are encoded as initial values of certain chemical species while the outputs are the limiting values of other chemical species. in this paper, we design chemical systems that carry out the elementary arithmetic computations of: identification, inversion, $m$th roots (for $m \\ge 2$), addition, multiplication, absolute difference, rectified subtraction over non-negative real numbers, and partial real inversion over real numbers. we prove that these ``elementary modules'' have a speed of computation that is independent of the inputs to the computation. moreover, we prove that finite sequences of such elementary modules, running in parallel, can carry out composite arithmetic over real numbers, also at a rate that is independent of inputs. furthermore, we show that the speed of a composite computation is precisely the speed of the slowest elementary step. specifically, the scale of the composite computation, i.e. the number of elementary steps involved in the composite, does not affect the overall asymptotic speed -- a feature of the parallel computing nature of our algorithm. our proofs require the careful mathematical analysis of certain non-autonomous systems, and we believe this analysis will be useful in different areas of applied mathematics, dynamical systems, and the theory of computation. we close with a discussion on future research directions, including numerous important open theoretical questions pertaining to the field of computation with reaction networks.   \n",
       " 2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               the stability--robustness--resilience--adaptiveness continuum in neuronal processing follows a hierarchical structure that explains interactions and information processing among the different time scales. interestingly, using \"canonical\" neuronal computational circuits, such as homeostatic activity regulation, winner-take-all, and hebbian temporal correlation learning, one can extend the behaviour spectrum towards antifragility. cast already in both probability theory and dynamical systems, antifragility can explain and define the interesting interplay among neural circuits, found, for instance, in sensorimotor control in the face of uncertainty and volatility. this perspective proposes a new framework to analyse and describe closed-loop neuronal processing using principles of antifragility, targeting sensorimotor control. our objective is two-fold. first, we introduce antifragile control as a conceptual framework to quantify closed-loop neuronal network behaviours that gain from uncertainty and volatility. second, we introduce neuronal network design principles, opening the path to neuromorphic implementations and transfer to technical systems.   \n",
       " 3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 in this work, we study a class of hybrid dynamical systems called hybrid gene regulatory networks (hgrns) which was proposed to model gene regulatory networks. in hgrns, there exist well-behaved trajectories that reach a fixed point or converge to a limit cycle, as well as chaotic trajectories that behave non-periodic or indeterministic. in our work, we investigate these irregular behaviors of hgrns and present theoretical results about the decidability of the reachability problem, the probability of indeterministic behavior of hgrns, and chaos especially in 2-dimensional hgrns.   \n",
       " 4                                                             identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. for instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. existing dynamical system identification methods often yield operators that accurately capture short-term behavior but fail to predict long-term trends, suggesting an incomplete capture of the underlying process. methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. here we introduce lookahead-driven inference of networked operators for continuous stability (linocs), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. linocs integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. we demonstrate linocs' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including linear, piece-wise linear, time-changing linear systems' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples.   \n",
       " \n",
       "   doi     created updated  \\\n",
       " 0      2024-03-29           \n",
       " 1      2024-04-05           \n",
       " 2      2024-04-23           \n",
       " 3      2024-04-24           \n",
       " 4      2024-04-28           \n",
       " \n",
       "                                                                      authors  \n",
       " 0                                              [zhuojun yu, peter j. thomas]  \n",
       " 1                                           [david f. anderson, badal joshi]  \n",
       " 2                                                          [cristian axenie]  \n",
       " 3                                                  [adrian wurm, honglu sun]  \n",
       " 4  [noga mudrik, eva yezerets, yenho chen, christopher rozell, adam charles]  ,\n",
       " 'download': True}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66d5fcaf-b28c-4449-9eb9-74db405664d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":{\"0\":\"2404.00111\",\"1\":\"2404.04396\",\"2\":\"2404.14799\",\"3\":\"2404.16197\",\"4\":\"2404.18267\"},\"title\":{\"0\":\"variational design of sensory feedback for powerstroke-recovery systems\",\"1\":\"chemical mass-action systems as analog computers: implementing   arithmetic computations at specified speed\",\"2\":\"antifragile control systems in neuronal processing: a sensorimotor   perspective\",\"3\":\"on hybrid gene regulatory networks\",\"4\":\"linocs: lookahead inference of networked operators for continuous   stability\"},\"categories\":{\"0\":\"q-bio.nc\",\"1\":\"math.ds q-bio.mn\",\"2\":\"q-bio.nc cs.sy eess.sy\",\"3\":\"q-bio.mn cs.ce\",\"4\":\"eess.sy cs.lg cs.sy q-bio.qm\"},\"abstract\":{\"0\":\"although the raison d\\'etre of the brain is the survival of the body, there are relatively few theoretical studies of closed-loop rhythmic motor control systems. in this paper we provide a unified framework, based on variational analysis, for investigating the dual goals of performance and robustness in powerstroke-recovery systems. we augment two previously published closed-loop motor control models by equipping each model with a performance measure based on the rate of progress of the system relative to a spatially extended external substrate -- such as progress relative to the ground for a locomotor task. the sensitivity measure quantifies the ability of the system to maintain performance in response to external perturbations. motivated by a search for optimal design principles for feedback control achieving the complementary requirements of efficiency and robustness, we discuss the performance-sensitivity patterns of the systems featuring different sensory feedback architectures. in a paradigmatic half-center oscillator (hco)-motor system, we observe that the excitation-inhibition property of feedback mechanisms determines the sensitivity pattern while the activation-inactivation property determines the performance pattern. moreover, we show that the nonlinearity of the sigmoid activation of feedback signals allows the existence of optimal combinations of performance and sensitivity. in a detailed hindlimb locomotor system, we find that a force-dependent feedback can simultaneously optimize both performance and robustness, while length-dependent feedback variations result in significant performance-versus-sensitivity tradeoffs. thus, this work provides an analytical framework for studying feedback control of oscillations in nonlinear dynamical systems, leading to several insights that have the potential to inform the design of control or rehabilitation systems.\",\"1\":\"recent technological advances allow us to view chemical mass-action systems as analog computers. in this context, the inputs to a computation are encoded as initial values of certain chemical species while the outputs are the limiting values of other chemical species. in this paper, we design chemical systems that carry out the elementary arithmetic computations of: identification, inversion, $m$th roots (for $m \\\\\\\\ge 2$), addition, multiplication, absolute difference, rectified subtraction over non-negative real numbers, and partial real inversion over real numbers. we prove that these ``elementary modules\\'\\' have a speed of computation that is independent of the inputs to the computation. moreover, we prove that finite sequences of such elementary modules, running in parallel, can carry out composite arithmetic over real numbers, also at a rate that is independent of inputs. furthermore, we show that the speed of a composite computation is precisely the speed of the slowest elementary step. specifically, the scale of the composite computation, i.e. the number of elementary steps involved in the composite, does not affect the overall asymptotic speed -- a feature of the parallel computing nature of our algorithm. our proofs require the careful mathematical analysis of certain non-autonomous systems, and we believe this analysis will be useful in different areas of applied mathematics, dynamical systems, and the theory of computation. we close with a discussion on future research directions, including numerous important open theoretical questions pertaining to the field of computation with reaction networks.\",\"2\":\"the stability--robustness--resilience--adaptiveness continuum in neuronal processing follows a hierarchical structure that explains interactions and information processing among the different time scales. interestingly, using \\\\\"canonical\\\\\" neuronal computational circuits, such as homeostatic activity regulation, winner-take-all, and hebbian temporal correlation learning, one can extend the behaviour spectrum towards antifragility. cast already in both probability theory and dynamical systems, antifragility can explain and define the interesting interplay among neural circuits, found, for instance, in sensorimotor control in the face of uncertainty and volatility. this perspective proposes a new framework to analyse and describe closed-loop neuronal processing using principles of antifragility, targeting sensorimotor control. our objective is two-fold. first, we introduce antifragile control as a conceptual framework to quantify closed-loop neuronal network behaviours that gain from uncertainty and volatility. second, we introduce neuronal network design principles, opening the path to neuromorphic implementations and transfer to technical systems.\",\"3\":\"in this work, we study a class of hybrid dynamical systems called hybrid gene regulatory networks (hgrns) which was proposed to model gene regulatory networks. in hgrns, there exist well-behaved trajectories that reach a fixed point or converge to a limit cycle, as well as chaotic trajectories that behave non-periodic or indeterministic. in our work, we investigate these irregular behaviors of hgrns and present theoretical results about the decidability of the reachability problem, the probability of indeterministic behavior of hgrns, and chaos especially in 2-dimensional hgrns.\",\"4\":\"identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. for instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. existing dynamical system identification methods often yield operators that accurately capture short-term behavior but fail to predict long-term trends, suggesting an incomplete capture of the underlying process. methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. here we introduce lookahead-driven inference of networked operators for continuous stability (linocs), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. linocs integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. we demonstrate linocs\\' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including linear, piece-wise linear, time-changing linear systems\\' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples.\"},\"doi\":{\"0\":\"\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\"},\"created\":{\"0\":\"2024-03-29\",\"1\":\"2024-04-05\",\"2\":\"2024-04-23\",\"3\":\"2024-04-24\",\"4\":\"2024-04-28\"},\"updated\":{\"0\":\"\",\"1\":\"\",\"2\":\"\",\"3\":\"\",\"4\":\"\"},\"authors\":{\"0\":[\"zhuojun yu\",\"peter j. thomas\"],\"1\":[\"david f. anderson\",\"badal joshi\"],\"2\":[\"cristian axenie\"],\"3\":[\"adrian wurm\",\"honglu sun\"],\"4\":[\"noga mudrik\",\"eva yezerets\",\"yenho chen\",\"christopher rozell\",\"adam charles\"]}}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f78038dc-082c-4fda-8c7e-25a4566e0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching up to  1000 records...\n",
      "fetching is completed in 6.2 seconds.\n",
      "Total number of records 5\n",
      "Directory '/home/jpic/RAG-DEV/specialized_docs' created successfully\n",
      "https://arxiv.org/pdf/2404.00111\n",
      "<Response [200]>\n",
      "https://arxiv.org/pdf/2404.04396\n",
      "<Response [200]>\n",
      "https://arxiv.org/pdf/2404.14799\n",
      "<Response [200]>\n",
      "https://arxiv.org/pdf/2404.16197\n",
      "<Response [200]>\n",
      "https://arxiv.org/pdf/2404.18267\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import arxivscraper\n",
    "query = 'dynamical systems'\n",
    "scraper = arxivscraper.Scraper(category='q-bio', date_from='2024-04-01',date_until='2024-05-01',t=10, filters={'abstract':[query]})\n",
    "output = scraper.scrape()\n",
    "cols = ('id', 'title', 'categories', 'abstract', 'doi', 'created', 'updated', 'authors')\n",
    "df = pd.DataFrame(output,columns=cols)\n",
    "id_list = df['id'].to_list()\n",
    "\n",
    "s = HTMLSession()\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'}\n",
    "#Create directory to store pdfs\n",
    "try:\n",
    "    path = os.path.abspath(os.getcwd()) + '/specialized_docs'\n",
    "    os.makedirs(path, exist_ok = True) \n",
    "    print(\"Directory '%s' created successfully\" % path)\n",
    "except OSError as error:\n",
    "    print(\"Directory '%s' can not be created\" % path)\n",
    "\n",
    "#Scrape arxiv and\n",
    "for ids in id_list:\n",
    "    try:\n",
    "        base_url = 'https://arxiv.org/pdf/'\n",
    "        pdf_url = base_url+ids\n",
    "        print(pdf_url)\n",
    "        r = s.get(pdf_url, stream=True)\n",
    "        with open(os.path.join(path, ids + '.pdf'), 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size = 1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    except ConnectionError as e:\n",
    "        pass\n",
    "        print(f\"{ids} could not be gathered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca9389e5-2701-408c-ac47-023bad1593ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>doi</th>\n",
       "      <th>created</th>\n",
       "      <th>updated</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2404.00111</td>\n",
       "      <td>variational design of sensory feedback for pow...</td>\n",
       "      <td>q-bio.nc</td>\n",
       "      <td>although the raison d'etre of the brain is the...</td>\n",
       "      <td></td>\n",
       "      <td>2024-03-29</td>\n",
       "      <td></td>\n",
       "      <td>[zhuojun yu, peter j. thomas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2404.04396</td>\n",
       "      <td>chemical mass-action systems as analog compute...</td>\n",
       "      <td>math.ds q-bio.mn</td>\n",
       "      <td>recent technological advances allow us to view...</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td></td>\n",
       "      <td>[david f. anderson, badal joshi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2404.14799</td>\n",
       "      <td>antifragile control systems in neuronal proces...</td>\n",
       "      <td>q-bio.nc cs.sy eess.sy</td>\n",
       "      <td>the stability--robustness--resilience--adaptiv...</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td></td>\n",
       "      <td>[cristian axenie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2404.16197</td>\n",
       "      <td>on hybrid gene regulatory networks</td>\n",
       "      <td>q-bio.mn cs.ce</td>\n",
       "      <td>in this work, we study a class of hybrid dynam...</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td></td>\n",
       "      <td>[adrian wurm, honglu sun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2404.18267</td>\n",
       "      <td>linocs: lookahead inference of networked opera...</td>\n",
       "      <td>eess.sy cs.lg cs.sy q-bio.qm</td>\n",
       "      <td>identifying latent interactions within complex...</td>\n",
       "      <td></td>\n",
       "      <td>2024-04-28</td>\n",
       "      <td></td>\n",
       "      <td>[noga mudrik, eva yezerets, yenho chen, christ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0  2404.00111  variational design of sensory feedback for pow...   \n",
       "1  2404.04396  chemical mass-action systems as analog compute...   \n",
       "2  2404.14799  antifragile control systems in neuronal proces...   \n",
       "3  2404.16197                 on hybrid gene regulatory networks   \n",
       "4  2404.18267  linocs: lookahead inference of networked opera...   \n",
       "\n",
       "                     categories  \\\n",
       "0                      q-bio.nc   \n",
       "1              math.ds q-bio.mn   \n",
       "2        q-bio.nc cs.sy eess.sy   \n",
       "3                q-bio.mn cs.ce   \n",
       "4  eess.sy cs.lg cs.sy q-bio.qm   \n",
       "\n",
       "                                            abstract doi     created updated  \\\n",
       "0  although the raison d'etre of the brain is the...      2024-03-29           \n",
       "1  recent technological advances allow us to view...      2024-04-05           \n",
       "2  the stability--robustness--resilience--adaptiv...      2024-04-23           \n",
       "3  in this work, we study a class of hybrid dynam...      2024-04-24           \n",
       "4  identifying latent interactions within complex...      2024-04-28           \n",
       "\n",
       "                                             authors  \n",
       "0                      [zhuojun yu, peter j. thomas]  \n",
       "1                   [david f. anderson, badal joshi]  \n",
       "2                                  [cristian axenie]  \n",
       "3                          [adrian wurm, honglu sun]  \n",
       "4  [noga mudrik, eva yezerets, yenho chen, christ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d7cf50-8d57-4b6f-b7b3-b9acccb46362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching up to  1000 records...\n",
      "fetching is completed in 7.6 seconds.\n",
      "Total number of records 5\n",
      "Directory '/home/jpic/RAG-DEV/specialized_docs' created successfully\n",
      "https://arxiv.org/pdf/2404.00111\n",
      "<Response [200]>\n",
      "https://arxiv.org/pdf/2404.04396\n",
      "<Response [200]>\n",
      "https://arxiv.org/pdf/2404.14799\n",
      "<Response [200]>\n",
      "https://arxiv.org/pdf/2404.16197\n",
      "<Response [200]>\n",
      "https://arxiv.org/pdf/2404.18267\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "from scraper import *\n",
    "arxiv('dynamical systems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5fa1da-862d-45b2-9897-0ad4bdeded0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://biorxiv.org/search/jcode%3Abiorxiv%20abstract_title%3Atranscription factor%20abstract_title_flags%3Amatch-all%20limit_from%3A2024-05-01%20limit_to%3A2024-05-17%20numresults%3A75%20format_result%3Acondensed%20sort%3Arelevance-rank\n",
      "Fetching search results 1 to 75...\n",
      "Max number of records (75) reached. Fetched in 8.4 seconds.\n",
      "Directory '/home/jpic/RAG-DEV/specialized_docs' created successfully\n",
      "Downloading 75 PDFs to /home/jpic/RAG-DEV/specialized_docs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "biorxiv('transcription factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6447844-83c6-4af9-8b75-816eded07754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/jpic/RAG-DEV/specialized_docs' created successfully\n",
      "https://ncbi.nlm.nih.gov/pmc/articles/PMC9667253/pdf/main.pdf\n",
      "https://ncbi.nlm.nih.gov/pmc/articles/PMC10136082/pdf/biosensors-13-00428.pdf\n",
      "https://ncbi.nlm.nih.gov/pmc/articles/PMC3367499/pdf/nihms-381457.pdf\n",
      "pdf collection complete!\n"
     ]
    }
   ],
   "source": [
    "pubmed('transcription factor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923a8120-b898-4a8b-ae87-3f1d6f287471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fri May 17 00:50:07 2024 INFO This is an info message\n",
      "Fri May 17 00:50:07 2024 WARNING This is a warning message\n",
      "Fri May 17 00:50:07 2024 ERROR This is an error message\n",
      "Fri May 17 00:50:07 2024 CRITICAL This is a critical message\n"
     ]
    }
   ],
   "source": [
    "def biorxiv_real_search(start_date  = datetime.date.today().replace(day=1), \n",
    "                        end_date    = datetime.date.today(), \n",
    "                        subjects    = [], \n",
    "                        journal     = 'biorxiv',\n",
    "                        kwd         = [], \n",
    "                        kwd_type    = 'all', \n",
    "                        athr        = [], \n",
    "                        max_records = 75, \n",
    "                        max_time    = 300,\n",
    "                        cols        = ['title', 'authors', 'url'],\n",
    "                        abstracts   = False):\n",
    "    \"\"\"\n",
    "    Searches a specified journal for articles matching given criteria and returns their details.\n",
    "\n",
    "    This function builds a search query URL based on the given parameters, fetches the search results\n",
    "    from the specified journal, and returns a DataFrame with the details of the articles found.\n",
    "\n",
    "    Parameters:\n",
    "    start_date (datetime.date, optional): The start date for the search. Defaults to the first day of the current month.\n",
    "    end_date (datetime.date, optional): The end date for the search. Defaults to today.\n",
    "    subjects (list, optional): List of subjects to filter the search by. Defaults to an empty list.\n",
    "    journal (str, optional): The journal to search. Defaults to 'biorxiv'.\n",
    "    kwd (list, optional): List of keywords to filter the search by. Defaults to an empty list.\n",
    "    kwd_type (str, optional): Type of keyword matching ('all', 'any'). Defaults to 'all'.\n",
    "    athr (list, optional): List of author names to filter the search by. Defaults to an empty list.\n",
    "    max_records (int, optional): Maximum number of records to fetch. Defaults to 75.\n",
    "    max_time (int, optional): Maximum time (in seconds) to spend on the search. Defaults to 300.\n",
    "    cols (list, optional): List of columns to include in the returned DataFrame. Defaults to ['title', 'authors', 'url'].\n",
    "    abstracts (bool, optional): Whether to fetch abstracts for the articles. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the details of the articles found.\n",
    "\n",
    "    Example:\n",
    "    >>> df = biorxiv_real_search(start_date=datetime.date(2023, 1, 1), end_date=datetime.date(2023, 1, 31), subjects=['neuroscience'], kwd=['brain'], max_records=10)\n",
    "    >>> print(df)\n",
    "       title        authors                                                url\n",
    "    0  Title1  [Author1, Author2]  http://www.biorxiv.org/content/10.1101/2023...\n",
    "\n",
    "    Notes:\n",
    "    - The function assumes that the BeautifulSoup, pandas, and requests libraries are installed and properly configured.\n",
    "    - The search is performed on the specified journal's website, and the articles' details are extracted from the search results.\n",
    "    - If `abstracts` is set to True, the function will also fetch the abstracts of the articles, which can increase the execution time.\n",
    "    \"\"\"\n",
    "\n",
    "    ## keep track of timing\n",
    "    overall_time = time.time()\n",
    "\n",
    "    ## url\n",
    "    BASE = 'http://{:s}.org/search/'.format(journal)\n",
    "    url = BASE\n",
    "    ## format dates\n",
    "    start_date = str(start_date)\n",
    "    end_date = str(end_date)\n",
    "\n",
    "    ## format inputs\n",
    "    journal = journal.lower()\n",
    "    kwd_type = kwd_type.lower()\n",
    "\n",
    "    ## journal selection\n",
    "    journal_str = 'jcode%3A' + journal\n",
    "    url += journal_str\n",
    "\n",
    "    ## subject selection\n",
    "    if len(subjects) > 0:\n",
    "        first_subject = ('%20').join(subjects[0].split())\n",
    "        subject_str = 'subject_collection_code%3A' + first_subject\n",
    "        for subject in subjects[1:]:\n",
    "            subject_str = subject_str + '%2C' + ('%20').join(subject.split())\n",
    "        url += '%20' + subject_str\n",
    "        \n",
    "    ## keyword selection\n",
    "    if len(kwd) > 0:\n",
    "        kwd_str = 'abstract_title%3A' + ('%252C%2B').join([kwd[0]] + [('%2B').join(keyword.split()) for keyword in kwd[1:]])\n",
    "        kwd_str = kwd_str + '%20abstract_title_flags%3Amatch-' + kwd_type\n",
    "        url += '%20' + kwd_str\n",
    "\n",
    "    ## author selection\n",
    "    if len(athr) == 1:\n",
    "        athr_str = 'author1%3A' + ('%2B').join(athr[0].split())\n",
    "        url += '%20' + athr_str\n",
    "    if len(athr) == 2:\n",
    "        athr_str = 'author1%3A' + ('%2B').join(athr[0].split()) + '%20author2%3A' + ('%2B').join(athr[1].split())\n",
    "        url += '%20' + athr_str\n",
    "\n",
    "    ## date range string\n",
    "    date_str = 'limit_from%3A' + start_date + '%20limit_to%3A' + end_date\n",
    "    url += '%20' + date_str\n",
    "\n",
    "    ## fixed formatting\n",
    "    num_page_results = 75\n",
    "    url += '%20numresults%3A' + str(num_page_results) + '%20format_result%3Acondensed' + '%20sort%3Arelevance-rank'\n",
    "\n",
    "    print(url)\n",
    "    ## lists to store date\n",
    "    titles = []\n",
    "    author_lists = []\n",
    "    urls = []\n",
    "\n",
    "    ### once the string has been built, access site\n",
    "\n",
    "    # initialize number of pages to loop through\n",
    "    page = 0\n",
    "    ## loop through other pages of search if they exist\n",
    "    while True:\n",
    "        # keep user aware of status\n",
    "        print('Fetching search results {:d} to {:d}...'.format(num_page_results*page+1, num_page_results*(page+1)))\n",
    "        # access url and pull html data\n",
    "        if page == 0:\n",
    "            url_response = requests.post(url)\n",
    "            html = bs(url_response.text, features='html.parser')\n",
    "            # find out how many results there are, and make sure don't pull more than user wants\n",
    "            num_results_text = html.find('div', attrs={'class': 'highwire-search-summary'}).text.strip().split()[0]\n",
    "            if num_results_text == 'No':\n",
    "                print('No results found matching search criteria.')\n",
    "                return()\n",
    "            num_results = int(num_results_text)\n",
    "            num_fetch_results = min(max_records, num_results)\n",
    "        else:\n",
    "            page_url = url + '?page=' + str(page)\n",
    "            print(page_url)\n",
    "            url_response = requests.post(page_url)\n",
    "            html = bs(url_response.text, features='html.parser')\n",
    "        # list of articles on page\n",
    "        articles = html.find_all(attrs={'class': 'search-result'})\n",
    "        ## pull details from each article on page\n",
    "        titles += [article.find('span', attrs={'class': 'highwire-cite-title'}).text.strip() if article.find('span', attrs={'class': 'highwire-cite-title'}) is not None else None for article in articles]\n",
    "        author_lists += [[author.text for author in article.find_all('span', attrs={'class': 'highwire-citation-author'})] for article in articles]\n",
    "        urls = ['http://www.{:s}.org'.format(journal) + article.find('a', href=True)['href'] for article in articles]\n",
    "        ## see if too much time has passed or max number of records reached or no more pages\n",
    "        if time.time() - overall_time > max_time or (page+1)*num_page_results >= num_fetch_results:\n",
    "            break\n",
    "        page += 1\n",
    "    records_data = list(zip(*list(map(lambda dummy_list: dummy_list[0:num_fetch_results], [titles, author_lists, urls]))))\n",
    "    full_records_df = pd.DataFrame(records_data,columns=['title', 'authors', 'url'])\n",
    "\n",
    "    if num_results > max_records:\n",
    "        print('Max number of records ({:d}) reached. Fetched in {:.1f} seconds.'.format(max_records, time.time() - overall_time))\n",
    "    elif time.time() - overall_time > max_time:\n",
    "        print('Max time ({:.0f} seconds) reached. Fetched {:d} records in {:.1f} seconds.'.format(max_time, num_fetch_results, time.time() - overall_time))\n",
    "    else:\n",
    "        print('Fetched {:d} records in {:.1f} seconds.'.format(num_fetch_results, time.time() - overall_time))\n",
    "    if abstracts:\n",
    "        print('Fetching abstracts for {:d} papers...'.format(len(full_records_df)))\n",
    "        full_records_df['abstract'] = [bs(requests.post(paper_url).text, features='html.parser').find('div', attrs={'class': 'section abstract'}).text.replace('Abstract','').replace('\\n','') for paper_url in full_records_df.url]\n",
    "        cols += ['abstract']\n",
    "        print('Abstracts fetched.')\n",
    "    try: \n",
    "        path = os.path.abspath(os.getcwd()) + '/specialized_docs'\n",
    "        os.makedirs(path, exist_ok = True) \n",
    "        print(\"Directory '%s' created successfully\" % path) \n",
    "    except OSError as error: \n",
    "        print(\"Directory '%s' can not be created\" % path) \n",
    "    print('Downloading {:d} PDFs to {:s}...'.format(len(full_records_df), path))\n",
    "    pdf_urls = [''.join(url) + '.full.pdf' for url in full_records_df.url] # list of urls to pull pdfs from\n",
    "    # create filenames to export pdfs to currently setup in year_lastname format\n",
    "    pdf_lastnames_full = ['_'.join([name.split()[-1] for name in namelist]) for namelist in full_records_df.authors] # pull out lastnames only\n",
    "    pdf_lastnames = [name if len(name) < 200 else name.split('_')[0] + '_et_al' for name in pdf_lastnames_full] # make sure file names don't get longer than ~200 chars\n",
    "    pdf_paths = [''.join(lastname) + '.pdf' for lastname in zip(pdf_lastnames)] # full path for each file\n",
    "    # export pdfs\n",
    "    for paper_idx in range(len(pdf_urls)):\n",
    "        response = requests.get(pdf_urls[paper_idx])\n",
    "        file = open(os.path.join(path,pdf_paths[paper_idx]), 'wb')\n",
    "        file.write(response.content)\n",
    "        file.close()\n",
    "        gc.collect()\n",
    "    print('Download complete.')\n",
    "    records_df = full_records_df[cols]\n",
    "    print('Total time to fetch and manipulate records was {:.1f} seconds.'.format(time.time() - overall_time))\n",
    "    return(records_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b37f80-ea66-4f63-b2e3-6c845fa12838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger(chatlog, chatname):\n",
    "    with open(chatname, 'w') as fp:\n",
    "        json.dump(chatlog, fp, indent=4)\n",
    "        \n",
    "chatlog = {\n",
    "    0: {\n",
    "        'prompt': 'whats up today?',\n",
    "        'out'   : 'not much my guy'\n",
    "    },\n",
    "    1: {\n",
    "        'prompt': 'whats up today? 1',\n",
    "        'out'   : 'not much my guy 1'\n",
    "    },\n",
    "    2: {\n",
    "        'prompt': 'whats up today? 2',\n",
    "        'out'   : 'not much my guy 2'\n",
    "    }\n",
    "}\n",
    "chatname = 'del.json'\n",
    "\n",
    "logger(chatlog, chatname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
