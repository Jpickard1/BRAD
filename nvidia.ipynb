{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912b5508-dc52-4738-a81b-91d27dc4dcb7",
   "metadata": {},
   "source": [
    "# NVIDIA Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256843cf-f76a-40ff-b254-332a707bff64",
   "metadata": {},
   "source": [
    "## https://blog.langchain.dev/nvidia-nim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e389b1ac-0f4e-4341-8e22-260d83bd30bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chatbot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchatbot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_literature_db\n\u001b[1;32m      2\u001b[0m persist_directory     \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/nfs/turbo/umms-indikar/shared/projects/RAG/databases/Transcription-Factors-5-10-2024/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m ragvectordb, embeddings_model \u001b[38;5;241m=\u001b[39m load_literature_db(persist_directory)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chatbot'"
     ]
    }
   ],
   "source": [
    "from chatbot import load_literature_db\n",
    "persist_directory     = \"/nfs/turbo/umms-indikar/shared/projects/RAG/databases/Transcription-Factors-5-10-2024/\"\n",
    "ragvectordb, embeddings_model = load_literature_db(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e3addb-76d5-47b7-a849-653668a6ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings, ChatNVIDIA\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b24173e-05dc-4e22-90ef-501832e44b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ragvectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa21e57f-4459-4066-a0b1-fc21377a109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatNVIDIA(model=\"mistral_7b\",\n",
    "                    api_key = \"XXXXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d443ea-f38f-472c-b30a-d89f7bfb9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_template = \"\"\"Even if you do not know the full answer, generate a one-paragraph hypothetical answer to the below question:\n",
    "\n",
    "{question}\"\"\"\n",
    "hyde_prompt = ChatPromptTemplate.from_template(hyde_template)\n",
    "hyde_query_transformer = hyde_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e1c344-65f3-4683-9e12-68012bd7fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def hyde_retriever(question):\n",
    "    hypothetical_document = hyde_query_transformer.invoke({\"question\": question})\n",
    "    return retriever.invoke(hypothetical_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "449082e9-1139-4c36-bd55-716421980b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "answer_chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57181f27-4dcf-4b34-899b-05e87a0edfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def final_chain(question):\n",
    "    documents = hyde_retriever.invoke(question)\n",
    "    for s in answer_chain.stream({\"question\": question, \"context\": documents}):\n",
    "        yield s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deddac0e-3100-40d9-ab90-ea6b981bf4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Transcription factors (TFs) play a crucial role in the process of reprogramming somatic cells into pluripotent stem cells (PSCs), also known as induced pluripotent stem cells (iPSCs). By introducing specific TFs, such as Oct3/4, Sox2, Klf4, and c-Myc, researchers have been able to trigger endogenous expression of pluripotent factors, resulting in the reprogramming of fibroblasts into PSCs. These TFs have been found to be sufficient for converting fibroblasts into iPSCs, and while alternative sets of TFs have been reported for iPSC reprogramming, most studies include Oct3/4 and Sox2. These TFs help erase the memories of somatic cells, enabling them to adopt a pluripotent state. The use of TFs for this purpose has revolutionized the field of regenerative medicine."
     ]
    }
   ],
   "source": [
    "for s in final_chain.stream(\"how can transcription factors help reprogramming?\"):\n",
    "    print(s, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "141c4e65-79b4-41d0-be7e-cb8b7385cc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, there are no specific mentions of databases about Transcription Factors. However, the text does discuss the importance of continued effort to understand TF-mediated gene regulation and mentions two previous comprehensive reviews of human TFs published in 2009. These reviews may contain or be associated with databases of human TFs and binding motifs. The text also mentions the limitations of existing data and the challenges of systematically detecting higher-order interactions, which suggests that there may be ongoing efforts to develop and improve databases in this area."
     ]
    }
   ],
   "source": [
    "for s in final_chain.stream(\"What some databases about Transcription Factors?\"):\n",
    "    print(s, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8cb2e2-8d47-4219-8466-f3b7dcecbec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The text mentions several databases related to Transcription Factors (TFs) that have been used to study TF-DNA interactions: TRANSFAC, JASPAR, HT-SELEX, CisBP, Interpro, and TFClass. These databases provide information on TF motifs and genomic binding sites. The papers cited in the text for this information are: Matys et al. (2006), Mathelier et al. (2016), Weirauch et al. (2014), Wingender et al. (2015), and Berman et al. (2000)."
     ]
    }
   ],
   "source": [
    "for s in final_chain.stream(\"What some databases about Transcription Factors? Which papers are you referencing to answer this question?\"):\n",
    "    print(s, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6728bf85-9f6b-4e25-94c1-ae2e6acd9aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The context does not directly provide information about specific databases related to Transcription Factors. The text discusses papers that have reviewed human Transcription Factors and compiled lists of them, but it does not mention any specific databases.\n",
      "\n",
      "The papers cited in the context are \"The Human Transcription Factors\" by Fulton et al., 2009 and \"Human Transcription Factors: A Comprehensive Catalogue and Profile-based Analysis\" by Vaquerizas et al., 2009."
     ]
    }
   ],
   "source": [
    "for s in final_chain.stream(\"What some databases about Transcription Factors? Provide the title and authors of the papers used to answer this question?\"):\n",
    "    print(s, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e0cd9-68a1-4cfa-8b54-005f32597cf6",
   "metadata": {},
   "source": [
    "## Guessing Game with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35683e2-2198-4ce2-a5b0-9c32cae8cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings, ChatNVIDIA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69997fd4-e491-499f-a76f-4e086fcff5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_statics.py:313: UserWarning: Model mistral_7b is deprecated. Using mistralai/mistral-7b-instruct-v0.2 instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ChatNVIDIA(model=\"mistral_7b\",\n",
    "                   api_key = \"XXXXX\",\n",
    "                   stop=['\\n', \"\\n\", \"Human\", \"Stop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "288006f9-35ab-40ea-b6ed-36312ff73444",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"The following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
    "\n",
    "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
    "\n",
    "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
    "\n",
    "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
    "\n",
    "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
    "\n",
    "Format your response as:\n",
    "\n",
    "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
    "\n",
    "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
    "\n",
    "Example:\n",
    "\n",
    "Iteration 0:\n",
    "Human: Guess a number between 0 and 20\n",
    "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
    "\n",
    "Iteration 1:\n",
    "Human: the number is > 8\n",
    "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
    "\n",
    "Iteration 2\n",
    "Human: the number is < 15\n",
    "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
    "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "\n",
    "Human: {input}\n",
    "BRAD:\"\"\"\n",
    "\n",
    "# Ensure PROMPT object uses the new template\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "memory = ConversationBufferMemory(ai_prefix=\"BRAD\")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    prompt=PROMPT,\n",
    "    llm=model,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e551b8-763c-4c8b-b42c-adf4e19c9727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
      "\n",
      "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
      "\n",
      "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
      "\n",
      "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
      "\n",
      "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
      "\n",
      "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
      "\n",
      "Example:\n",
      "\n",
      "Iteration 0:\n",
      "Human: Guess a number between 0 and 20\n",
      "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
      "\n",
      "Iteration 1:\n",
      "Human: the number is > 8\n",
      "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
      "\n",
      "Iteration 2\n",
      "Human: the number is < 15\n",
      "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
      "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "\n",
      "Human: Guess a number with a lower bound of 0 and upper bound 100.\n",
      "BRAD:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The upper bound is 100 and lower bound is 0. My guess is 50 and 0 < 50 < 100.\n",
      "Stop.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Guess a number with a lower bound of 0 and upper bound 100.\"\n",
    "response = conversation.predict(input=user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afad92cf-5cb5-4f0f-a81e-f4c751cda155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
      "\n",
      "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
      "\n",
      "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
      "\n",
      "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
      "\n",
      "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
      "\n",
      "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
      "\n",
      "Example:\n",
      "\n",
      "Iteration 0:\n",
      "Human: Guess a number between 0 and 20\n",
      "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
      "\n",
      "Iteration 1:\n",
      "Human: the number is > 8\n",
      "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
      "\n",
      "Iteration 2\n",
      "Human: the number is < 15\n",
      "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
      "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
      "\n",
      "Current conversation:\n",
      "Human: Guess a number with a lower bound of 0 and upper bound 100.\n",
      "BRAD:  The upper bound is 100 and lower bound is 0. My guess is 50 and 0 < 50 < 100.\n",
      "Stop.\n",
      "\n",
      "Human: The number is < 50. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The upper bound is 50 and lower bound is 0. My guess is 25 and 0 < 25 < 50.\n",
      "Stop.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The number is < 50. Give the next iteration and stop the response at the word Stop\"\n",
    "response = conversation.predict(input=user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d83f1d1b-1064-4e6b-8688-d13f4ad47711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
      "\n",
      "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
      "\n",
      "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
      "\n",
      "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
      "\n",
      "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
      "\n",
      "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
      "\n",
      "Example:\n",
      "\n",
      "Iteration 0:\n",
      "Human: Guess a number between 0 and 20\n",
      "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
      "\n",
      "Iteration 1:\n",
      "Human: the number is > 8\n",
      "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
      "\n",
      "Iteration 2\n",
      "Human: the number is < 15\n",
      "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
      "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
      "\n",
      "Current conversation:\n",
      "Human: Guess a number with a lower bound of 0 and upper bound 100.\n",
      "BRAD:  The upper bound is 100 and lower bound is 0. My guess is 50 and 0 < 50 < 100.\n",
      "Stop.\n",
      "Human: The number is < 50. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 0. My guess is 25 and 0 < 25 < 50.\n",
      "Stop.\n",
      "\n",
      "Human: The number is > 25. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The upper bound is 50 and lower bound is 25. My guess is 38 and 25 < 38 < 50.\n",
      "Stop.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The number is > 25. Give the next iteration and stop the response at the word Stop\"\n",
    "response = conversation.predict(input=user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54a8d02e-8eaf-4eec-b1b5-6a861e195e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
      "\n",
      "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
      "\n",
      "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
      "\n",
      "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
      "\n",
      "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
      "\n",
      "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
      "\n",
      "Example:\n",
      "\n",
      "Iteration 0:\n",
      "Human: Guess a number between 0 and 20\n",
      "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
      "\n",
      "Iteration 1:\n",
      "Human: the number is > 8\n",
      "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
      "\n",
      "Iteration 2\n",
      "Human: the number is < 15\n",
      "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
      "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
      "\n",
      "Current conversation:\n",
      "Human: Guess a number with a lower bound of 0 and upper bound 100.\n",
      "BRAD:  The upper bound is 100 and lower bound is 0. My guess is 50 and 0 < 50 < 100.\n",
      "Stop.\n",
      "Human: The number is < 50. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 0. My guess is 25 and 0 < 25 < 50.\n",
      "Stop.\n",
      "Human: The number is > 25. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 25. My guess is 38 and 25 < 38 < 50.\n",
      "Stop.\n",
      "\n",
      "Human: The number is > 38. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The upper bound is 50 and lower bound is 38. My guess is 45 and 38 < 45 < 50.\n",
      "Stop.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The number is > 38. Give the next iteration and stop the response at the word Stop\"\n",
    "response = conversation.predict(input=user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68339203-65d3-4957-976d-f26cfe5704d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
      "\n",
      "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
      "\n",
      "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
      "\n",
      "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
      "\n",
      "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
      "\n",
      "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
      "\n",
      "Example:\n",
      "\n",
      "Iteration 0:\n",
      "Human: Guess a number between 0 and 20\n",
      "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
      "\n",
      "Iteration 1:\n",
      "Human: the number is > 8\n",
      "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
      "\n",
      "Iteration 2\n",
      "Human: the number is < 15\n",
      "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
      "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
      "\n",
      "Current conversation:\n",
      "Human: Guess a number with a lower bound of 0 and upper bound 100.\n",
      "BRAD:  The upper bound is 100 and lower bound is 0. My guess is 50 and 0 < 50 < 100.\n",
      "Stop.\n",
      "Human: The number is < 50. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 0. My guess is 25 and 0 < 25 < 50.\n",
      "Stop.\n",
      "Human: The number is > 25. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 25. My guess is 38 and 25 < 38 < 50.\n",
      "Stop.\n",
      "Human: The number is > 38. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 38. My guess is 45 and 38 < 45 < 50.\n",
      "Stop.\n",
      "\n",
      "Human: The number is < 45. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The upper bound is 45 and lower bound is 38. My guess is 42 and 38 < 42 < 45.\n",
      "Stop.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The number is < 45. Give the next iteration and stop the response at the word Stop\"\n",
    "response = conversation.predict(input=user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbc34137-82d4-4dea-b24c-a91d092bc6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
      "\n",
      "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
      "\n",
      "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
      "\n",
      "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
      "\n",
      "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
      "\n",
      "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
      "\n",
      "Example:\n",
      "\n",
      "Iteration 0:\n",
      "Human: Guess a number between 0 and 20\n",
      "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
      "\n",
      "Iteration 1:\n",
      "Human: the number is > 8\n",
      "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
      "\n",
      "Iteration 2\n",
      "Human: the number is < 15\n",
      "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
      "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
      "\n",
      "Current conversation:\n",
      "Human: Guess a number with a lower bound of 0 and upper bound 100.\n",
      "BRAD:  The upper bound is 100 and lower bound is 0. My guess is 50 and 0 < 50 < 100.\n",
      "Stop.\n",
      "Human: The number is < 50. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 0. My guess is 25 and 0 < 25 < 50.\n",
      "Stop.\n",
      "Human: The number is > 25. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 25. My guess is 38 and 25 < 38 < 50.\n",
      "Stop.\n",
      "Human: The number is > 38. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 38. My guess is 45 and 38 < 45 < 50.\n",
      "Stop.\n",
      "Human: The number is < 45. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 45 and lower bound is 38. My guess is 42 and 38 < 42 < 45.\n",
      "Stop.\n",
      "\n",
      "Human: The number is < 42. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The upper bound is 45 and lower bound is 38. My guess is 40 and 38 < 40 < 45.\n",
      "Stop.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The number is < 42. Give the next iteration and stop the response at the word Stop\"\n",
    "response = conversation.predict(input=user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "602fd68e-1d36-4023-b52b-db7fbe269fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
      "\n",
      "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
      "\n",
      "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
      "\n",
      "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
      "\n",
      "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
      "\n",
      "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
      "\n",
      "Example:\n",
      "\n",
      "Iteration 0:\n",
      "Human: Guess a number between 0 and 20\n",
      "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
      "\n",
      "Iteration 1:\n",
      "Human: the number is > 8\n",
      "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
      "\n",
      "Iteration 2\n",
      "Human: the number is < 15\n",
      "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
      "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
      "\n",
      "Current conversation:\n",
      "Human: Guess a number with a lower bound of 0 and upper bound 100.\n",
      "BRAD:  The upper bound is 100 and lower bound is 0. My guess is 50 and 0 < 50 < 100.\n",
      "Stop.\n",
      "Human: The number is < 50. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 0. My guess is 25 and 0 < 25 < 50.\n",
      "Stop.\n",
      "Human: The number is > 25. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 25. My guess is 38 and 25 < 38 < 50.\n",
      "Stop.\n",
      "Human: The number is > 38. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 38. My guess is 45 and 38 < 45 < 50.\n",
      "Stop.\n",
      "Human: The number is < 45. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 45 and lower bound is 38. My guess is 42 and 38 < 42 < 45.\n",
      "Stop.\n",
      "Human: The number is < 42. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 45 and lower bound is 38. My guess is 40 and 38 < 40 < 45.\n",
      "Stop.\n",
      "\n",
      "Human: The number is > 40. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The upper bound is 45 and lower bound is 40. My guess is 43 and 40 < 43 < 45.\n",
      "Stop.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The number is > 40. Give the next iteration and stop the response at the word Stop\"\n",
    "response = conversation.predict(input=user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86270c29-2aee-4912-921f-4bce6d9f426b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a guessing game between you (BRAD) and a human. You guess an integer X between an upper and lower bound and the human will give information of higher > X, lower < X, or = X until you guess correctly. Each turn, use information from the human to update one of either your upper or lower bound for X. By updating your bounds over time, you will narrow the options for X.\n",
      "\n",
      "Use a binary search strategy. For instance, if we know X is between 0 and 10, guess in the middle 5, or if X is in between 5 and 10, guess in the middle 8.\n",
      "\n",
      "At each step, answer with your upper bound for X, your lower bound for X, and your guess for X.\n",
      "\n",
      "You want to use the lowest upper bound and the highest lower bound. These bounds can be found in the chat history where z < x or x > z indicates z is a lower bound for x and x is an upper bound for z.\n",
      "\n",
      "**Important:** Only provide your output in the specified format below. Do not continue the conversation beyond this format.\n",
      "\n",
      "Format your response as:\n",
      "\n",
      "\"The upper bound is (Y) and lower bound is (Z). My guess is (X) and (Z) < (X) < (Y). Stop\"\n",
      "\n",
      "Do not continue generating any code after the word \"Stop\". There will be multiple iterations but you only create the response one time per iteration.\n",
      "\n",
      "Example:\n",
      "\n",
      "Iteration 0:\n",
      "Human: Guess a number between 0 and 20\n",
      "System: The upper bound is 20 and lower bound is 0. My guess is 8 and 0 < 8 < 20\n",
      "\n",
      "Iteration 1:\n",
      "Human: the number is > 8\n",
      "System: The upper bound is 20 and lower bound is 8. My guess is 15 and 8 < 15 < 20\n",
      "\n",
      "Iteration 2\n",
      "Human: the number is < 15\n",
      "System: The upper bound is 15 and lower bound is 8. My guess is 12 and 8 < 12 < 15\n",
      "END EXAMPLE. The numbers above are just for a workflow. Do not base your guesses on these\n",
      "\n",
      "Current conversation:\n",
      "Human: Guess a number with a lower bound of 0 and upper bound 100.\n",
      "BRAD:  The upper bound is 100 and lower bound is 0. My guess is 50 and 0 < 50 < 100.\n",
      "Stop.\n",
      "Human: The number is < 50. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 0. My guess is 25 and 0 < 25 < 50.\n",
      "Stop.\n",
      "Human: The number is > 25. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 25. My guess is 38 and 25 < 38 < 50.\n",
      "Stop.\n",
      "Human: The number is > 38. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 50 and lower bound is 38. My guess is 45 and 38 < 45 < 50.\n",
      "Stop.\n",
      "Human: The number is < 45. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 45 and lower bound is 38. My guess is 42 and 38 < 42 < 45.\n",
      "Stop.\n",
      "Human: The number is < 42. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 45 and lower bound is 38. My guess is 40 and 38 < 40 < 45.\n",
      "Stop.\n",
      "Human: The number is > 40. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:  The upper bound is 45 and lower bound is 40. My guess is 43 and 40 < 43 < 45.\n",
      "Stop.\n",
      "\n",
      "Human: The number is < 43. Give the next iteration and stop the response at the word Stop\n",
      "BRAD:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The upper bound is 43 and lower bound is 40. My guess is 41 and 40 < 41 < 43.\n",
      "Stop.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"The number is < 43. Give the next iteration and stop the response at the word Stop\"\n",
    "response = conversation.predict(input=user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b17c7-56f9-4024-836f-464348218f8e",
   "metadata": {},
   "source": [
    "## NVIDIA with BRAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d8570-4b70-4d6c-9b01-072fb3ad1e4c",
   "metadata": {},
   "source": [
    "### LLM + Searching for New Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b36abf13-d0b6-4d57-bb5c-5034923c3a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_statics.py:313: UserWarning: Model mistral_7b is deprecated. Using mistralai/mistral-7b-instruct-v0.2 instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from BRAD import llms\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = llms.load_nvidia()\n",
    "memory = ConversationBufferMemory(ai_prefix=\"BRAD\")\n",
    "\n",
    "template = \"\"\"Current conversation:\\n{history}\n",
    "\n",
    "Query:{input}\n",
    "\n",
    "From the query, decide if ARXIV, PUBMED, or BIORXIV should be searched, and propose no more than 10 words for this query and database.\n",
    "\n",
    "Database: <ARXIV, PUBMED, or BIORXIV>\n",
    "Search Terms: <improved search terms>\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation = ConversationChain(prompt  = PROMPT,\n",
    "                                 llm     = llm,\n",
    "                                 verbose = True,\n",
    "                                 memory  = memory,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ead26ac-237f-49aa-a875-2799d8c01f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mCurrent conversation:\n",
      "\n",
      "\n",
      "Query:What is the latest work in transcription factor control of the cell cycle?\n",
      "\n",
      "From the query, decide if ARXIV, PUBMED, or BIORXIV should be searched, and propose no more than 10 words for this query and database.\n",
      "\n",
      "Database: <ARXIV, PUBMED, or BIORXIV>\n",
      "Search Terms: <improved search terms>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Database: PUBMED\n",
      "Search Terms: Transcription factors, Cell cycle regulation, Latest findings.\n",
      "\n",
      "You can also add specific transcription factors or cell types for more precise results. For example, \"Myc transcription factor and cell cycle regulation\" or \"Transcription factor role in G2 checkpoint in human cells\".\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the latest work in transcription factor control of the cell cycle?\"\n",
    "response = conversation.predict(input=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "159a20a7-4841-4dc8-b9c6-fdc76392b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mCurrent conversation:\n",
      "Human: What is the latest work in transcription factor control of the cell cycle?\n",
      "BRAD:  Database: PUBMED\n",
      "Search Terms: Transcription factors, Cell cycle regulation, Latest findings.\n",
      "\n",
      "You can also add specific transcription factors or cell types for more precise results. For example, \"Myc transcription factor and cell cycle regulation\" or \"Transcription factor role in G2 checkpoint in human cells\".\n",
      "\n",
      "Query:list the most recent unpublished work on BIORXIV for reprogramming\n",
      "\n",
      "From the query, decide if ARXIV, PUBMED, or BIORXIV should be searched, and propose no more than 10 words for this query and database.\n",
      "\n",
      "Database: <ARXIV, PUBMED, or BIORXIV>\n",
      "Search Terms: <improved search terms>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Database: BIORXIV\n",
      "Search Terms: Reprogramming, Latest findings, Unpublished work.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"list the most recent unpublished work on BIORXIV for reprogramming\"\n",
    "response = conversation.predict(input=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3efd3bb-906e-43d5-9fef-4db779f71941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mCurrent conversation:\n",
      "Human: What is the latest work in transcription factor control of the cell cycle?\n",
      "BRAD:  Database: PUBMED\n",
      "Search Terms: Transcription factors, Cell cycle regulation, Latest findings.\n",
      "\n",
      "You can also add specific transcription factors or cell types for more precise results. For example, \"Myc transcription factor and cell cycle regulation\" or \"Transcription factor role in G2 checkpoint in human cells\".\n",
      "Human: list the most recent unpublished work on BIORXIV for reprogramming\n",
      "BRAD:  Database: BIORXIV\n",
      "Search Terms: Reprogramming, Latest findings, Unpublished work.\n",
      "\n",
      "Query:What is the latest work in bifurcation detection on manifolds?\n",
      "\n",
      "From the query, decide if ARXIV, PUBMED, or BIORXIV should be searched, and propose no more than 10 words for this query and database.\n",
      "\n",
      "Database: <ARXIV, PUBMED, or BIORXIV>\n",
      "Search Terms: <improved search terms>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Database: ARXIV\n",
      "Search Terms: Bifurcation detection, Manifolds, Latest preprints.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the latest work in bifurcation detection on manifolds?\"\n",
    "response = conversation.predict(input=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad63d566-bd88-4931-82f1-20230718303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'database': 'ARXIV', 'search_terms': ['Bifurcation detection', 'Manifolds', 'Latest preprints']}\n"
     ]
    }
   ],
   "source": [
    "def parse_llm_response(response):\n",
    "    \"\"\"\n",
    "    Parses the LLM response to extract the database name and search terms.\n",
    "    \n",
    "    Parameters:\n",
    "    response (str): The response from the LLM.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary with the database name and a list of search terms.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to hold the parsed data\n",
    "    parsed_data = {}\n",
    "\n",
    "    # Split the response into lines\n",
    "    lines = response.strip().split('\\n')\n",
    "\n",
    "    # Extract the database name\n",
    "    database_line = lines[0].replace(\"Database:\", \"\").strip()\n",
    "    parsed_data[\"database\"] = database_line\n",
    "\n",
    "    # Extract the search terms\n",
    "    search_terms_line = lines[1].replace(\"Search Terms:\", \"\").strip()\n",
    "    search_terms = [term.strip() for term in search_terms_line.split(',')]\n",
    "    parsed_data[\"search_terms\"] = search_terms\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "# Example LLM response\n",
    "llm_response = \"\"\"\n",
    "Database: ARXIV\n",
    "Search Terms: Bifurcation detection, Manifolds, Latest preprints\n",
    "\"\"\"\n",
    "\n",
    "# Parse the LLM response\n",
    "parsed_response = parse_llm_response(llm_response)\n",
    "print(parsed_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb9bf7-515e-48d3-bfdd-0129a635bade",
   "metadata": {},
   "source": [
    "### LLM + Gene Ontology + Enrichr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836ad9d6-fc8b-40c1-8993-dbcd5ea0dc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jpic/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jpic/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jpic/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your NVIDIA API key:  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/langchain_nvidia_ai_endpoints/_statics.py:313: UserWarning: Model mistral_7b is deprecated. Using mistralai/mistral-7b-instruct-v0.2 instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from BRAD import llms\n",
    "llm = llms.load_nvidia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f93a2d-f66a-4162-8950-e7c57964aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680b4732-480e-4e26-9fdf-cd92b57d5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(ai_prefix=\"BRAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "755e57cf-574a-4d83-a9be-b30c6894606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "template = \"\"\"Current conversation:\\n{history}\\n\\n\\nNew You are an expert in bioinformatics. A user has provided the following query related to their dataset. Query:\\n{input}\n",
    "\n",
    "Please determine which database (Enrichr or Gene Ontology) is most suitable for this query and list the relevant genes from the dataset. Provide your response in the following format:\n",
    "\n",
    "Database: [Database name]\n",
    "Relevant Genes: [List of relevant genes]\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation = ConversationChain(prompt  = PROMPT,\n",
    "                                 llm     = llm,\n",
    "                                 verbose = True,\n",
    "                                 memory  = memory,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff234811-3cb8-4399-b6b4-292e65ab79de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mCurrent conversation:\n",
      "Human: Look up MYOD, MYC, cMYC, and PCNA in gene ontology\n",
      "BRAD:  I'd be happy to help you look up information about the genes MYOD, MYC, cMYC, and PCNA in the Gene Ontology (GO). The Gene Ontology is a standardized database used to unify the representation of gene and gene product functions across all organisms.\n",
      "\n",
      "Let's look up each gene one by one to understand their functions in the context of the biological process, molecular function, and cellular component categories in the Gene Ontology:\n",
      "\n",
      "1. MYOD:\n",
      "Myod is a gene that encodes the myoblast determination protein 1 (MYOD1). MYOD1 is a transcription factor that plays a critical role in the differentiation of muscle cells. In the Gene Ontology, MYOD1 is associated with several biological processes such as muscle cell differentiation, muscle cell development, and muscle cell proliferation. At the molecular function level, it interacts with DNA as a transcription regulator, and at the cellular component level, it is mainly involved in the nucleus.\n",
      "\n",
      "2. MYC:\n",
      "The MYC gene encodes a family of transcription factors called the MYC proteins (MYC, MYCN, and MYCL1), which are involved in cell proliferation, differentiation, and apoptosis (programmed cell death). The functions of MYC proteins in the Gene Ontology include DNA binding, transcription factor activity, and involvement in cell cycle, cell growth, and development. They can be found in the nucleus and involved in chromatin organization and nucleosome organization.\n",
      "\n",
      "3. cMYC:\n",
      "cMYC refers to the constant isoform of the MYC protein. It is involved in various cellular processes, including cell growth, metabolism, cell differentiation, and programmed cell death. cMYC participates in a wide scope of biological processes in the Gene Ontology, ranging from cellular mitosis, cellular response to stress, and cellular response to hormones. At the molecular function level, it interacts with DNA, acts as a transcription factor, and stimulates growth or multiplication. In terms of cellular components, it is mainly involved in the nucleus and nucleoplasm.\n",
      "\n",
      "4. PCNA:\n",
      "PCNA (Proliferating Cell Nuclear Antigen) is a protein involved in replication and DNA repair processes. Specifically, it acts as a processivity factor, allowing DNA polymerase to maintain a high rate of DNA synthesis while moving along the template. In the Gene Ontology, PCNA is associated with a variety of biological processes related to cellular processes such as DNA-templated synthesis, DNA repair, and chromosome organization. It functions primarily at the molecular level, where it acts as a nucleotide binding, DNA binding, and single-stranded DNA binding protein. At the cellular component level, it is mainly located in the nucleus and interacts with the chromatin and nuclear matrix.\n",
      "\n",
      "These are just some of the Gene Ontology terms associated with the given genes. For a more detailed analysis, you can visit the official Gene Ontology website (<https://www.geneontology.org>) and explore each gene's entry using their IDs (MYOD: GO:0045116, MYC: GO:0005757, cMYC: GO:0051232, and PCNA: GO:0006260). Check out theassociated ontologiesandtheirrelatedterms to deepen your understanding of their role in biological processes.\n",
      "\n",
      "\n",
      "New You are an expert in bioinformatics. A user has provided the following query related to their dataset. Query:\n",
      "Look up MYOD, MYC, cMYC, and PCNA in gene ontology\n",
      "\n",
      "Please determine which database (Enrichr or Gene Ontology) is most suitable for this query and list the relevant genes from the dataset. Provide your response in the following format:\n",
      "\n",
      "Database: [Database name]\n",
      "Relevant Genes: [List of relevant genes]\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Database: Gene Ontology (GO)\n",
      "Relevant Genes: MYOD (GO:0045116), MYC (GO:0005757 and its isoforms: MYCN, MYCL1), cMYC (GO:0051232), and PCNA (GO:0006260)\n",
      "\n",
      "Explanation:\n",
      "The user's query asks for the gene ontology terms related to MYOD, MYC, cMYC, and PCNA genes. Gene Ontology (GO) is an appropriate database for this query since it is a standardized database used to unify the representation of gene and gene product functions across all organisms. The Gene Ontology database provides curated functional annotations for these genes in the context of biological processes, molecular functions, and cellular components.\n",
      "\n",
      "To further explore the data, users can visit the Gene Ontology website (<https://www.geneontology.org/>) and search for each gene using their respective official GO IDs (provided above) to examine their associated ontologies and related terms in detail. This information will deepen the understanding of the role of these genes in biological processes at a finer level.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Look up MYOD, MYC, cMYC, and PCNA in gene ontology\"\n",
    "response = conversation.predict(input=prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71e5359-8a9a-4af1-8cef-54837fdbc3ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ConversationChain\n__root__\n  Got unexpected prompt input variables. The prompt expects ['history', 'user_query'], but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationChain\n\u001b[1;32m      2\u001b[0m PROMPT \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m      3\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_query\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m conversation \u001b[38;5;241m=\u001b[39m \u001b[43mConversationChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m response \u001b[38;5;241m=\u001b[39m conversation\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mprompt)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:183\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     emit_warning()\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ConversationChain\n__root__\n  Got unexpected prompt input variables. The prompt expects ['history', 'user_query'], but got ['history'] as inputs from memory, and input as the normal input key. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=['user_query', 'history'],\n",
    "    template=\"\"\"\n",
    "    History: {history}\n",
    "    \n",
    "    You are an expert in bioinformatics. A user has provided the following query related to their dataset:\n",
    "\n",
    "    Query: {user_query}\n",
    "\n",
    "    Please determine which database (Enrichr or Gene Ontology) is most suitable for this query and list the relevant genes from the dataset. Provide your response in the following format:\n",
    "\n",
    "    Database: [Database name]\n",
    "    Relevant Genes: [List of relevant genes]\n",
    "    \"\"\"\n",
    ")\n",
    "conversation = ConversationChain(prompt  = PROMPT,\n",
    "                                 llm     = llm,\n",
    "                                 verbose = True,\n",
    "                                 memory  = memory\n",
    "                                )\n",
    "response = conversation.predict(input=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc45294-5125-45cb-9ff8-7ca2348c388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"user_query\"],\n",
    "    template=\"\"\"\n",
    "    You are an expert in bioinformatics. A user has provided the following query related to their dataset:\n",
    "\n",
    "    Query: {user_query}\n",
    "\n",
    "    Please determine which database (Enrichr or Gene Ontology) is most suitable for this query and list the relevant genes from the dataset. Provide your response in the following format:\n",
    "\n",
    "    Database: [Database name]\n",
    "    Relevant Genes: [List of relevant genes]\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725ddf68-75d9-4f6d-8667-feb3ac25f5aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nllm\n  Can't instantiate abstract class BaseLanguageModel with abstract methods agenerate_prompt, apredict, apredict_messages, generate_prompt, predict, predict_messages (type=type_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/load/serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for LLMChain\nllm\n  Can't instantiate abstract class BaseLanguageModel with abstract methods agenerate_prompt, apredict, apredict_messages, generate_prompt, predict, predict_messages (type=type_error)"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=prompt_template,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa2494a-67fe-4ae2-8e0c-2e4a202fea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9f3dc-b3d0-4200-8b8e-fb601dac3c79",
   "metadata": {},
   "source": [
    "### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcca75b-a891-408d-b889-f2abcde6f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jpic/RAG-DEV/BRAD/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f68bf39-c2d0-458f-869e-73b2a84e8005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import brad\n",
    "importlib.reload(brad)\n",
    "from brad import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14efc36e-050b-4911-9c03-01c6f21b9639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun Jun  2 17:32:27 2024 INFO Use pytorch device_name: cpu\n",
      "Sun Jun  2 17:32:27 2024 INFO Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "/home/jpic/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Sun Jun  2 17:32:28 2024 INFO Collection DB_cosine_cSize_700_cOver_200 is not created.\n"
     ]
    }
   ],
   "source": [
    "model_path            = '/nfs/turbo/umms-indikar/shared/projects/RAG/models/llama-2-7b-chat.Q2_K.gguf' # llama-2-7b-chat.Q8_0.gguf'\n",
    "persist_directory     = \"/nfs/turbo/umms-indikar/shared/projects/RAG/databases/Transcription-Factors-5-10-2024/\"\n",
    "llm, callback_manager = load_llama(nvidia_api_key = \"XXXXX\",\n",
    "                                   nvidia_model   = \"mistral_7b\",\n",
    "                                  )\n",
    "ragvectordb, embeddings_model = load_literature_db(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165687b1-b1a0-49c5-a590-e02600adeef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun Jun  2 17:32:30 2024 INFO local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to RAG! The chat log from this conversation will be saved to logs/RAG2024-06-02-17:32:30.549192.json. How can I help?\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  what role do transcription factors play in cell reprogramming?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun Jun  2 17:32:51 2024 INFO RAG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RAG >> 1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Transcription factors are key players in cell reprogramming. As suggested by the studies cited in the context, a subset of eukaryotic transcription factors has the ability to reprogram one type of cell into another by engaging genes that are developmentally silenced. These transcription factors are often crucial for the initial cell programming in embryonic development. For instance, OCT4, SOX2, and other factors are used to reprogram somatic cells into pluripotent stem cells (PSCs). Reprogramming involves a rapid chromatin switch, and context-specific transcription factor functions regulate epigenomic and transcriptional dynamics during this process. Differentiated cells can be reprogrammed towards various lineages, such as neurons or cardiac cells, by using specific sets of transcription factors. Overall, transcription factors orchestrate the dynamic interplay between genome topology and gene regulation during cell reprogramming.\n",
      "['']\n",
      "\n",
      " would you search Gene Ontology for these terms [Y/N]?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  list some of the most important genes/transcription factors involved in this process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun Jun  2 17:33:31 2024 INFO RAG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RAG >> 2:  The context provides information about transcription factors, their role in cellular identity, and their mode of action in gene expression. Transcription factors are proteins that bind to specific DNA sequences and control the expression of genes involved in establishing or maintaining cellular identity. They can do this by promoting or impeding the recruitment of cellular machineries necessary for gene transcription. The context also mentions that transcription factors can form dimers and bind to DNA sequences of around 10-15 nucleotides. However, there is uncertainty about how transcription factors find their specific sequences in the genome. The identification of the factors and signaling pathways that regulate the expression and activity of transcription factors in wound healing is an important task, as well as identifying their target genes in different cell types of the healing skin. Some examples of transcription factors and genes involved in wound healing include PPARβ/δ, regulated by proinflammatory cytokines, SAPKs, and AP-1, but repressed by the TGF-β–Smad3 pathway. However, the text does not provide a comprehensive list of all the most important genes/transcription factors involved in this process.\n",
      "['']\n",
      "\n",
      " would you search Gene Ontology for these terms [Y/N]?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " N\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  list the most important transcription factors for reprogramming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sun Jun  2 17:33:59 2024 INFO RAG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RAG >> 3:  The reprogramming factors are a subset of eukaryotic transcription factors that have the ability to reprogram one type of cell into another. These factors are crucial for initial cell programming in embryonic development. examples of such factors include MYOD for fibroblast to myoblast conversion, GATA1 for myeloblast, and CEBP for B lymphocyte. The identification of these candidate reprogramming factors was based on the fact that genes that contribute to the identities of fertilized eggs or ES cells were thought to be responsible for the reconstitution of specific transcriptional networks during reprogramming. The seminal work leading to the discovery of these factors and their use for the generation of the first iPPS (induced pluripotent stem cells) was described in the article \"Induction of pluripotency: a status report\" by Soufi et al. (2006). Other references, such as Spitz and Furlong (2012), Stormo and Zhao (2010), and Stubbs et al. (2011), provide additional information on transcription factor-mediated reprogramming.\n",
      "['', 'MYOD', 'GATA1', 'WAS', 'WAS']\n",
      "\n",
      " would you search Gene Ontology for these terms [Y/N]?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Y\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gonto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main(llm\u001b[38;5;241m=\u001b[39mllm, ragvectordb\u001b[38;5;241m=\u001b[39mragvectordb, embeddings_model\u001b[38;5;241m=\u001b[39membeddings_model)\n",
      "File \u001b[0;32m~/RAG-DEV/BRAD/brad.py:262\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model_path, persist_directory, llm, ragvectordb, embeddings_model)\u001b[0m\n\u001b[1;32m    259\u001b[0m module \u001b[38;5;241m=\u001b[39m module_functions[routeName]\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Query database\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m chatstatus \u001b[38;5;241m=\u001b[39m module(chatstatus)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Log and reset these values\u001b[39;00m\n\u001b[1;32m    265\u001b[0m chatlog, chatstatus \u001b[38;5;241m=\u001b[39m logger(chatlog, chatstatus, chatname)\n",
      "File \u001b[0;32m~/RAG-DEV/BRAD/rag.py:50\u001b[0m, in \u001b[0;36mqueryDocs\u001b[0;34m(chatstatus)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# update and return the chatstatus\u001b[39;00m\n\u001b[1;32m     49\u001b[0m chatstatus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m], chatstatus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m'\u001b[39m], res\n\u001b[0;32m---> 50\u001b[0m chatstatus \u001b[38;5;241m=\u001b[39m geneOntology(chatstatus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m], chatstatus)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chatstatus\n",
      "File \u001b[0;32m~/RAG-DEV/BRAD/gene_ontology.py:27\u001b[0m, in \u001b[0;36mgeneOntology\u001b[0;34m(goQuery, chatstatus)\u001b[0m\n\u001b[1;32m     25\u001b[0m     chatstatus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (go \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m go \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         go_process \u001b[38;5;241m=\u001b[39m gonto\u001b[38;5;241m.\u001b[39mgoSearch(real_list)\n\u001b[1;32m     28\u001b[0m         chatstatus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGO\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m go_process\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chatstatus\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gonto' is not defined"
     ]
    }
   ],
   "source": [
    "main(llm=llm, ragvectordb=ragvectordb, embeddings_model=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65d0f84-97a0-4f37-b907-f5cd53efd3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_llama in module chatbot:\n",
      "\n",
      "load_llama(model_path='/nfs/turbo/umms-indikar/shared/projects/RAG/models/llama-2-7b-chat.Q8_0.gguf', nvidia_api_key=None, nvidia_model=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bae4f7-5160-45bd-91d0-268ec02bc9ca",
   "metadata": {},
   "source": [
    "### Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0234983-8d07-402a-bfd3-cb2ac98f1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings, ChatNVIDIA\n",
    "import importlib\n",
    "import chatbot\n",
    "importlib.reload(chatbot)\n",
    "from chatbot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf026a3-f378-4786-a044-c3426e2a0751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sat 01 Jun 2024 02:38:03 PM EDT INFO Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Sat 01 Jun 2024 02:38:04 PM EDT INFO Use pytorch device_name: cpu\n",
      "Sat 01 Jun 2024 02:38:04 PM EDT INFO Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Sat 01 Jun 2024 02:38:04 PM EDT INFO Collection DB_cosine_cSize_700_cOver_200 is not created.\n"
     ]
    }
   ],
   "source": [
    "persist_directory     = \"/nfs/turbo/umms-indikar/shared/projects/RAG/databases/Transcription-Factors-5-10-2024/\"\n",
    "ragvectordb, embeddings_model = load_literature_db(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8e8ecdc-da82-48d7-a3f9-b3c7800a23bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatNVIDIA(model   = \"mistral_7b\",\n",
    "                   api_key = \"XXXXX\",\n",
    "                  )\n",
    "#                   stop=['\\n', \"\\n\", \"Human\", \"Stop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a696e631-f403-4903-850c-f23b47e84cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"how can transcription factors help reprogramming?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe17a61-eb76-4605-8bed-7d264e620a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# query to database\n",
    "documentSearch = ragvectordb.similarity_search_with_relevance_scores(prompt)\n",
    "docs, scores = getDocumentSimilarity(documentSearch)\n",
    "\n",
    "# pass the database output to the llm\n",
    "chain = load_qa_chain(model, chain_type=\"stuff\")\n",
    "res = chain({\"input_documents\": docs, \"question\": prompt})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beeefa75-b7ac-4b02-b544-99284509ccfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Transcription factors are crucial for the initial cell programming during embryonic development and play a key role in cell reprogramming by engaging genes that are developmentally silenced. In the context of the provided text, the specific transcription factors identified for their ability to reprogram somatic cells into pluripotent stem cells include OCT4, SOX2, and other factors. These factors were discovered through seminal work that led to the generation of the first induced pluripotent stem cells (iPSCs), as described in the article. The process of identifying these factors was based on the assumption that genes responsible for the identities of fertilized eggs or ES cells would contribute to the reconstitution of specific transcriptional networks during reprogramming.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['output_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
