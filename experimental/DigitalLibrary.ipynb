{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a0bdb3e-9085-4837-bd9b-f9f4a9124e7d",
   "metadata": {},
   "source": [
    "# Digital Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75033712-e260-49d1-a22e-f579ef888dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70802659-b69d-4024-b417-6299de737855",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsPath='/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/'\n",
    "dbName='DigitalLibrary'\n",
    "dbPath='/nfs/turbo/umms-indikar/shared/projects/RAG/databases/DigitalLibrary-10-June-2024/'\n",
    "HuggingFaceEmbeddingsModel = 'BAAI/bge-base-en-v1.5'\n",
    "chunk_size=[1000]\n",
    "chunck_overlap=[50]\n",
    "v=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f4b7b50-1817-4281-9f9c-154800fc8e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Work Directory: /home/jpic/RAG-DEV/experimental\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/jpic/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Documents loading from: /nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/\n"
     ]
    }
   ],
   "source": [
    "local = os.getcwd()  ## Get local dir\n",
    "os.chdir(local)      ## shift the work dir to local dir\n",
    "\n",
    "print('\\nWork Directory: {}'.format(local)) if v else None\n",
    "\n",
    "#%% Phase 1 - Load DB\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=HuggingFaceEmbeddingsModel)\n",
    "\n",
    "print('\\nDocuments loading from:', docsPath) if v else None\n",
    "\n",
    "text_loader_kwargs={'autodetect_encoding': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b88ae38-88ff-43ff-8a18-9ad5dc9c25a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/520 [00:01<05:37,  1.53it/s]Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "  7%|▋         | 38/520 [04:04<1:31:52, 11.44s/it]Ignoring wrong pointing object 0 0 (offset 0)\n",
      " 31%|███       | 161/520 [09:58<20:23,  3.41s/it]  Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 98 0 (offset 0)\n",
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 147 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 164 0 (offset 0)\n",
      "Ignoring wrong pointing object 186 0 (offset 0)\n",
      "Ignoring wrong pointing object 188 0 (offset 0)\n",
      "Ignoring wrong pointing object 197 0 (offset 0)\n",
      " 86%|████████▌ | 445/520 [21:58<02:10,  1.74s/it]  Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 14 65536 (offset 0)\n",
      "Ignoring wrong pointing object 35 65536 (offset 0)\n",
      "Ignoring wrong pointing object 55 65536 (offset 0)\n",
      "Ignoring wrong pointing object 69 65536 (offset 0)\n",
      "Ignoring wrong pointing object 81 65536 (offset 0)\n",
      "Ignoring wrong pointing object 95 65536 (offset 0)\n",
      "Ignoring wrong pointing object 107 65536 (offset 0)\n",
      "Ignoring wrong pointing object 123 65536 (offset 0)\n",
      "Ignoring wrong pointing object 141 65536 (offset 0)\n",
      "Ignoring wrong pointing object 157 65536 (offset 0)\n",
      "Ignoring wrong pointing object 169 65536 (offset 0)\n",
      "Ignoring wrong pointing object 185 65536 (offset 0)\n",
      "Ignoring wrong pointing object 207 65536 (offset 0)\n",
      "Ignoring wrong pointing object 221 65536 (offset 0)\n",
      "Ignoring wrong pointing object 233 65536 (offset 0)\n",
      "Ignoring wrong pointing object 247 65536 (offset 0)\n",
      " 89%|████████▉ | 462/520 [22:49<06:51,  7.09s/it]Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 14 65536 (offset 0)\n",
      "Ignoring wrong pointing object 43 65536 (offset 0)\n",
      "Ignoring wrong pointing object 61 65536 (offset 0)\n",
      "Ignoring wrong pointing object 79 65536 (offset 0)\n",
      "Ignoring wrong pointing object 97 65536 (offset 0)\n",
      "Ignoring wrong pointing object 115 65536 (offset 0)\n",
      "Ignoring wrong pointing object 135 65536 (offset 0)\n",
      "Ignoring wrong pointing object 151 65536 (offset 0)\n",
      "100%|██████████| 520/520 [24:31<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(docsPath,\n",
    "                         glob=\"**/*.pdf\",\n",
    "                         loader_cls=PyPDFLoader, \n",
    "                         #loader_kwargs=text_loader_kwargs,\n",
    "                         show_progress=True,\n",
    "                         )\n",
    "docs_data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fddb193-445e-4c2d-a6ca-3b9291fd2de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Documents: 62202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/nfs/turbo/umms-indikar/shared/projects/RAG/databases/DigitalLibrary-10-June-2024/DigitalLibrary/*’: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Chrom Call\n"
     ]
    }
   ],
   "source": [
    "chunk_size = [1000] #Chunk size \n",
    "chunk_overlap = [50] #Chunk overlap\n",
    "for i in range(len(chunk_size)):\n",
    "    for j in range(len(chunk_overlap)):\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size = chunk_size[i],\n",
    "                                                        chunk_overlap = chunk_overlap[j],\n",
    "                                                        separators=[\" \", \",\", \"\\n\", \". \"])\n",
    "        \n",
    "        data_splits = text_splitter.split_documents(docs_data)\n",
    "        print('Split Documents: ' + str(len(data_splits)))\n",
    "\n",
    "        p2_2 = subprocess.run('mkdir  %s/*'%(dbPath+dbName), shell=True)\n",
    "        _client_settings = chromadb.PersistentClient(path=(dbPath+dbName))\n",
    "\n",
    "        print('Beginning Chrom Call')\n",
    "        vectordb = Chroma.from_documents(documents           = data_splits,\n",
    "                                         embedding           = embeddings_model,\n",
    "                                         client              = _client_settings,\n",
    "                                         collection_name     = dbName,\n",
    "                                         collection_metadata = {\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "        print('Completed Chroma Database: ', dbName) if v else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515a7cd-3bd9-4209-af57-c331918bb289",
   "metadata": {},
   "source": [
    "# Load the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66a30b1-b725-4667-b085-fc5535f29986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/jpic/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "persist_directory = '/nfs/turbo/umms-indikar/shared/projects/RAG/databases/DigitalLibrary-10-June-2024/' # DigitalLibraryXXX' # '/nfs/turbo/umms-indikar/shared/projects/RAG/databases/DigitalLibrary-10-June-2024/DigitalLibrary/'\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name='BAAI/bge-base-en-v1.5')        # Embedding model\n",
    "db_name = \"DigitalLibrary\" # \"DB_cosine_cSize_%d_cOver_%d\" % (700, 200)\n",
    "_client_settings = chromadb.PersistentClient(path=(persist_directory + db_name))\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings_model, client=_client_settings, collection_name=db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ba79f-01ad-4642-b2cd-78715e401364",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search_with_relevance_scores('Remark on the differences between direct and indirect cell reprogramming', k=4)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76fa82de-1151-49d6-8216-b5b9420ffb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/turbo/umms-indikar/shared/projects/RAG/databases/DigitalLibrary-10-June-2024/DigitalLibraryDigitalLibrary'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42f7aebf-8763-4ad4-a941-1782dc2c0254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DB_cosine_cSize_700_cOver_200'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395a5c77-7965-4d49-86db-91189ab072a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mvectordb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:612\u001b[0m, in \u001b[0;36mChroma.get\u001b[0;34m(self, ids, where, limit, offset, where_document, include)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m include\n\u001b[0;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/chromadb/api/models/Collection.py:211\u001b[0m, in \u001b[0;36mCollection.get\u001b[0;34m(self, ids, where, limit, offset, where_document, include)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m include:\n\u001b[1;32m    209\u001b[0m     valid_include\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 211\u001b[0m get_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_where\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_where_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_include\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m get_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    226\u001b[0m ):\n\u001b[1;32m    227\u001b[0m     get_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader(get_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muris\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:143\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/chromadb/rate_limiting/__init__.py:45\u001b[0m, in \u001b[0;36mrate_limit.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Dict[Any, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# If not rate limiting provider is present, just run and return the function.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_system\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mchroma_rate_limiting_provider_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     48\u001b[0m         subject_value \u001b[38;5;241m=\u001b[39m kwargs[subject]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/chromadb/api/segment.py:517\u001b[0m, in \u001b[0;36mSegmentAPI._get\u001b[0;34m(self, collection_id, ids, where, sort, limit, offset, page, page_size, where_document, include)\u001b[0m\n\u001b[1;32m    514\u001b[0m     offset \u001b[38;5;241m=\u001b[39m (page \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m page_size\n\u001b[1;32m    515\u001b[0m     limit \u001b[38;5;241m=\u001b[39m page_size\n\u001b[0;32m--> 517\u001b[0m records \u001b[38;5;241m=\u001b[39m \u001b[43mmetadata_segment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(records) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;66;03m# Nothing to return if there are no records\u001b[39;00m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GetResult(\n\u001b[1;32m    528\u001b[0m         ids\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m    529\u001b[0m         embeddings\u001b[38;5;241m=\u001b[39m[] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m         data\u001b[38;5;241m=\u001b[39m[] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m include \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    534\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:143\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/chromadb/segment/impl/metadata/sqlite.py:216\u001b[0m, in \u001b[0;36mSqliteMetadataSegment.get_metadata\u001b[0;34m(self, where, where_document, ids, limit, offset)\u001b[0m\n\u001b[1;32m    212\u001b[0m     q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mwhere(embeddings_t\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39misin(embeddings_q))\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_db\u001b[38;5;241m.\u001b[39mtx() \u001b[38;5;28;01mas\u001b[39;00m cur:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# Execute the query with the limit and offset already applied\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/chromadb/segment/impl/metadata/sqlite.py:225\u001b[0m, in \u001b[0;36mSqliteMetadataSegment._records\u001b[0;34m(self, cur, q)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given a cursor and a QueryBuilder, yield a generator of records. Assumes\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mcursor returns rows in ID order.\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m sql, params \u001b[38;5;241m=\u001b[39m get_sql(q)\n\u001b[0;32m--> 225\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m cur_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(cur\u001b[38;5;241m.\u001b[39mfetchone, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    228\u001b[0m group_iterator \u001b[38;5;241m=\u001b[39m groupby(cur_iterator, \u001b[38;5;28;01mlambda\u001b[39;00m r: \u001b[38;5;28mint\u001b[39m(r[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "len(vectordb.get()['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3a3661-5763-42df-906f-e2c5ba556cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62202"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectordb.get()['ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d89287-21e6-4995-8daf-84343aa55d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='without transitioning through an intermediate pluripotent \\nor multi  potent state\\n3, has been described as ‘direct  \\nreprogramming’ , also known as ‘transdifferentiation’ .\\nIn addition to increasing our understanding of cell \\nfate specification and plasticity, direct reprogramming \\nholds promises for regenerative medicine. Compared to induced pluripotent stem cell (iPSC) reprogramming \\n(not the focus of this review, reviewed in \\nrefs4–7), direct \\nreprogramming is a faster and more efficient process and has unique advantages for tissue repair \\n(fig.\\xa0 1). Whereas \\nthe use of iPSCs6 requires the isolation of somatic cells \\nand their reprogramming to a pluripotent state fol-lowed by their differentiation into a different lineage,  in principle, direct reprogramming enables the con-\\nversion of cells in\\xa0situ (in the desired tissue) without \\ntransitioning through an intermediate pluripotent state \\nand without the need for ex vivo cell expansion and transplantation\\n8. Although direct', metadata={'page': 0, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Direct cell reprogramming.pdf'}),\n",
       "  0.8507865071296692),\n",
       " (Document(page_content='resulting cells were most similar in maturity to ones derived from\\npluripotent stem cells.\\nOverall, studies of direct conversion have identiﬁed many new\\ncombinations of factors that alter cell fate, including transcriptionfactors described above, chemicals ( Ladewig et al., 2012; Liu et\\nal., 2016 ), microRNAs ( Yoo et al., 2011 ), and combinations\\nthereof ( Wang et al., 2014 ), as well as single transcription factors\\nwith appropriate culture conditions ( Ring et al., 2012 ). The\\nvarious approaches share the common goal of making direct\\nconversion more experimentally tractable, robust, and safe.\\nBlood cells and other cell types have also been obtainedin vitro by direct conversion ( Batta et al., 2016; Szabo et al.,\\n2010; Xie et al., 2004 ). The studies discussed above point to\\nthe utility of in vitro direct reprogramming, particularly as it per-tains to cell-based therapies and disease modeling. Thus, within\\nless than a decade, in vitro reprogramming has become a rich\\nand vigorous ﬁeld,', metadata={'page': 3, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/In Vivo Cellular Reprogramming The Next Generation.pdf'}),\n",
       "  0.84769207239151),\n",
       " (Document(page_content='driving cell fate decisions. A major utility of direct\\nreprogramming is the potential of harnessing resident support cells within damaged organs to\\nregenerate lost tissue by converting them into the desired cell type in situ. Here, we review the prog-\\nress in direct cellular reprogramming, with a focus on the paradigm of in vivo reprogramming for\\nregenerative medicine, while pointing to hurdles that must be overcome to translate this technologyinto future therapeutics.\\nIntroduction\\nThe concept that differentiated cells are plastic and can be re-\\nprogrammed to alternate cell fates was ﬁrst suggested by thecloning experiments of Gurdon ( Gurdon et al., 1958 ) and later\\nWilmut ( Campbell et al., 1996 ). In these studies, undeﬁned fac-\\ntors in the oocyte cytoplasm were found to induce somatic cells\\nto assume an embryonic state. Embryonic and fetal develop-ment ensued, culminating in live births and surprisingly normal\\npostnatal development. This observation was the original form\\nof ‘‘in', metadata={'page': 0, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/In Vivo Cellular Reprogramming The Next Generation.pdf'}),\n",
       "  0.8463755249977112),\n",
       " (Document(page_content='et al. (2015) Direct lineage reprogramming: strategies, mechanisms, and\\napplications. Cell Stem Cell ,16, 119–134.2846 R.Eguchi et al.Downloaded from https://academic.oup.com/bioinformatics/article/38/10/2839/6567358 by University of Michigan user on 04 January 2023', metadata={'page': 7, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Eguchi et al. - 2022 - TRANSDIRE data-driven direct reprogramming by a p.pdf'}),\n",
       "  0.844811201095581)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vectordb.similarity_search_with_relevance_scores('Remark on the differences between direct and indirect cell reprogramming', k=4)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a9df3d4-6859-43bd-81dd-d3016710503c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='58 A Appendix: High-Accuracy Approximation Methods for General Binary-State. . .\\n“spin up” versus “spin down” magnetic dipoles in an Ising spin model, “inactive”\\nversus “active” nodes in a social system, and so on. We presented many examples of\\nbinary-state dynamics in Chapter 3. See, for example, our discussions of percolation\\nmodels in Sec. 3.1, biological contagions in Sec. 3.2, and social contagions in\\nSec.3.3.\\nIn the present section, we will consider asynchronous updating and local rules\\nfor node updates. In other words, the transition rates depend only on the state of\\na node and on the states of its immediate neighbors in a network. Consequently,\\nan updating node that is susceptible becomes infected with a probability of Fk;mdt,\\nwhere kis the node’s degree and mis the number of its neighbors that are infected.\\nWe refer to the function Fk;mas the infection rate . Similarly, an updating node that is\\ninfected becomes susceptible with a probability of Rk;mdt, and we refer to Rk;mas', metadata={'page': 69, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Dynamical Systems on Networks - A Tutorial.pdf'}),\n",
       "  0.44744348526000977),\n",
       " (Document(page_content='A.2 Approximation Methods for General Binary-State Dynamics 59\\neach time step, one node is chosen uniformly at random for updating (during the\\ninterval dtD1=N), and this node copies the state of one of its neighbors (chosen\\nuniformly at random). Therefore, a degree- knode that has minfected neighbors\\nhas probability m=kof copying an infected neighbor and probability .k/NULm/=kof\\ncopying a susceptible neighbor. This yields\\nFV oter\\nk;mDm=kand RV oter\\nk;mD.k/NULm/=k: (A.3)\\nWithin this general framework, one can consider a wide class of well-studied\\nbinary-state dynamics. Table I in Ref. [ 108] lists the infection rates Fk;mand\\nrecovery rates Rk;mfor models such as the Bass model for the spread of innovations\\n[20,77], the Ising spin model, the majority-vote model [ 67,190], and threshold\\nopinion models. This uniﬁed perspective on stochastic binary-state dynamics also\\nallows general derivations of mean-ﬁeld and pair approximations from a higher-\\norder approximation scheme.\\nA.2 Approximation', metadata={'page': 70, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Dynamical Systems on Networks - A Tutorial.pdf'}),\n",
       "  0.4467930197715759),\n",
       " (Document(page_content='considerations in Chapter 4followed part of the\\npresentation in this book, which also has thorough discussions of processes\\nlike percolation and biological contagions. Reference [ 228] also discusses the\\nuse of mean-ﬁeld theories and related techniques for studying such dynamical\\nprocesses, and we drew on some of those discussions for portions of our\\npresentation. In particular, in Sec. 4.3.1 , we largely followed the presentation in\\n[228].\\n• Reference [ 174] is a textbook on networks that takes a statistical perspective.\\nIt includes material on dynamical systems on networks.\\n• Two of the classical review articles in network science are [ 227] and [ 27]. How-\\never, because network science advances quickly, they are somewhat out of date.\\n• Reference [ 18] is a book devoted to dynamical systems on networks from a\\nphysics perspective.\\n• Reference [ 234] is a recent survey of spreading processes on networks from a\\ncontrol-theoretic perspective.\\n• The survey article [ 38] examines ﬂows on', metadata={'page': 64, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Dynamical Systems on Networks - A Tutorial.pdf'}),\n",
       "  0.442932665348053),\n",
       " (Document(page_content='Appendix A\\nAppendix: High-Accuracy Approximation\\nMethods for General Binary-State Dynamics\\nA.1 High-Accuracy Approximations for Binary-State\\nDynamics\\nTo illustrate some general concepts for how network structure affects dynamics,\\nlet’s examine a class of stochastic binary-state dynamics on conﬁguration-model\\nnetworks. Recall from Chapter 2that a network in a conﬁguration-model ensemble\\nis speciﬁed by a degree distribution Pkbut is otherwise maximally random [ 33,228].\\nPairs of stubs (i.e., ends of edges) are connected to each other uniformly at\\nrandom, so no degree–degree (or other) correlations are input, and taking theN!1 limit guarantees negligible clustering (if we assume, e.g., that the\\nsecond moment of P\\nkremains ﬁnite as N!1 ). In this section, we discuss a\\ngeneral class of binary-state dynamics and then examine approximation methodsat mean-ﬁeld, pair-approximation, and higher-order levels [ 218]. We choose to\\nfocus on approximations that yield deterministic systems in the form', metadata={'page': 68, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Dynamical Systems on Networks - A Tutorial.pdf'}),\n",
       "  0.4428536295890808),\n",
       " (Document(page_content='SeeRefs. [ 32,262] for examples of such an “equation-free” approach.\\n4.4 Additional Considerations\\nAs we discuss in Appendix A, there exist rather sophisticated approximation\\nmethods for binary-state dynamics on conﬁguration-model networks. Moreover, for\\nmonotonic binary dynamics, there has also been signiﬁcant progress in extendingtheories to networks with degree–degree correlations, clustering, modularity, and\\nmultilayer structures. Indeed, degree–degree correlations have been incorporated\\ninto many MF and PA methods.\\nHowever, despite this progress, much remains to be done. Moving beyond\\nbinary-state dynamics is a signiﬁcant challenge. There has been notable progress in\\nsome dynamical systems that include three states—particularly when the dynam-ics remains monotonic (i.e., transitions between states still occur only in one\\ndirection). Examples include the multi-stage complex contagion model of social\\ninﬂuence in Ref. [ 212] and high-accuracy approximations for SIR disease', metadata={'page': 58, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Dynamical Systems on Networks - A Tutorial.pdf'}),\n",
       "  0.4408687949180603),\n",
       " (Document(page_content='54 7 Other Resources\\n• Reference [ 270] is a review article on recent advances in percolation theory.\\n• Reference [ 242] is a recent, extensive review of contagions on networks. It\\nfocuses especially on biological contagions, but it also includes discussions ofother spreading processes.\\n• Reference [ 99] is a book about biological contagions on networks, although there\\nis also some discussion of the spread of information.\\n• Reference [ 218] is a review of contagions on networks that focuses on moment-\\nclosure methods and discusses the challenges of generalizing methods from\\nconﬁguration-model networks to more complicated random-graph ensembles.\\n• Reference [ 48] is a review of social dynamics from the perspective of statistical\\nphysics.\\n• Reference [ 156] is a survey about games on networks.\\n• Reference [ 8] reviews synchronization on networks, although there has been a\\nlot of work on this topic since it was published.\\n• Reference [ 192] is a recent review of control in networks, and', metadata={'page': 65, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Dynamical Systems on Networks - A Tutorial.pdf'}),\n",
       "  0.44044798612594604),\n",
       " (Document(page_content='(A.18)\\nand applying the identity\\nkX\\nmD1Bk;m./RS/Œ1/NUL.1/NULp/m/c141D1/NUL.1/NULp/RS/k: (A.19)\\nSee Sec. II.B of [ 106] for additional discussion.\\nA.3.3 Cascade Conditions\\nIn addition to giving very accurate predictions for monotonic dynamics,\\nEqs. ( A.9,A.10 ) make it possible to obtain analytical insights into dynamical\\nprocesses. Let’s again use the Watts threshold model as an example. Consider\\nthe question of whether, for a given distribution of thresholds, global cascadescan occur on conﬁguration-model networks with degree distribution P\\nk. Watts\\nused percolation theory in [ 328] to derive a cascade condition that addresses this\\nquestion. We will now derive the same cascade condition by using linear stabilityanalysis of the 2D dynamical system deﬁned by Eqs. ( A.9,A.10 ,A.16 ,A.17 ).\\nSuppose that all nodes have positive thresholds, so C.0/D0, and consider the\\nseed fraction /SUB.0/ to be vanishingly small. The system ( A.9,A.10 ) then has an\\nequilibrium point at ./SUB;/RS/ D.0;0/', metadata={'page': 75, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Dynamical Systems on Networks - A Tutorial.pdf'}),\n",
       "  0.4398994445800781),\n",
       " (Document(page_content='from a random-graph ensemble (i.e. a\\nprobability distribution on graphs). Some or all of these sources of randomness can be\\npresent when studying dynamical processes on networks. It is desirable to compare\\nthe sample mean of a stochastic process on a network to an ensemble average (i.e.\\nto an expectation over a suitable probability distribution).\\nProminent examples of stochastic processes on networks include percolation [ 96],\\nrandom walks [ 97], compartment models of biological contagions [ 77,78], bounded-\\nconﬁdence models of the dynamics of continuous-valued opinions [ 98], and other\\nopinion and voter models [ 11,79,80,99].\\n6.4.2.1 Example: A Compartmental Model of a Biological Contagion\\nCompartmental models of biological contagions are a topic of intense interest in\\nnetwork science [ 1,11,77,78]. A compartment represents a possible state of a\\nnode; examples include susceptible, infected, zombiﬁed, vaccinated, and recovered.\\nAn update rule determines how a node changes its state', metadata={'page': 10, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Nonlinearity + Networks A 2020 Vision.pdf'}),\n",
       "  0.43848490715026855),\n",
       " (Document(page_content='the spin of every atom can point either up or down. We model\\nthis by ann×ngridG=Gn×n(for simplicity, in two dimensions). If we assign\\nto every node of G(every “site”) a “state”, which can be UP or DOWN, we get\\na “conﬁguration”. The atoms are changing their spins randomly all the time, but\\nnot independently of each other: depending on the spins of adjacent atoms, one\\ndirection of the spin of an atom may be less likely then the other, or even entirely\\nimpossible. We would like to know how a typical conﬁguration looks like: is it\\nrandom-like as the ﬁrst picture in Figure 2.3, is it homogeneous as the second\\n(well, maybe with a few exceptions here and there), or is it structured in other\\nways, as the third?\\nFigure 2.3. Three conﬁgurations of the Ising model.\\nTwo atoms that are adjacent in the grid have an “interaction energy”, which\\ndepends on their states. In the simplest version of the basic Ising model, the\\ninteraction energy is some number −Jif the atoms are in the same state, and', metadata={'page': 43, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Large networks and graph limits.pdf'}),\n",
       "  0.4384419918060303),\n",
       " (Document(page_content='model, in which susceptible nodes can still transition to “going” infected,but infected nodes recover to a state Rin which they can no longer be infected [ 37].\\nFatalistic people might let state Rstand for “removed” instead of recovered, but\\nwe’re going to be more positive than that.\\nAs with an SIS process, two rates deﬁne the stochastic dynamics. These are the\\ntransmission rate /NAKand the recovery rate /SYN. They are both deﬁned as we described\\nabove for SIS dynamics, but now the recovery process takes nodes from the Istate\\nto the Rstate rather than returning them to the Sstate. Interestingly, one can relate\\nthe steady-state of the basic SIR model on a network to a bond-percolation process\\n[123]. See [ 132,170,306] for additional discussion of the connection between SIR\\ndynamics and bond percolation.\\n3.2.4 More Complicated Compartmental Models\\nThe contagion models that we have discussed above are interesting to study, andthey provide a nice family of tractable examples (including', metadata={'page': 24, 'source': '/nfs/turbo/umms-indikar/shared/projects/RAG/papers/DigitalLibrary-9-June-2024/Dynamical Systems on Networks - A Tutorial.pdf'}),\n",
       "  0.4378235340118408)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45ccf08e-d726-45c4-9d03-584939de3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Chroma in module langchain_community.vectorstores.chroma:\n",
      "\n",
      "class Chroma(langchain_core.vectorstores.VectorStore)\n",
      " |  Chroma(collection_name: 'str' = 'langchain', embedding_function: 'Optional[Embeddings]' = None, persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, collection_metadata: 'Optional[Dict]' = None, client: 'Optional[chromadb.Client]' = None, relevance_score_fn: 'Optional[Callable[[float], float]]' = None) -> 'None'\n",
      " |  \n",
      " |  `ChromaDB` vector store.\n",
      " |  \n",
      " |  To use, you should have the ``chromadb`` python package installed.\n",
      " |  \n",
      " |  Example:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |              from langchain_community.vectorstores import Chroma\n",
      " |              from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
      " |  \n",
      " |              embeddings = OpenAIEmbeddings()\n",
      " |              vectorstore = Chroma(\"langchain_store\", embeddings)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Chroma\n",
      " |      langchain_core.vectorstores.VectorStore\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, collection_name: 'str' = 'langchain', embedding_function: 'Optional[Embeddings]' = None, persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, collection_metadata: 'Optional[Dict]' = None, client: 'Optional[chromadb.Client]' = None, relevance_score_fn: 'Optional[Callable[[float], float]]' = None) -> 'None'\n",
      " |      Initialize with a Chroma client.\n",
      " |  \n",
      " |  __len__(self) -> 'int'\n",
      " |      Count the number of documents in the collection.\n",
      " |  \n",
      " |  add_images(self, uris: 'List[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more images through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          uris List[str]: File path to the image.\n",
      " |          metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
      " |          ids (Optional[List[str]], optional): Optional list of IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added images.\n",
      " |  \n",
      " |  add_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more texts through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts (Iterable[str]): Texts to add to the vectorstore.\n",
      " |          metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
      " |          ids (Optional[List[str]], optional): Optional list of IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  delete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'None'\n",
      " |      Delete by vector IDs.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to delete.\n",
      " |  \n",
      " |  delete_collection(self) -> 'None'\n",
      " |      Delete the collection.\n",
      " |  \n",
      " |  encode_image(self, uri: 'str') -> 'str'\n",
      " |      Get base64 string from image URI.\n",
      " |  \n",
      " |  get(self, ids: 'Optional[OneOrMany[ID]]' = None, where: 'Optional[Where]' = None, limit: 'Optional[int]' = None, offset: 'Optional[int]' = None, where_document: 'Optional[WhereDocument]' = None, include: 'Optional[List[str]]' = None) -> 'Dict[str, Any]'\n",
      " |      Gets the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: The ids of the embeddings to get. Optional.\n",
      " |          where: A Where type dict used to filter results by.\n",
      " |                 E.g. `{\"color\" : \"red\", \"price\": 4.20}`. Optional.\n",
      " |          limit: The number of documents to return. Optional.\n",
      " |          offset: The offset to start returning results from.\n",
      " |                  Useful for paging results with limit. Optional.\n",
      " |          where_document: A WhereDocument type dict used to filter by the documents.\n",
      " |                          E.g. `{$contains: \"hello\"}`. Optional.\n",
      " |          include: A list of what to include in the results.\n",
      " |                   Can contain `\"embeddings\"`, `\"metadatas\"`, `\"documents\"`.\n",
      " |                   Ids are always included.\n",
      " |                   Defaults to `[\"metadatas\", \"documents\"]`. Optional.\n",
      " |  \n",
      " |  max_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  max_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  persist(self) -> 'None'\n",
      " |      [*Deprecated*] Persist the collection.\n",
      " |      \n",
      " |      This can be used to explicitly persist the data to disk.\n",
      " |      It will also be called automatically when the object is destroyed.\n",
      " |      \n",
      " |      Since Chroma 0.4.x the manual persistence method is no longer\n",
      " |      supported as docs are automatically persisted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. deprecated:: langchain-community==0.1.17\n",
      " |         Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      " |  \n",
      " |  similarity_search(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Run similarity search with Chroma.\n",
      " |      \n",
      " |      Args:\n",
      " |          query (str): Query text to search for.\n",
      " |          k (int): Number of results to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Document]: List of documents most similar to the query text.\n",
      " |  \n",
      " |  similarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to embedding vector.\n",
      " |      Args:\n",
      " |          embedding (List[float]): Embedding to look up documents similar to.\n",
      " |          k (int): Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      Returns:\n",
      " |          List of Documents most similar to the query vector.\n",
      " |  \n",
      " |  similarity_search_by_vector_with_relevance_scores(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs most similar to embedding vector and similarity score.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding (List[float]): Embedding to look up documents similar to.\n",
      " |          k (int): Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Tuple[Document, float]]: List of documents most similar to\n",
      " |          the query text and cosine distance in float for each.\n",
      " |          Lower score represents more similarity.\n",
      " |  \n",
      " |  similarity_search_with_score(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Run similarity search with Chroma with distance.\n",
      " |      \n",
      " |      Args:\n",
      " |          query (str): Query text to search for.\n",
      " |          k (int): Number of results to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Tuple[Document, float]]: List of documents most similar to\n",
      " |          the query text and cosine distance in float for each.\n",
      " |          Lower score represents more similarity.\n",
      " |  \n",
      " |  update_document(self, document_id: 'str', document: 'Document') -> 'None'\n",
      " |      Update a document in the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          document_id (str): ID of the document to update.\n",
      " |          document (Document): Document to update.\n",
      " |  \n",
      " |  update_documents(self, ids: 'List[str]', documents: 'List[Document]') -> 'None'\n",
      " |      Update a document in the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids (List[str]): List of ids of the document to update.\n",
      " |          documents (List[Document]): List of documents to update.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_documents(documents: 'List[Document]', embedding: 'Optional[Embeddings]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.Client]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' from abc.ABCMeta\n",
      " |      Create a Chroma vectorstore from a list of documents.\n",
      " |      \n",
      " |      If a persist_directory is specified, the collection will be persisted there.\n",
      " |      Otherwise, the data will be ephemeral in-memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          collection_name (str): Name of the collection to create.\n",
      " |          persist_directory (Optional[str]): Directory to persist the collection.\n",
      " |          ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      " |          documents (List[Document]): List of documents to add to the vectorstore.\n",
      " |          embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      " |          client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      " |          collection_metadata (Optional[Dict]): Collection configurations.\n",
      " |                                                Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Chroma: Chroma vectorstore.\n",
      " |  \n",
      " |  from_texts(texts: 'List[str]', embedding: 'Optional[Embeddings]' = None, metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.Client]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' from abc.ABCMeta\n",
      " |      Create a Chroma vectorstore from a raw documents.\n",
      " |      \n",
      " |      If a persist_directory is specified, the collection will be persisted there.\n",
      " |      Otherwise, the data will be ephemeral in-memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts (List[str]): List of texts to add to the collection.\n",
      " |          collection_name (str): Name of the collection to create.\n",
      " |          persist_directory (Optional[str]): Directory to persist the collection.\n",
      " |          embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      " |          metadatas (Optional[List[dict]]): List of metadatas. Defaults to None.\n",
      " |          ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      " |          client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      " |          collection_metadata (Optional[Dict]): Collection configurations.\n",
      " |                                                Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Chroma: Chroma vectorstore.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  embeddings\n",
      " |      Access the query embedding object if available.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  async aadd_documents(self, documents: 'List[Document]', **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more documents through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents (List[Document]: Documents to add to the vectorstore.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  async aadd_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more texts through the embeddings and add to the vectorstore.\n",
      " |  \n",
      " |  add_documents(self, documents: 'List[Document]', **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more documents through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents (List[Document]: Documents to add to the vectorstore.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  async adelete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'Optional[bool]'\n",
      " |      Delete by vector ID or other criteria.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to delete.\n",
      " |          **kwargs: Other keyword arguments that subclasses might use.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Optional[bool]: True if deletion is successful,\n",
      " |          False otherwise, None if not implemented.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |  \n",
      " |  as_retriever(self, **kwargs: 'Any') -> 'VectorStoreRetriever'\n",
      " |      Return VectorStoreRetriever initialized from this VectorStore.\n",
      " |      \n",
      " |      Args:\n",
      " |          search_type (Optional[str]): Defines the type of search that\n",
      " |              the Retriever should perform.\n",
      " |              Can be \"similarity\" (default), \"mmr\", or\n",
      " |              \"similarity_score_threshold\".\n",
      " |          search_kwargs (Optional[Dict]): Keyword arguments to pass to the\n",
      " |              search function. Can include things like:\n",
      " |                  k: Amount of documents to return (Default: 4)\n",
      " |                  score_threshold: Minimum relevance threshold\n",
      " |                      for similarity_score_threshold\n",
      " |                  fetch_k: Amount of documents to pass to MMR algorithm (Default: 20)\n",
      " |                  lambda_mult: Diversity of results returned by MMR;\n",
      " |                      1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
      " |                  filter: Filter by document metadata\n",
      " |      \n",
      " |      Returns:\n",
      " |          VectorStoreRetriever: Retriever class for VectorStore.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # Retrieve more documents with higher diversity\n",
      " |          # Useful if your dataset has many similar documents\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
      " |          )\n",
      " |      \n",
      " |          # Fetch more documents for the MMR algorithm to consider\n",
      " |          # But only return the top 5\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={'k': 5, 'fetch_k': 50}\n",
      " |          )\n",
      " |      \n",
      " |          # Only retrieve documents that have a relevance score\n",
      " |          # Above a certain threshold\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"similarity_score_threshold\",\n",
      " |              search_kwargs={'score_threshold': 0.8}\n",
      " |          )\n",
      " |      \n",
      " |          # Only get the single most similar document from the dataset\n",
      " |          docsearch.as_retriever(search_kwargs={'k': 1})\n",
      " |      \n",
      " |          # Use a filter to only retrieve documents from a specific paper\n",
      " |          docsearch.as_retriever(\n",
      " |              search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}}\n",
      " |          )\n",
      " |  \n",
      " |  async asearch(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query using specified search type.\n",
      " |  \n",
      " |  async asimilarity_search(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query.\n",
      " |  \n",
      " |  async asimilarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to embedding vector.\n",
      " |  \n",
      " |  async asimilarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs and relevance scores in the range [0, 1], asynchronously.\n",
      " |      \n",
      " |      0 is dissimilar, 1 is most similar.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: input text\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Tuples of (doc, similarity_score)\n",
      " |  \n",
      " |  async asimilarity_search_with_score(self, *args: 'Any', **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Run similarity search with distance asynchronously.\n",
      " |  \n",
      " |  search(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query using specified search type.\n",
      " |  \n",
      " |  similarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs and relevance scores in the range [0, 1].\n",
      " |      \n",
      " |      0 is dissimilar, 1 is most similar.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: input text\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Tuples of (doc, similarity_score)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  async afrom_documents(documents: 'List[Document]', embedding: 'Embeddings', **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
      " |      Return VectorStore initialized from documents and embeddings.\n",
      " |  \n",
      " |  async afrom_texts(texts: 'List[str]', embedding: 'Embeddings', metadatas: 'Optional[List[dict]]' = None, **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
      " |      Return VectorStore initialized from texts and embeddings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Chroma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294fc6b-645b-4bc3-bbd6-6430dc9f42a6",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99b9f978-6c69-42de-9f0b-020f8d937dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mon Jun 10 09:37:43 2024 INFO Use pytorch device_name: cpu\n",
      "Mon Jun 10 09:37:43 2024 INFO Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Mon Jun 10 09:37:43 2024 INFO Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "from BRAD import brad\n",
    "vectordb, _ = brad.load_literature_db(persist_directory='/nfs/turbo/umms-indikar/shared/projects/RAG/databases/DigitalLibrary-10-June-2024/DigitalLibraryDigitalLibrary/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "984ea24a-2e8d-4554-8051-ed166c3516e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectordb.get()['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83f67499-a678-44b1-b97f-f4becf3f0f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [], 'embeddings': None, 'metadatas': [], 'documents': [], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "print(vectordb.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1879c468-07ee-474f-9d98-a7a0a41d6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bert_score import BERTScorer\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee8c573-af5b-4240-be8a-6c36c8e795c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/jpic/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jpic/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jpic/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from BRAD import brad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65e24f9c-828d-4b97-b8bb-758665db71c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to RAG! The chat log from this conversation will be saved to /home/jpic/BRAD/2024-06-10-02:38:15.066406.json. How can I help?\n",
      "\n",
      "Would you like to use a database with BRAD [Y/N]?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mon Jun 10 02:38:20 2024 INFO Use pytorch device_name: cpu\n",
      "Mon Jun 10 02:38:20 2024 INFO Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "/home/jpic/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Mon Jun 10 02:38:20 2024 INFO Collection DB_cosine_cSize_700_cOver_200 is not created.\n",
      "Mon Jun 10 02:38:20 2024 INFO local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  /force RAG what can you tell me about bifurcation theory?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mon Jun 10 02:38:38 2024 INFO RAG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RAG >> 1: \n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "\n",
      "Human: /force RAG what can you tell me about bifurcation theory?\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Bifurcation theory is a branch of mathematics, specifically in the field of dynamical systems, that studies the behavior of systems undergoing qualitative changes when parameters are varied. In simpler terms, it explores how small changes to the input of a system can lead to large alterations in its output or behavior. The term \"bifurcation\" refers to the point at which this qualitative change occurs. Bifurcation theory helps us understand how complicated behaviors can emerge from relatively simple equations, and is of great importance in various fields such as physics, engineering, and finance.\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  /force RAG what did smale contribute to dynamical systems?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mon Jun 10 02:39:37 2024 INFO RAG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RAG >> 2: \n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "\n",
      "Human: /force RAG what did smale contribute to dynamical systems?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Smale was a prominent mathematician who made significant contributions to the field of dynamical systems. Here are a few of his major accomplishments:\n",
      "\n",
      "1. He proved the Poincaré conjecture in higher dimensions for certain cases using his h-cobordism theorem. This work contributed to the development of the modern theory of smooth manifolds and topology.\n",
      "2. Smale introduced the concept of horseshoes and hyperbolic sets in dynamics. These objects are now fundamental in understanding chaotic behaviors in systems.\n",
      "3. He proved the existence of a horseshoe map in the tent map and provided a topological characterization of chaos.\n",
      "4. Smale contributed to the study of bifurcation theory, which investigates how simple solutions in a dynamic system change as a parameter is varied. He provided a systematic method for classifying bifurcations using his famous S and U maps.\n",
      "\n",
      "These are just a few of Smale's contributions to dynamical systems and chaos theory. His work has significantly advanced our understanding of complex, nonlinear systems and continues to inspire new research in the field.\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for chatting today! I hope to talk soon, and don't forget that a record of this conversation is available at: /home/jpic/BRAD/2024-06-10-02:38:15.066406.json\n"
     ]
    }
   ],
   "source": [
    "brad.chat(persist_directory='/nfs/turbo/umms-indikar/shared/projects/RAG/databases/DigitalLibrary-9-June-2024/DigitalLibraryDigitalLibrary/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8761a65b-3a58-469c-b231-cb3fcdafbbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function chat in module BRAD.brad:\n",
      "\n",
      "chat(model_path='/nfs/turbo/umms-indikar/shared/projects/RAG/models/llama-2-7b-chat.Q8_0.gguf', persist_directory='/nfs/turbo/umms-indikar/shared/projects/RAG/databases/Transcription-Factors-5-10-2024/', llm=None, ragvectordb=None, embeddings_model=None)\n",
      "    Initializes and runs the RAG chatbot, allowing interaction with various models and databases, and logs the conversation.\n",
      "    \n",
      "    :param model_path: The path to the Llama model file, defaults to '/nfs/turbo/umms-indikar/shared/projects/RAG/models/llama-2-7b-chat.Q8_0.gguf'.\n",
      "    :type model_path: str, optional\n",
      "    :param persist_directory: The directory where the literature database is stored, defaults to \"/nfs/turbo/umms-indikar/shared/projects/RAG/databases/Transcription-Factors-5-10-2024/\".\n",
      "    :type persist_directory: str, optional\n",
      "    :param llm: The language model to be used. If None, it will be loaded within the function.\n",
      "    :type llm: PreTrainedModel, optional\n",
      "    :param ragvectordb: The RAG vector database to be used. If None, it will prompt the user to load it.\n",
      "    :type ragvectordb: Chroma, optional\n",
      "    :param embeddings_model: The embeddings model to be used. If None, it will be loaded within the function.\n",
      "    :type embeddings_model: HuggingFaceEmbeddings, optional\n",
      "    \n",
      "    :raises FileNotFoundError: If the specified model or database directories do not exist.\n",
      "    :raises json.JSONDecodeError: If the configuration file contains invalid JSON.\n",
      "    :raises KeyError: If required keys are missing from the configuration or chat status.\n",
      "    \n",
      "    :return: None\n",
      "    :rtype: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(brad.chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f692e2-8a2b-49bc-8c2f-590cd0a63905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
