{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd77758-f458-43e0-bae1-68b33efa3c2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'BRAD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m transformers\u001b[38;5;241m.\u001b[39mmodeling_utils\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mERROR)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#from bert_score import BERTScorer\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBRAD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m brad\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBRAD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rag\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'BRAD'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chromadb\n",
    "import subprocess\n",
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from semantic_router.layer import RouteLayer\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#BERTscore\n",
    "#import bert_score\n",
    "import logging\n",
    "import transformers\n",
    "transformers.tokenization_utils.logger.setLevel(logging.ERROR)\n",
    "transformers.configuration_utils.logger.setLevel(logging.ERROR)\n",
    "transformers.modeling_utils.logger.setLevel(logging.ERROR)\n",
    "#from bert_score import BERTScorer\n",
    "from BRAD import brad\n",
    "from BRAD import rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea8d33-41c8-415c-a6fb-c295f46832dd",
   "metadata": {},
   "source": [
    "/force RAG summarize the human transcription factors paper\n",
    "\n",
    "\n",
    "NVIDIA KEY\n",
    "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"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a07c3-15a6-446d-84cf-5d0143f90466",
   "metadata": {},
   "source": [
    "## Single Document Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef62494e-f811-49ee-9abd-7eaccea833fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to RAG! The chat log from this conversation will be saved to /home/machoi/BRAD/2024-06-21_15-58-09/log.json. How can I help?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your NVIDIA API key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Would you like to use a database with BRAD [Y/N]?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machoi/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/machoi/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-06-21 15:58:29 INFO semantic_router.utils.logger local\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  /force RAG summarize the human transcription factors paper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RAG >> 1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machoi/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best match is /nfs/turbo/umms-indikar/shared/projects/rag/papers/transcription-factors/a comprehensive library of human transcription factors for cell fate engineering with a score of 0.7479504346847534\n",
      "232\n",
      "232\n",
      "after retrieval: [Document(page_content='Nakatake, Y. et al. Generation and profiling of 2,135 human ESC lines for the systematic analyses of cell states perturbed by inducing single transcription factors. Cell Rep. 31, 107655 (2020).\\n\\n14. Vaquerizas, J. M., Kummerfeld, S. K., Teichmann, S. A. & Luscombe, N. M. A census of human transcription factors: function, expression and evolution. Nat. Rev. Genet. 10, 252–263 (2009).\\n\\nNATuRE BioTECHNoLoGY | www.nature.com/naturebiotechnology\\n\\n15. Jolma, A. et al. DNA-binding specificities of human transcription factors. Cell\\n\\n41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\\n\\n41. Bi, W., Deng, J.'), Document(page_content='A comprehensive library of human transcription factors for cell fate engineering\\n\\nAlex H. M. Ng1,2,3,14, Parastoo Khoshakhlagh1,2,3,14, Jesus Eduardo Rojo Arias\\u200a \\u200a5,6, Anka Swiersy4, Seth L. Shipman7, Evan Appleton\\u200a Kai Wang\\u200a Richie E. Kohman1,2, Andyna Vernet2, Matthew Dysart1,2, Kathleen Leeper\\u200a \\u200a1,2, Amanda Graveline2, Jussi Taipale8,9,10, David E. Hill\\u200a Jeremy Y. Huang\\u200a Juan M. Melero-Martin5,6, Volker Busskamp\\n\\n4,13, Giovanni Pasquini4,\\n\\n1,2,3, Kiavash Kiaee1,2,3,\\n\\n1,2, Wren Saylor\\u200a \\u200a1,11, Marc Vidal1,11,\\n\\n1,2,\\n\\n4,12\\u2009✉ and George M. Church\\n\\n1,2,3\\u2009✉\\n\\nHuman pluripotent stem cells (hPSCs) offer an unprecedented opportunity to model diverse cell types and tissues. To enable systematic'), Document(page_content='Cahan, P. et al. CellNet: network biology applied to stem cell engineering. Cell 158, 903–915 (2014).\\n\\n10. Rackham, O. J. et al. A predictive computational framework for direct reprogramming between human cell types. Nat. Genet. 48, 331–335 (2016).\\n\\n11. D’Alessio, A. C. et al. A systematic approach to identify candidate trans-\\n\\ncription factors that control cell identity. Stem Cell Rep. 5, 763–775 (2015). 12. Lambert, S. A. et al. The human transcription factors. Cell 175, 598–599 (2018). 13. Nakatake, Y. et al. Generation and profiling of 2,135 human ESC lines for the systematic analyses of cell states perturbed by inducing single transcription factors. Cell Rep. 31, 107655 (2020).\\n\\n14.'), Document(page_content='Ehrlich, M. et al. Rapid and efficient generation of oligodendrocytes from human induced pluripotent stem cells using transcription factors. Proc. Natl Acad. Sci. USA 114, E2243–E2252 (2017).\\n\\n40. Sarkar, A. & Hochedlinger, K. The sox family of transcription factors: versatile regulators of stem and progenitor cell fate. Cell Stem Cell 12, 15–30 (2013).\\n\\n63. Moss, J. et al. Comprehensive human cell-type methylation atlas reveals origins of circulating cell-free DNA in health and disease. Nat. Commun. 9, 5068 (2018).\\n\\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n\\n© The Author(s), under exclusive'), Document(page_content='transcription factors. Cell\\n\\n41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\\n\\n41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\\n\\n16. Seiler, C. Y. et al. DNASU plasmid and PSI:Biology-Materials repositories:\\n\\n42. Canals, I. et al. Rapid and efficient induction of functional astrocytes from\\n\\nresources to accelerate biological research. Nucleic Acids Res. 42, D1253–D1260 (2014).\\n\\n17. Yang, X. et al. A public genome-scale lentiviral expression library of human ORFs. Nat. Methods 8, 659–661'), Document(page_content='Nat. Neurosci. 22, 484–491 (2019).\\n\\n62. Cusanovich, D. A. et al. A single-cell atlas of in vivo mammalian chromatin\\n\\n38. Garcia-Leon, J. A. et al. SOX10 single transcription factor-based fast and efficient generation of oligodendrocytes from human pluripotent stem cells. Stem Cell Rep. 10, 655–672 (2018).\\n\\n38. Garcia-Leon, J. A. et al. SOX10 single transcription factor-based fast and efficient generation of oligodendrocytes from human pluripotent stem cells. Stem Cell Rep. 10, 655–672 (2018).\\n\\n39. Ehrlich, M. et al. Rapid and efficient generation of oligodendrocytes from human induced pluripotent stem cells using transcription factors. Proc. Natl Acad. Sci. USA 114, E2243–E2252 (2017).\\n\\n40.'), Document(page_content='Marc Vidal1,11,\\n\\n1,2,\\n\\n4,12\\u2009✉ and George M. Church\\n\\n1,2,3\\u2009✉\\n\\nHuman pluripotent stem cells (hPSCs) offer an unprecedented opportunity to model diverse cell types and tissues. To enable systematic exploration of the programming landscape mediated by transcription factors (TFs), we present the Human TFome, a comprehensive library containing 1,564 TF genes and 1,732 TF splice isoforms. By screening the library in three hPSC lines, we discovered 290 TFs, including 241 that were previously unreported, that induce differentiation in 4 days without alteration of external soluble or biomechanical cues. We used four of the hits to program hPSCs into neurons, fibroblasts, oligodendro- cytes and'), Document(page_content='K. A., Yates, B., Seal, R. L., Wright, M. W. & Bruford, E. A. Genenames. org: the HGNC resources in 2015. Nucleic Acids Res. 43, D1079–D1085 (2015).\\n\\n65. Mele, M. et al. Human genomics. The human transcriptome across tissues and individuals. Science 348, 660–665 (2015).\\n\\n66. Church, G. M. The personal genome project. Mol. Syst. Biol. 1, 2005.0030 (2005).\\n\\n67. Kutsche, L. K. et al. Combined experimental and system-level analyses reveal the complex regulatory network of miR-124 during human neurogenesis. Cell Syst. 7, 438–452 (2018).\\n\\n68. Salmon, P. & Trono, D. Production and titration of lentiviral vectors. in Current Protocols in Human Genetics Ch. 12, Unit 12.10 (Wiley, 2007).\\n\\n69. Dobin,'), Document(page_content='defined factors. Cell 126, 663–676 (2006).\\n\\n3. Zhang, Y. et al. Rapid single-step induction of functional neurons from human pluripotent stem cells. Neuron 78, 785–798 (2013).\\n\\n4. Parekh, U. et al. Mapping cellular reprogramming via pooled overexpression screens with paired fitness and single-cell RNA-sequencing readout. Cell Syst. 7, 548–555 (2018).\\n\\n5. Tsunemoto, R. et al. Diverse reprogramming codes for neuronal identity. Nature 557, 375–380 (2018).\\n\\n6. Pritsker, M., Ford, N. R., Jenq, H. T. & Lemischka, I. R. Genomewide\\n\\ngain-of-function genetic screen identifies functionally active genes in mouse embryonic stem cells. Proc. Natl Acad. Sci. USA 103, 6946–6951 (2006). 7. Theodorou, E. et'), Document(page_content='Nat. Commun. 9, 5068 (2018).\\n\\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n\\n© The Author(s), under exclusive licence to Springer Nature America, Inc. 2020\\n\\nNATuRE BioTECHNoLoGY | www.nature.com/naturebiotechnology\\n\\nMethods Annotation of human TFs. A starting set of 1,591 TFs14 was used, based on their evidence codes “a” and “b” (confirmed experimental evidence), “c” (prediction only) and “other” (probable TFs with undefined DNA-binding domains). Additional TFs curated by the Human Genome Organization’s HUGO Gene Nomenclature Committee (HGNC)64 were added: zinc fingers (including those containing C2H2')]\n",
      "[[1.0000001  0.6557605  0.7378004  0.616431   0.6868915  0.6382761\n",
      "  0.48725685 0.48152244 0.5627506  0.30996332]\n",
      " [0.6557605  0.99999994 0.74394196 0.6693484  0.6241696  0.5980241\n",
      "  0.68256617 0.4364017  0.5791335  0.40567154]\n",
      " [0.7378004  0.74394196 1.0000001  0.65325254 0.5281526  0.6453785\n",
      "  0.56854486 0.46182904 0.6718427  0.33359438]\n",
      " [0.616431   0.6693484  0.65325254 1.0000008  0.69331294 0.82596725\n",
      "  0.5571683  0.46166536 0.6209468  0.3940152 ]\n",
      " [0.6868915  0.6241696  0.5281526  0.69331294 1.         0.64704007\n",
      "  0.46290672 0.44551212 0.5327642  0.37234783]\n",
      " [0.6382761  0.5980241  0.6453785  0.82596725 0.64704007 0.9999997\n",
      "  0.49014437 0.4042119  0.583956   0.32044157]\n",
      " [0.48725685 0.68256617 0.56854486 0.5571683  0.46290672 0.49014437\n",
      "  1.         0.44446024 0.51465434 0.543449  ]\n",
      " [0.48152244 0.4364017  0.46182904 0.46166536 0.44551212 0.4042119\n",
      "  0.44446024 1.0000001  0.45217836 0.45504966]\n",
      " [0.5627506  0.5791335  0.6718427  0.6209468  0.5327642  0.583956\n",
      "  0.51465434 0.45217836 1.0000004  0.3620262 ]\n",
      " [0.30996332 0.40567154 0.33359438 0.3940152  0.37234783 0.32044157\n",
      "  0.543449   0.45504966 0.3620262  1.0000007 ]]\n",
      "[3, 1, 2, 0, 5, 4, 8, 6, 7, 9]\n",
      "[Document(page_content='Ehrlich, M. et al. Rapid and efficient generation of oligodendrocytes from human induced pluripotent stem cells using transcription factors. Proc. Natl Acad. Sci. USA 114, E2243–E2252 (2017).\\n\\n40. Sarkar, A. & Hochedlinger, K. The sox family of transcription factors: versatile regulators of stem and progenitor cell fate. Cell Stem Cell 12, 15–30 (2013).\\n\\n63. Moss, J. et al. Comprehensive human cell-type methylation atlas reveals origins of circulating cell-free DNA in health and disease. Nat. Commun. 9, 5068 (2018).\\n\\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n\\n© The Author(s), under exclusive'), Document(page_content='A comprehensive library of human transcription factors for cell fate engineering\\n\\nAlex H. M. Ng1,2,3,14, Parastoo Khoshakhlagh1,2,3,14, Jesus Eduardo Rojo Arias\\u200a \\u200a5,6, Anka Swiersy4, Seth L. Shipman7, Evan Appleton\\u200a Kai Wang\\u200a Richie E. Kohman1,2, Andyna Vernet2, Matthew Dysart1,2, Kathleen Leeper\\u200a \\u200a1,2, Amanda Graveline2, Jussi Taipale8,9,10, David E. Hill\\u200a Jeremy Y. Huang\\u200a Juan M. Melero-Martin5,6, Volker Busskamp\\n\\n4,13, Giovanni Pasquini4,\\n\\n1,2,3, Kiavash Kiaee1,2,3,\\n\\n1,2, Wren Saylor\\u200a \\u200a1,11, Marc Vidal1,11,\\n\\n1,2,\\n\\n4,12\\u2009✉ and George M. Church\\n\\n1,2,3\\u2009✉\\n\\nHuman pluripotent stem cells (hPSCs) offer an unprecedented opportunity to model diverse cell types and tissues. To enable systematic'), Document(page_content='Cahan, P. et al. CellNet: network biology applied to stem cell engineering. Cell 158, 903–915 (2014).\\n\\n10. Rackham, O. J. et al. A predictive computational framework for direct reprogramming between human cell types. Nat. Genet. 48, 331–335 (2016).\\n\\n11. D’Alessio, A. C. et al. A systematic approach to identify candidate trans-\\n\\ncription factors that control cell identity. Stem Cell Rep. 5, 763–775 (2015). 12. Lambert, S. A. et al. The human transcription factors. Cell 175, 598–599 (2018). 13. Nakatake, Y. et al. Generation and profiling of 2,135 human ESC lines for the systematic analyses of cell states perturbed by inducing single transcription factors. Cell Rep. 31, 107655 (2020).\\n\\n14.'), Document(page_content='Nakatake, Y. et al. Generation and profiling of 2,135 human ESC lines for the systematic analyses of cell states perturbed by inducing single transcription factors. Cell Rep. 31, 107655 (2020).\\n\\n14. Vaquerizas, J. M., Kummerfeld, S. K., Teichmann, S. A. & Luscombe, N. M. A census of human transcription factors: function, expression and evolution. Nat. Rev. Genet. 10, 252–263 (2009).\\n\\nNATuRE BioTECHNoLoGY | www.nature.com/naturebiotechnology\\n\\n15. Jolma, A. et al. DNA-binding specificities of human transcription factors. Cell\\n\\n41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\\n\\n41. Bi, W., Deng, J.'), Document(page_content='Nat. Neurosci. 22, 484–491 (2019).\\n\\n62. Cusanovich, D. A. et al. A single-cell atlas of in vivo mammalian chromatin\\n\\n38. Garcia-Leon, J. A. et al. SOX10 single transcription factor-based fast and efficient generation of oligodendrocytes from human pluripotent stem cells. Stem Cell Rep. 10, 655–672 (2018).\\n\\n38. Garcia-Leon, J. A. et al. SOX10 single transcription factor-based fast and efficient generation of oligodendrocytes from human pluripotent stem cells. Stem Cell Rep. 10, 655–672 (2018).\\n\\n39. Ehrlich, M. et al. Rapid and efficient generation of oligodendrocytes from human induced pluripotent stem cells using transcription factors. Proc. Natl Acad. Sci. USA 114, E2243–E2252 (2017).\\n\\n40.'), Document(page_content='transcription factors. Cell\\n\\n41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\\n\\n41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\\n\\n16. Seiler, C. Y. et al. DNASU plasmid and PSI:Biology-Materials repositories:\\n\\n42. Canals, I. et al. Rapid and efficient induction of functional astrocytes from\\n\\nresources to accelerate biological research. Nucleic Acids Res. 42, D1253–D1260 (2014).\\n\\n17. Yang, X. et al. A public genome-scale lentiviral expression library of human ORFs. Nat. Methods 8, 659–661'), Document(page_content='defined factors. Cell 126, 663–676 (2006).\\n\\n3. Zhang, Y. et al. Rapid single-step induction of functional neurons from human pluripotent stem cells. Neuron 78, 785–798 (2013).\\n\\n4. Parekh, U. et al. Mapping cellular reprogramming via pooled overexpression screens with paired fitness and single-cell RNA-sequencing readout. Cell Syst. 7, 548–555 (2018).\\n\\n5. Tsunemoto, R. et al. Diverse reprogramming codes for neuronal identity. Nature 557, 375–380 (2018).\\n\\n6. Pritsker, M., Ford, N. R., Jenq, H. T. & Lemischka, I. R. Genomewide\\n\\ngain-of-function genetic screen identifies functionally active genes in mouse embryonic stem cells. Proc. Natl Acad. Sci. USA 103, 6946–6951 (2006). 7. Theodorou, E. et'), Document(page_content='Marc Vidal1,11,\\n\\n1,2,\\n\\n4,12\\u2009✉ and George M. Church\\n\\n1,2,3\\u2009✉\\n\\nHuman pluripotent stem cells (hPSCs) offer an unprecedented opportunity to model diverse cell types and tissues. To enable systematic exploration of the programming landscape mediated by transcription factors (TFs), we present the Human TFome, a comprehensive library containing 1,564 TF genes and 1,732 TF splice isoforms. By screening the library in three hPSC lines, we discovered 290 TFs, including 241 that were previously unreported, that induce differentiation in 4 days without alteration of external soluble or biomechanical cues. We used four of the hits to program hPSCs into neurons, fibroblasts, oligodendro- cytes and'), Document(page_content='K. A., Yates, B., Seal, R. L., Wright, M. W. & Bruford, E. A. Genenames. org: the HGNC resources in 2015. Nucleic Acids Res. 43, D1079–D1085 (2015).\\n\\n65. Mele, M. et al. Human genomics. The human transcriptome across tissues and individuals. Science 348, 660–665 (2015).\\n\\n66. Church, G. M. The personal genome project. Mol. Syst. Biol. 1, 2005.0030 (2005).\\n\\n67. Kutsche, L. K. et al. Combined experimental and system-level analyses reveal the complex regulatory network of miR-124 during human neurogenesis. Cell Syst. 7, 438–452 (2018).\\n\\n68. Salmon, P. & Trono, D. Production and titration of lentiviral vectors. in Current Protocols in Human Genetics Ch. 12, Unit 12.10 (Wiley, 2007).\\n\\n69. Dobin,'), Document(page_content='Nat. Commun. 9, 5068 (2018).\\n\\nPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n\\n© The Author(s), under exclusive licence to Springer Nature America, Inc. 2020\\n\\nNATuRE BioTECHNoLoGY | www.nature.com/naturebiotechnology\\n\\nMethods Annotation of human TFs. A starting set of 1,591 TFs14 was used, based on their evidence codes “a” and “b” (confirmed experimental evidence), “c” (prediction only) and “other” (probable TFs with undefined DNA-binding domains). Additional TFs curated by the Human Genome Organization’s HUGO Gene Nomenclature Committee (HGNC)64 were added: zinc fingers (including those containing C2H2')]\n",
      "============\n",
      "Ehrlich, M. et al. Rapid and efficient generation of oligodendrocytes from human induced pluripotent stem cells using transcription factors. Proc. Natl Acad. Sci. USA 114, E2243–E2252 (2017).\n",
      "\n",
      "40. Sarkar, A. & Hochedlinger, K. The sox family of transcription factors: versatile regulators of stem and progenitor cell fate. Cell Stem Cell 12, 15–30 (2013).\n",
      "\n",
      "63. Moss, J. et al. Comprehensive human cell-type methylation atlas reveals origins of circulating cell-free DNA in health and disease. Nat. Commun. 9, 5068 (2018).\n",
      "\n",
      "Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n",
      "\n",
      "© The Author(s), under exclusive\n",
      "Summary: None\n",
      "============\n",
      "A comprehensive library of human transcription factors for cell fate engineering\n",
      "\n",
      "Alex H. M. Ng1,2,3,14, Parastoo Khoshakhlagh1,2,3,14, Jesus Eduardo Rojo Arias   5,6, Anka Swiersy4, Seth L. Shipman7, Evan Appleton  Kai Wang  Richie E. Kohman1,2, Andyna Vernet2, Matthew Dysart1,2, Kathleen Leeper   1,2, Amanda Graveline2, Jussi Taipale8,9,10, David E. Hill  Jeremy Y. Huang  Juan M. Melero-Martin5,6, Volker Busskamp\n",
      "\n",
      "4,13, Giovanni Pasquini4,\n",
      "\n",
      "1,2,3, Kiavash Kiaee1,2,3,\n",
      "\n",
      "1,2, Wren Saylor   1,11, Marc Vidal1,11,\n",
      "\n",
      "1,2,\n",
      "\n",
      "4,12 ✉ and George M. Church\n",
      "\n",
      "1,2,3 ✉\n",
      "\n",
      "Human pluripotent stem cells (hPSCs) offer an unprecedented opportunity to model diverse cell types and tissues. To enable systematic\n",
      "Summary: Here is a summary of the text related to the topic of the human transcription factors paper:\n",
      "\n",
      "The study presents a comprehensive library of human transcription factors for cell fate engineering, enabling the modeling of diverse cell types and tissues using human pluripotent stem cells (hPSCs).\n",
      "\n",
      "Note: The authors' names and affiliations have been removed as they are not essential to understanding the main idea of the paper.\n",
      "============\n",
      "Cahan, P. et al. CellNet: network biology applied to stem cell engineering. Cell 158, 903–915 (2014).\n",
      "\n",
      "10. Rackham, O. J. et al. A predictive computational framework for direct reprogramming between human cell types. Nat. Genet. 48, 331–335 (2016).\n",
      "\n",
      "11. D’Alessio, A. C. et al. A systematic approach to identify candidate trans-\n",
      "\n",
      "cription factors that control cell identity. Stem Cell Rep. 5, 763–775 (2015). 12. Lambert, S. A. et al. The human transcription factors. Cell 175, 598–599 (2018). 13. Nakatake, Y. et al. Generation and profiling of 2,135 human ESC lines for the systematic analyses of cell states perturbed by inducing single transcription factors. Cell Rep. 31, 107655 (2020).\n",
      "\n",
      "14.\n",
      "Summary: Here is a summary of the text related to the topic of \"human transcription factors paper\":\n",
      "\n",
      "The paper by Lambert et al. (2018) presents a study on human transcription factors. Additionally, Nakatake et al. (2020) generated and profiled 2,135 human embryonic stem cell lines to analyze cell states perturbed by inducing single transcription factors.\n",
      "============\n",
      "Nakatake, Y. et al. Generation and profiling of 2,135 human ESC lines for the systematic analyses of cell states perturbed by inducing single transcription factors. Cell Rep. 31, 107655 (2020).\n",
      "\n",
      "14. Vaquerizas, J. M., Kummerfeld, S. K., Teichmann, S. A. & Luscombe, N. M. A census of human transcription factors: function, expression and evolution. Nat. Rev. Genet. 10, 252–263 (2009).\n",
      "\n",
      "NATuRE BioTECHNoLoGY | www.nature.com/naturebiotechnology\n",
      "\n",
      "15. Jolma, A. et al. DNA-binding specificities of human transcription factors. Cell\n",
      "\n",
      "41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\n",
      "\n",
      "41. Bi, W., Deng, J.\n",
      "Summary: Here is a summary of the text related to the human transcription factors paper:\n",
      "\n",
      "The paper \"A census of human transcription factors: function, expression and evolution\" (2009) provides a comprehensive analysis of human transcription factors. Meanwhile, another study \"DNA-binding specificities of human transcription factors\" explores the DNA-binding specificities of these factors. Additionally, a study generated and profiled 2,135 human embryonic stem cell lines to systematically analyze cell states perturbed by inducing single transcription factors (2020).\n",
      "============\n",
      "Nat. Neurosci. 22, 484–491 (2019).\n",
      "\n",
      "62. Cusanovich, D. A. et al. A single-cell atlas of in vivo mammalian chromatin\n",
      "\n",
      "38. Garcia-Leon, J. A. et al. SOX10 single transcription factor-based fast and efficient generation of oligodendrocytes from human pluripotent stem cells. Stem Cell Rep. 10, 655–672 (2018).\n",
      "\n",
      "38. Garcia-Leon, J. A. et al. SOX10 single transcription factor-based fast and efficient generation of oligodendrocytes from human pluripotent stem cells. Stem Cell Rep. 10, 655–672 (2018).\n",
      "\n",
      "39. Ehrlich, M. et al. Rapid and efficient generation of oligodendrocytes from human induced pluripotent stem cells using transcription factors. Proc. Natl Acad. Sci. USA 114, E2243–E2252 (2017).\n",
      "\n",
      "40.\n",
      "Summary: Here is a summary of the text related to the human transcription factors paper:\n",
      "\n",
      "The text describes the generation of oligodendrocytes from human pluripotent stem cells using transcription factors. Specifically, SOX10 single transcription factor was used to efficiently generate oligodendrocytes (Garcia-Leon et al., 2018). Another study also demonstrated the rapid and efficient generation of oligodendrocytes from human induced pluripotent stem cells using transcription factors (Ehrlich et al., 2017).\n",
      "============\n",
      "transcription factors. Cell\n",
      "\n",
      "41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\n",
      "\n",
      "41. Bi, W., Deng, J. M., Zhang, Z., Behringer, R. R. & de Crombrugghe, B. Sox9 is required for cartilage formation. Nat. Genet. 22, 85–89 (1999).\n",
      "\n",
      "16. Seiler, C. Y. et al. DNASU plasmid and PSI:Biology-Materials repositories:\n",
      "\n",
      "42. Canals, I. et al. Rapid and efficient induction of functional astrocytes from\n",
      "\n",
      "resources to accelerate biological research. Nucleic Acids Res. 42, D1253–D1260 (2014).\n",
      "\n",
      "17. Yang, X. et al. A public genome-scale lentiviral expression library of human ORFs. Nat. Methods 8, 659–661\n",
      "Summary: Here is a summary of the text related to human transcription factors:\n",
      "\n",
      "None\n",
      "\n",
      "The provided text appears to be a list of references or citations, but none of them directly discuss human transcription factors. The references mentioned are related to topics such as cartilage formation, biological research resources, and astrocytes, but do not provide information specifically about human transcription factors.\n",
      "============\n",
      "defined factors. Cell 126, 663–676 (2006).\n",
      "\n",
      "3. Zhang, Y. et al. Rapid single-step induction of functional neurons from human pluripotent stem cells. Neuron 78, 785–798 (2013).\n",
      "\n",
      "4. Parekh, U. et al. Mapping cellular reprogramming via pooled overexpression screens with paired fitness and single-cell RNA-sequencing readout. Cell Syst. 7, 548–555 (2018).\n",
      "\n",
      "5. Tsunemoto, R. et al. Diverse reprogramming codes for neuronal identity. Nature 557, 375–380 (2018).\n",
      "\n",
      "6. Pritsker, M., Ford, N. R., Jenq, H. T. & Lemischka, I. R. Genomewide\n",
      "\n",
      "gain-of-function genetic screen identifies functionally active genes in mouse embryonic stem cells. Proc. Natl Acad. Sci. USA 103, 6946–6951 (2006). 7. Theodorou, E. et\n",
      "Summary: Here is a summary of the text related to the topic of \"human transcription factors\":\n",
      "\n",
      "None\n",
      "============\n",
      "Marc Vidal1,11,\n",
      "\n",
      "1,2,\n",
      "\n",
      "4,12 ✉ and George M. Church\n",
      "\n",
      "1,2,3 ✉\n",
      "\n",
      "Human pluripotent stem cells (hPSCs) offer an unprecedented opportunity to model diverse cell types and tissues. To enable systematic exploration of the programming landscape mediated by transcription factors (TFs), we present the Human TFome, a comprehensive library containing 1,564 TF genes and 1,732 TF splice isoforms. By screening the library in three hPSC lines, we discovered 290 TFs, including 241 that were previously unreported, that induce differentiation in 4 days without alteration of external soluble or biomechanical cues. We used four of the hits to program hPSCs into neurons, fibroblasts, oligodendro- cytes and\n",
      "Summary: Here is a summary of the text related to the user's query about human transcription factors:\n",
      "\n",
      "Researchers have created the Human TFome, a library of 1,564 transcription factor (TF) genes and 1,732 TF splice isoforms. By screening the library in three human pluripotent stem cell lines, they discovered 290 TFs that induce differentiation into various cell types, including 241 previously unreported TFs. This discovery enables the systematic exploration of transcription factor-mediated programming of diverse cell types and tissues.\n",
      "============\n",
      "K. A., Yates, B., Seal, R. L., Wright, M. W. & Bruford, E. A. Genenames. org: the HGNC resources in 2015. Nucleic Acids Res. 43, D1079–D1085 (2015).\n",
      "\n",
      "65. Mele, M. et al. Human genomics. The human transcriptome across tissues and individuals. Science 348, 660–665 (2015).\n",
      "\n",
      "66. Church, G. M. The personal genome project. Mol. Syst. Biol. 1, 2005.0030 (2005).\n",
      "\n",
      "67. Kutsche, L. K. et al. Combined experimental and system-level analyses reveal the complex regulatory network of miR-124 during human neurogenesis. Cell Syst. 7, 438–452 (2018).\n",
      "\n",
      "68. Salmon, P. & Trono, D. Production and titration of lentiviral vectors. in Current Protocols in Human Genetics Ch. 12, Unit 12.10 (Wiley, 2007).\n",
      "\n",
      "69. Dobin,\n",
      "Summary: None\n",
      "============\n",
      "Nat. Commun. 9, 5068 (2018).\n",
      "\n",
      "Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n",
      "\n",
      "© The Author(s), under exclusive licence to Springer Nature America, Inc. 2020\n",
      "\n",
      "NATuRE BioTECHNoLoGY | www.nature.com/naturebiotechnology\n",
      "\n",
      "Methods Annotation of human TFs. A starting set of 1,591 TFs14 was used, based on their evidence codes “a” and “b” (confirmed experimental evidence), “c” (prediction only) and “other” (probable TFs with undefined DNA-binding domains). Additional TFs curated by the Human Genome Organization’s HUGO Gene Nomenclature Committee (HGNC)64 were added: zinc fingers (including those containing C2H2\n",
      "Summary: Here is a summary of the text related to the human transcription factors paper:\n",
      "\n",
      "The paper focuses on the annotation of human transcription factors (TFs). It starts with a set of 1,591 TFs, which are categorized based on evidence codes: \"a\" and \"b\" for confirmed experimental evidence, \"c\" for prediction only, and \"other\" for probable TFs with undefined DNA-binding domains. Additional TFs are curated by the Human Genome Organization's HUGO Gene Nomenclature Committee (HGNC), including zinc fingers with C2H2 domains.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "None\n",
      "\n",
      "Here is a summary of the text related to the topic of the human transcription factors paper:\n",
      "\n",
      "The study presents a comprehensive library of human transcription factors for cell fate engineering, enabling the modeling of diverse cell types and tissues using human pluripotent stem cells (hPSCs).\n",
      "\n",
      "Note: The authors' names and affiliations have been removed as they are not essential to understanding the main idea of the paper.\n",
      "\n",
      "Here is a summary of the text related to the topic of \"human transcription factors paper\":\n",
      "\n",
      "The paper by Lambert et al. (2018) presents a study on human transcription factors. Additionally, Nakatake et al. (2020) generated and profiled 2,135 human embryonic stem cell lines to analyze cell states perturbed by inducing single transcription factors.\n",
      "\n",
      "Here is a summary of the text related to the human transcription factors paper:\n",
      "\n",
      "The paper \"A census of human transcription factors: function, expression and evolution\" (2009) provides a comprehensive analysis of human transcription factors. Meanwhile, another study \"DNA-binding specificities of human transcription factors\" explores the DNA-binding specificities of these factors. Additionally, a study generated and profiled 2,135 human embryonic stem cell lines to systematically analyze cell states perturbed by inducing single transcription factors (2020).\n",
      "\n",
      "Here is a summary of the text related to the human transcription factors paper:\n",
      "\n",
      "The text describes the generation of oligodendrocytes from human pluripotent stem cells using transcription factors. Specifically, SOX10 single transcription factor was used to efficiently generate oligodendrocytes (Garcia-Leon et al., 2018). Another study also demonstrated the rapid and efficient generation of oligodendrocytes from human induced pluripotent stem cells using transcription factors (Ehrlich et al., 2017).\n",
      "\n",
      "Here is a summary of the text related to human transcription factors:\n",
      "\n",
      "None\n",
      "\n",
      "The provided text appears to be a list of references or citations, but none of them directly discuss human transcription factors. The references mentioned are related to topics such as cartilage formation, biological research resources, and astrocytes, but do not provide information specifically about human transcription factors.\n",
      "\n",
      "Here is a summary of the text related to the topic of \"human transcription factors\":\n",
      "\n",
      "None\n",
      "\n",
      "Here is a summary of the text related to the user's query about human transcription factors:\n",
      "\n",
      "Researchers have created the Human TFome, a library of 1,564 transcription factor (TF) genes and 1,732 TF splice isoforms. By screening the library in three human pluripotent stem cell lines, they discovered 290 TFs that induce differentiation into various cell types, including 241 previously unreported TFs. This discovery enables the systematic exploration of transcription factor-mediated programming of diverse cell types and tissues.\n",
      "\n",
      "None\n",
      "\n",
      "Here is a summary of the text related to the human transcription factors paper:\n",
      "\n",
      "The paper focuses on the annotation of human transcription factors (TFs). It starts with a set of 1,591 TFs, which are categorized based on evidence codes: \"a\" and \"b\" for confirmed experimental evidence, \"c\" for prediction only, and \"other\" for probable TFs with undefined DNA-binding domains. Additional TFs are curated by the Human Genome Organization's HUGO Gene Nomenclature Committee (HGNC), including zinc fingers with C2H2 domains.\n",
      "Human: summarize the human transcription factors paper\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machoi/.local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, here is a summary of the human transcription factors paper:\n",
      "\n",
      "The paper presents a comprehensive library of human transcription factors (TFs) for cell fate engineering, enabling the modeling of diverse cell types and tissues using human pluripotent stem cells (hPSCs). Researchers have created the Human TFome, a library of 1,564 TF genes and 1,732 TF splice isoforms. By screening the library in three human pluripotent stem cell lines, they discovered 290 TFs that induce differentiation into various cell types, including 241 previously unreported TFs. This discovery enables the systematic exploration of transcription factor-mediated programming of diverse cell types and tissues. The paper also focuses on the annotation of human TFs, categorizing them based on evidence codes and curating additional TFs by the Human Genome Organization's HUGO Gene Nomenclature Committee (HGNC).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBRAD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m brad\n\u001b[0;32m----> 2\u001b[0m brad\u001b[38;5;241m.\u001b[39mchat()\n",
      "File \u001b[0;32m~/RAG2/RAG-DEV/BRAD/brad.py:470\u001b[0m, in \u001b[0;36mchat\u001b[0;34m(model_path, persist_directory, llm, ragvectordb, embeddings_model)\u001b[0m\n\u001b[1;32m    467\u001b[0m module \u001b[38;5;241m=\u001b[39m module_functions[routeName]\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Query database\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m chatstatus \u001b[38;5;241m=\u001b[39m module(chatstatus)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# Remove the item that was executed. We need must do it after running it for the current file naming system.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chatstatus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplanned\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m route \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPLANNER\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/RAG2/RAG-DEV/BRAD/rag.py:106\u001b[0m, in \u001b[0;36mqueryDocs\u001b[0;34m(chatstatus)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m    105\u001b[0m     source \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m     short_source \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(source)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshort_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# change inputs to be json readable\u001b[39;00m\n",
      "File \u001b[0;32m<frozen posixpath>:142\u001b[0m, in \u001b[0;36mbasename\u001b[0;34m(p)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "from BRAD import brad\n",
    "brad.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3516f15-d53c-448c-b9c7-6171fac70589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92829391-d5c6-4c49-8adc-d312e4d01254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wed Jun 19 09:34:53 2024 INFO Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "/home/machoi/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Wed Jun 19 09:35:07 2024 INFO Use pytorch device_name: cpu\n",
      "Wed Jun 19 09:35:08 2024 INFO Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Wed Jun 19 09:35:09 2024 INFO Collection DB_cosine_cSize_700_cOver_200 is not created.\n"
     ]
    }
   ],
   "source": [
    "path = '/nfs/turbo/umms-indikar/shared/projects/RAG/databases/EXP2/'\n",
    "vectordb, embeddings_model = brad.load_literature_db(persist_directory='/nfs/turbo/umms-indikar/shared/projects/RAG/databases/EXP2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93337a8e-4af8-403a-93f5-bbbcab2201f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Chroma in module langchain_chroma.vectorstores object:\n",
      "\n",
      "class Chroma(langchain_core.vectorstores.VectorStore)\n",
      " |  Chroma(collection_name: 'str' = 'langchain', embedding_function: 'Optional[Embeddings]' = None, persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, collection_metadata: 'Optional[Dict]' = None, client: 'Optional[chromadb.ClientAPI]' = None, relevance_score_fn: 'Optional[Callable[[float], float]]' = None, create_collection_if_not_exists: 'Optional[bool]' = True) -> 'None'\n",
      " |  \n",
      " |  `ChromaDB` vector store.\n",
      " |  \n",
      " |  To use, you should have the ``chromadb`` python package installed.\n",
      " |  \n",
      " |  Example:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |              from langchain_chroma import Chroma\n",
      " |              from langchain_openai import OpenAIEmbeddings\n",
      " |  \n",
      " |              embeddings = OpenAIEmbeddings()\n",
      " |              vectorstore = Chroma(\"langchain_store\", embeddings)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Chroma\n",
      " |      langchain_core.vectorstores.VectorStore\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, collection_name: 'str' = 'langchain', embedding_function: 'Optional[Embeddings]' = None, persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, collection_metadata: 'Optional[Dict]' = None, client: 'Optional[chromadb.ClientAPI]' = None, relevance_score_fn: 'Optional[Callable[[float], float]]' = None, create_collection_if_not_exists: 'Optional[bool]' = True) -> 'None'\n",
      " |      Initialize with a Chroma client.\n",
      " |  \n",
      " |  add_images(self, uris: 'List[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more images through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          uris List[str]: File path to the image.\n",
      " |          metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
      " |          ids (Optional[List[str]], optional): Optional list of IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added images.\n",
      " |  \n",
      " |  add_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more texts through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts (Iterable[str]): Texts to add to the vectorstore.\n",
      " |          metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
      " |          ids (Optional[List[str]], optional): Optional list of IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  delete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'None'\n",
      " |      Delete by vector IDs.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to delete.\n",
      " |  \n",
      " |  delete_collection(self) -> 'None'\n",
      " |      Delete the collection.\n",
      " |  \n",
      " |  encode_image(self, uri: 'str') -> 'str'\n",
      " |      Get base64 string from image URI.\n",
      " |  \n",
      " |  get(self, ids: 'Optional[OneOrMany[ID]]' = None, where: 'Optional[Where]' = None, limit: 'Optional[int]' = None, offset: 'Optional[int]' = None, where_document: 'Optional[WhereDocument]' = None, include: 'Optional[List[str]]' = None) -> 'Dict[str, Any]'\n",
      " |      Gets the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: The ids of the embeddings to get. Optional.\n",
      " |          where: A Where type dict used to filter results by.\n",
      " |                 E.g. `{\"color\" : \"red\", \"price\": 4.20}`. Optional.\n",
      " |          limit: The number of documents to return. Optional.\n",
      " |          offset: The offset to start returning results from.\n",
      " |                  Useful for paging results with limit. Optional.\n",
      " |          where_document: A WhereDocument type dict used to filter by the documents.\n",
      " |                          E.g. `{$contains: \"hello\"}`. Optional.\n",
      " |          include: A list of what to include in the results.\n",
      " |                   Can contain `\"embeddings\"`, `\"metadatas\"`, `\"documents\"`.\n",
      " |                   Ids are always included.\n",
      " |                   Defaults to `[\"metadatas\", \"documents\"]`. Optional.\n",
      " |  \n",
      " |  max_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  max_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  similarity_search(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Run similarity search with Chroma.\n",
      " |      \n",
      " |      Args:\n",
      " |          query (str): Query text to search for.\n",
      " |          k (int): Number of results to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Document]: List of documents most similar to the query text.\n",
      " |  \n",
      " |  similarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to embedding vector.\n",
      " |      Args:\n",
      " |          embedding (List[float]): Embedding to look up documents similar to.\n",
      " |          k (int): Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      Returns:\n",
      " |          List of Documents most similar to the query vector.\n",
      " |  \n",
      " |  similarity_search_by_vector_with_relevance_scores(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs most similar to embedding vector and similarity score.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding (List[float]): Embedding to look up documents similar to.\n",
      " |          k (int): Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Tuple[Document, float]]: List of documents most similar to\n",
      " |          the query text and cosine distance in float for each.\n",
      " |          Lower score represents more similarity.\n",
      " |  \n",
      " |  similarity_search_with_score(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Run similarity search with Chroma with distance.\n",
      " |      \n",
      " |      Args:\n",
      " |          query (str): Query text to search for.\n",
      " |          k (int): Number of results to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Tuple[Document, float]]: List of documents most similar to\n",
      " |          the query text and cosine distance in float for each.\n",
      " |          Lower score represents more similarity.\n",
      " |  \n",
      " |  update_document(self, document_id: 'str', document: 'Document') -> 'None'\n",
      " |      Update a document in the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          document_id (str): ID of the document to update.\n",
      " |          document (Document): Document to update.\n",
      " |  \n",
      " |  update_documents(self, ids: 'List[str]', documents: 'List[Document]') -> 'None'\n",
      " |      Update a document in the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids (List[str]): List of ids of the document to update.\n",
      " |          documents (List[Document]): List of documents to update.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_documents(documents: 'List[Document]', embedding: 'Optional[Embeddings]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.ClientAPI]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' from abc.ABCMeta\n",
      " |      Create a Chroma vectorstore from a list of documents.\n",
      " |      \n",
      " |      If a persist_directory is specified, the collection will be persisted there.\n",
      " |      Otherwise, the data will be ephemeral in-memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          collection_name (str): Name of the collection to create.\n",
      " |          persist_directory (Optional[str]): Directory to persist the collection.\n",
      " |          ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      " |          documents (List[Document]): List of documents to add to the vectorstore.\n",
      " |          embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      " |          client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      " |          collection_metadata (Optional[Dict]): Collection configurations.\n",
      " |                                                Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Chroma: Chroma vectorstore.\n",
      " |  \n",
      " |  from_texts(texts: 'List[str]', embedding: 'Optional[Embeddings]' = None, metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.ClientAPI]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' from abc.ABCMeta\n",
      " |      Create a Chroma vectorstore from a raw documents.\n",
      " |      \n",
      " |      If a persist_directory is specified, the collection will be persisted there.\n",
      " |      Otherwise, the data will be ephemeral in-memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts (List[str]): List of texts to add to the collection.\n",
      " |          collection_name (str): Name of the collection to create.\n",
      " |          persist_directory (Optional[str]): Directory to persist the collection.\n",
      " |          embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      " |          metadatas (Optional[List[dict]]): List of metadatas. Defaults to None.\n",
      " |          ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      " |          client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      " |          collection_metadata (Optional[Dict]): Collection configurations.\n",
      " |                                                Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Chroma: Chroma vectorstore.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  embeddings\n",
      " |      Access the query embedding object if available.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  async aadd_documents(self, documents: 'List[Document]', **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more documents through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents (List[Document]: Documents to add to the vectorstore.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  async aadd_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more texts through the embeddings and add to the vectorstore.\n",
      " |  \n",
      " |  add_documents(self, documents: 'List[Document]', **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more documents through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents (List[Document]: Documents to add to the vectorstore.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  async adelete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'Optional[bool]'\n",
      " |      Delete by vector ID or other criteria.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to delete.\n",
      " |          **kwargs: Other keyword arguments that subclasses might use.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Optional[bool]: True if deletion is successful,\n",
      " |          False otherwise, None if not implemented.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |  \n",
      " |  as_retriever(self, **kwargs: 'Any') -> 'VectorStoreRetriever'\n",
      " |      Return VectorStoreRetriever initialized from this VectorStore.\n",
      " |      \n",
      " |      Args:\n",
      " |          search_type (Optional[str]): Defines the type of search that\n",
      " |              the Retriever should perform.\n",
      " |              Can be \"similarity\" (default), \"mmr\", or\n",
      " |              \"similarity_score_threshold\".\n",
      " |          search_kwargs (Optional[Dict]): Keyword arguments to pass to the\n",
      " |              search function. Can include things like:\n",
      " |                  k: Amount of documents to return (Default: 4)\n",
      " |                  score_threshold: Minimum relevance threshold\n",
      " |                      for similarity_score_threshold\n",
      " |                  fetch_k: Amount of documents to pass to MMR algorithm (Default: 20)\n",
      " |                  lambda_mult: Diversity of results returned by MMR;\n",
      " |                      1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
      " |                  filter: Filter by document metadata\n",
      " |      \n",
      " |      Returns:\n",
      " |          VectorStoreRetriever: Retriever class for VectorStore.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # Retrieve more documents with higher diversity\n",
      " |          # Useful if your dataset has many similar documents\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
      " |          )\n",
      " |      \n",
      " |          # Fetch more documents for the MMR algorithm to consider\n",
      " |          # But only return the top 5\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={'k': 5, 'fetch_k': 50}\n",
      " |          )\n",
      " |      \n",
      " |          # Only retrieve documents that have a relevance score\n",
      " |          # Above a certain threshold\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"similarity_score_threshold\",\n",
      " |              search_kwargs={'score_threshold': 0.8}\n",
      " |          )\n",
      " |      \n",
      " |          # Only get the single most similar document from the dataset\n",
      " |          docsearch.as_retriever(search_kwargs={'k': 1})\n",
      " |      \n",
      " |          # Use a filter to only retrieve documents from a specific paper\n",
      " |          docsearch.as_retriever(\n",
      " |              search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}}\n",
      " |          )\n",
      " |  \n",
      " |  async asearch(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query using specified search type.\n",
      " |  \n",
      " |  async asimilarity_search(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query.\n",
      " |  \n",
      " |  async asimilarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to embedding vector.\n",
      " |  \n",
      " |  async asimilarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs and relevance scores in the range [0, 1], asynchronously.\n",
      " |      \n",
      " |      0 is dissimilar, 1 is most similar.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: input text\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Tuples of (doc, similarity_score)\n",
      " |  \n",
      " |  async asimilarity_search_with_score(self, *args: 'Any', **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Run similarity search with distance asynchronously.\n",
      " |  \n",
      " |  search(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query using specified search type.\n",
      " |  \n",
      " |  similarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs and relevance scores in the range [0, 1].\n",
      " |      \n",
      " |      0 is dissimilar, 1 is most similar.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: input text\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Tuples of (doc, similarity_score)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  async afrom_documents(documents: 'List[Document]', embedding: 'Embeddings', **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
      " |      Return VectorStore initialized from documents and embeddings.\n",
      " |  \n",
      " |  async afrom_texts(texts: 'List[str]', embedding: 'Embeddings', metadatas: 'Optional[List[dict]]' = None, **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
      " |      Return VectorStore initialized from texts and embeddings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317ec1b9-e072-4576-b32f-14cf1119359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(vectordb.get()['ids'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935bda08-5a22-4878-9b8d-2355423842f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f64588-a3e8-43e5-91e7-2ff25d0a2e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/turbo/umms-indikar/shared/projects/RAG/papers/EXP2/\n",
      "['a transient disruption of fibroblastic', 'szklarczyk2023string', 'in vivo cellular reprogramming the next generation', 'direct cell reprogramming', 'ismara automated modeling of genomic signals as a democracy of regulatory motifs', 'similar active genes cluster in specialized transcription factories', 'cooperative transcription factor induction', 'updated perspectives on direct vascular cellular reprogramming', 'elite and stochastic models for induced pluripotent stem cell generation', 'transcription factors orchestrate dynamic interplay between genome topology and gene regulation during cell reprogramming', 'the circuitry of a master switch', 'a comprehensive library of human transcription factors for cell fate engineering', 'qiu et al. - 2022 - mapping transcriptomic vector fields of single cel', 'ahmad and henikoff - 2021 - the h3.3k27m oncohistone antagonizes reprogramming', 'conserved transcription factors promote cell fate stability', 'pioneer transcription factors in cell reprogramming', 'the human transcription factors', 'cell fate determination by transcription factors', 'activation of muscle-specific genes in pigment, nerve, fat, liver, and fibroblast cell lines by forced expression of myod', 'cell identity reprogrammed', 'transcription-driven genome organization a model for chromosome structure and the regulation of gene expression tested through simulations', 'reprogramming- emerging strategies to rejuvenate aging', 'computational stem cell biology open questions and guiding principles', 'a decade of transcription factor‑mediated reprogramming to pluripotency', 'molecular interaction networks to select factors for cell conversion', 'transcriptional control of wound repair', 'a modular master regulator landscape controls', 'transcription factories gene expression in unions', 'active genes dynamically colocalize to shared sites of ongoing transcription', 'challenges for computational stem cell biology a discussion for the field', 'responsiveness to perturbations is a hallmark of transcription factors that maintain cell identity', 'high-spatial-resolution multi-omics sequencing via deterministic barcoding in tissue', 'genome-wide myod binding', 'a predictive computational framework for direct reprogramming between human cell types', 'the organization of replication and transcription', 'direct cell-fate conversion of somatic cells toward regenerative medicine and industries', 'ctcf making the right connections', 'leveling waddington the emergence of direct programming and the loss of cell fate hierarchies', 'luck2020reference', 'a computer-guided design tool to increase the efficiency of cellular conversions', 'dynamic condensates activate transcription', 'optimal-transport analysis of single-cell gene expression identifies developmental trajectories in reprogramming', 'direct cell reprogramming for tissue engineering', 'transcription factories genome organization and gene regulation', 'a comprehensive library of human transcription', 'enabling direct fate conversion with network biology', 'direct lineage reprogramming strategies, mechanisms, and applications', 'hematopoietic stem cells count', 'the myod family and myogenesis redundancy, networks, and thresholds', 'transcription factors and 3d genome conformation in cell-fate decisions', 'balsalobre and drouin - 2022 - pioneer factors as master regulators of the epigen', 'predicting three-dimensional genome structure from transcriptional activity', 'understanding transcriptional networks regulating initiation of cutaneous wound healing', 'eguchi et al. - 2022 - transdire data-driven direct reprogramming by a p', 'induction of pluripotent stem cells from adult human fibroblasts by defined factors', 'long-term association of a transcription factor with its chromatin binding site can stabilize gene expression and cell fate commitment', 'computational methods for direct cell conversion', 'pederson - 2021 - a layperson encounter, on the “modified” rna world', 'converting cell fates generating hematopoietic stem cells de novo via transcription factor reprogramming', 'nuclear reprogramming in cells']\n"
     ]
    }
   ],
   "source": [
    "source_title = []\n",
    "path = \"/nfs/turbo/umms-indikar/shared/projects/RAG/papers/EXP2/\"\n",
    "print(path)\n",
    "for metadata in vectordb.get()['metadatas']:\n",
    "    source_title.append(metadata['source'].removeprefix(path).removesuffix(\".pdf\"))\n",
    "no_repeat_source_title = set(source_title)\n",
    "post_process_title = [x.lower() for x in no_repeat_source_title]\n",
    "print(post_process_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f52dabae-3985-47fb-86f1-cc356e6cc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into two methods?\n",
    "def get_all_sources(prompt, path):\n",
    "    prompt = prompt.lower()\n",
    "    metadata_full = vectordb.get()['metadatas']\n",
    "    source_list = [item['source'] for item in metadata_full]   \n",
    "    real_source_list = [((item.replace(path, '')).removesuffix('.pdf')).lower() for item in source_list]\n",
    "    db = pd.DataFrame({'id' :vectordb.get()['ids'] , 'metadatas' : real_source_list})\n",
    "    filtered_df = db[db['metadatas'].apply(lambda x: x in prompt)]\n",
    "    return real_source_list, filtered_df['id'].to_list()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fb96b6-db3c-4034-b001-26ed30fb735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wed Jun 19 09:35:12 2024 INFO Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Wed Jun 19 09:35:14 2024 INFO Use pytorch device_name: cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_match' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43247/2729889946.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdb_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"new_DB_cosine_cSize_%d_cOver_%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtitle_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_id_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbest_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtitle_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_id_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectordb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal_id_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'documents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_match' is not defined"
     ]
    }
   ],
   "source": [
    "prompt = 'Summarize the human transcription factors paper'\n",
    "path = \"/nfs/turbo/umms-indikar/shared/projects/RAG/papers/EXP2/\"\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name='BAAI/bge-base-en-v1.5')\n",
    "db_name = \"new_DB_cosine_cSize_%d_cOver_%d\" % (700, 200)\n",
    "title_list, real_id_list = get_all_sources(prompt, path)\n",
    "best_title, best_score = best_match(prompt, title_list)\n",
    "title_list, real_id_list = get_all_sources(best_title, path)\n",
    "text = vectordb.get(ids=real_id_list)['documents']\n",
    "print(len(text))\n",
    "#newdb = Chroma(persist_directory='/nfs/turbo/umms-indikar/shared/projects/RAG/databases/new_EXP3/', embedding_function=embeddings_model, collection_name=db_name)\n",
    "#print(len(newdb.get()['documents']))\n",
    "#newdb.add_texts(text)\n",
    "#print(len(newdb.get()['documents']))\n",
    "\n",
    "#things to do - hook this up with RAG (shouldnt be too bad)\n",
    "#determine how to sift thru the prompt or go thru paper titles that are not well done\n",
    "#ask about which paper db to use on turbo\n",
    "#where to save this new db\n",
    "#sometimes there is a weird error that occurs - maybe split up lower text stuff but idk how that effects runtime\n",
    "#how to remove docs from database / make new one everytime since it keeps adding to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cada8-4087-4e9b-b522-c30b7695e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "#Given the prompt, find the title and corresponding score that is the best match\n",
    "def best_match(prompt, title_list):\n",
    "    sentence_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "    unique_title_list = list(set(title_list))\n",
    "    query_embedding = sentence_model.encode(prompt)\n",
    "    passage_embedding = sentence_model.encode(unique_title_list)\n",
    "\n",
    "    save_title = \"\"\n",
    "    save_score = 0\n",
    "\n",
    "    for score, title in zip(util.cos_sim(query_embedding, passage_embedding)[0], unique_title_list):\n",
    "        if score > save_score:\n",
    "            save_score = score\n",
    "            save_title = title\n",
    "    print(f\"The best match is {save_title} with a score of {save_score}\")\n",
    "    return save_title, save_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d32cc-16b0-4dce-a271-f3d0d7e9974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27458348-b815-4917-9d68-383f37dfabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "unique_title_list = list(set(title_list))\n",
    "query_embedding = sentence_model.encode(prompt)\n",
    "passage_embedding = sentence_model.encode(unique_title_list)\n",
    "\n",
    "save_title = \"\"\n",
    "save_score = 0\n",
    "\n",
    "for score, title in zip(util.cos_sim(query_embedding, passage_embedding)[0], unique_title_list):\n",
    "    if score > save_score:\n",
    "        save_score = score\n",
    "        save_title = title\n",
    "print(f\"The best match is {save_title} with a score of {save_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935dbf8-b82c-4b89-95c6-70ff9a5e6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list, real_id_list = get_all_sources(save_title, \"/nfs/turbo/umms-indikar/shared/projects/RAG/papers/EXP2/\")\n",
    "text = vectordb.get(ids=real_id_list)['documents']\n",
    "#print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664ad69-7ab1-41e0-bbd4-149b0721dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def restrictedDB(prompt, vectordb, path):\n",
    "    #path = \"/nfs/turbo/umms-indikar/shared/projects/RAG/papers/EXP2/\"\n",
    "    embeddings_model = HuggingFaceEmbeddings(model_name='BAAI/bge-base-en-v1.5')\n",
    "    db_name = \"new_DB_cosine_cSize_%d_cOver_%d\" % (700, 200)\n",
    "    title_list, real_id_list = get_all_sources(prompt, path)\n",
    "    best_title, best_score = best_match(prompt, title_list)\n",
    "    title_list, real_id_list = get_all_sources(best_title, path)\n",
    "    text = vectordb.get(ids=real_id_list)['documents']\n",
    "    newdb = Chroma(persist_directory='/nfs/turbo/umms-indikar/shared/projects/RAG/databases/new_EXP3/', embedding_function=embeddings_model, collection_name=db_name)\n",
    "    newdb.add_texts(text)\n",
    "    return best_score, newdb\n",
    "\n",
    "\n",
    "#Given the prompt, find the title and corresponding score that is the best match\n",
    "def best_match(prompt, title_list):\n",
    "    sentence_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "    unique_title_list = list(set(title_list))\n",
    "    query_embedding = sentence_model.encode(prompt)\n",
    "    passage_embedding = sentence_model.encode(unique_title_list)\n",
    "\n",
    "    save_title = \"\"\n",
    "    #adjust the save_score to be the threshold cutoff - set to 0.75 but maybe thats too high\n",
    "    save_score = 0.75\n",
    "\n",
    "    for score, title in zip(util.cos_sim(query_embedding, passage_embedding)[0], unique_title_list):\n",
    "        if score > save_score:\n",
    "            save_score = score\n",
    "            save_title = title\n",
    "    print(f\"The best match is {save_title} with a score of {save_score}\")\n",
    "    return save_title, save_score\n",
    "\n",
    "#Split into two methods?\n",
    "def get_all_sources(prompt, path):\n",
    "    prompt = prompt.lower()\n",
    "    metadata_full = vectordb.get()['metadatas']\n",
    "    source_list = [item['source'] for item in metadata_full]   \n",
    "    real_source_list = [((item.replace(path, '')).removesuffix('.pdf')).lower() for item in source_list]\n",
    "    db = pd.DataFrame({'id' :vectordb.get()['ids'] , 'metadatas' : real_source_list})\n",
    "    filtered_df = db[db['metadatas'].apply(lambda x: x in prompt)]\n",
    "    return real_source_list, filtered_df['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5a074-377a-41fd-b22e-ff0846a4e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Summarize the human transcription factors paper'\n",
    "path = \"/nfs/turbo/umms-indikar/shared/projects/RAG/papers/EXP2/\"\n",
    "#path = '/nfs/turbo/umms-indikar/shared/projects/RAG/databases/EXP2/'\n",
    "vectordb, embeddings_model = brad.load_literature_db(persist_directory='/nfs/turbo/umms-indikar/shared/projects/RAG/databases/EXP2/')\n",
    "best_score, text = restrictedDB(prompt, vectordb, path)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bad5e-82f6-42ed-963f-42903cec1a1c",
   "metadata": {},
   "source": [
    "## PageRanker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59771ae9-3b83-4e8b-8465-e7a8fe157415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeats(vectordb):\n",
    "    df = pd.DataFrame({'id' :vectordb.get()['ids'] , 'documents' : vectordb.get()['documents']})\n",
    "    repeated_ids = df[df.duplicated(subset='documents', keep='last')]['id'].tolist()\n",
    "    vectordb.delete(repeated_ids)\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598f70f-3fe9-410c-8fb5-25093d074c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_repeats(vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea9a41-a9bd-427b-b27b-05b2afccb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectordb.get()['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a560acc-7478-46e1-8ce6-92243d1bc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the prompt, find the title and corresponding score that is the best match\n",
    "def adj_matrix_builder(vectordb):\n",
    "    dimension = len(vectordb.get()['documents'])\n",
    "    adj_matrix = np.zeros([dimension, dimension])\n",
    "    \n",
    "    sentence_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "    passage_embedding = sentence_model.encode(vectordb.get()['documents'])\n",
    "    cosine_similarities = cosine_similarity(passage_embedding[0:10])\n",
    "    print(cosine_similarities)\n",
    "    return cosine_similarities\n",
    "\n",
    "# Normalize columns of A\n",
    "def normalize_adjacency_matrix(A):\n",
    "    col_sums = A.sum(axis=0)\n",
    "    return A / col_sums[np.newaxis, :]\n",
    "\n",
    "#weighted pagerank algorithm\n",
    "def pagerank_weighted(A, alpha=0.85, tol=1e-6, max_iter=100):\n",
    "    n = A.shape[0]\n",
    "    A_normalized = normalize_adjacency_matrix(A)\n",
    "    v = np.ones(n) / n  # Initial PageRank vector\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        v_next = alpha * A_normalized.dot(v) + (1 - alpha) / n\n",
    "        if np.linalg.norm(v_next - v, 1) < tol:\n",
    "            break\n",
    "        v = v_next\n",
    "\n",
    "    return v\n",
    "\n",
    "#reranker\n",
    "\n",
    "def pagerank_rerank(vectordb):\n",
    "    adj_matrix = adj_matrix_builder(vectordb)\n",
    "    pagerank_scores = pagerank_weighted(A = adj_matrix)\n",
    "    top_rank_scores = sorted(range(len(pagerank_scores)), key=lambda i: pagerank_scores[i], reverse=True)[1:11]\n",
    "    df = pd.DataFrame({'id' :vectordb.get()['ids'] , 'documents' : vectordb.get()['documents'], 'metadatas' : vectordb.get()['metadatas']})\n",
    "    reranked_df = df.iloc[top_rank_scores]\n",
    "    return reranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5fa7a4-44de-4e92-b211-9f39d1acd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank_scores = pagerank_rerank(vectordb)\n",
    "#print(rank_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ff3be-56f7-4a25-8862-c0c9993e5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first entry is always the prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08771f10-5301-4695-a331-086ba5a30623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the prompt, find the title and corresponding score that is the best match\n",
    "def adj_matrix_builder(vectordb):\n",
    "    dimension = len(vectordb.get()['documents'])\n",
    "    adj_matrix = np.zeros([dimension, dimension])\n",
    "    \n",
    "    sentence_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "    passage_embedding = sentence_model.encode(vectordb.get()['documents'])\n",
    "    print(type(passage_embedding))\n",
    "    print(passage_embedding)\n",
    "    pos = 1\n",
    "    for score in zip(util.cos_sim(query_embedding, passage_embedding)[0]):\n",
    "        adj_matrix[0][pos] = score[0]\n",
    "        adj_matrix[pos][0] = score[0]\n",
    "        pos += 1\n",
    "    return adj_matrix\n",
    "\n",
    "# Normalize columns of A\n",
    "def normalize_adjacency_matrix(A):\n",
    "    col_sums = A.sum(axis=0)\n",
    "    return A / col_sums[np.newaxis, :]\n",
    "\n",
    "#weighted pagerank algorithm\n",
    "def pagerank_weighted(A, alpha=0.85, tol=1e-6, max_iter=100):\n",
    "    n = A.shape[0]\n",
    "    A_normalized = normalize_adjacency_matrix(A)\n",
    "    v = np.ones(n) / n  # Initial PageRank vector\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        v_next = alpha * A_normalized.dot(v) + (1 - alpha) / n\n",
    "        if np.linalg.norm(v_next - v, 1) < tol:\n",
    "            break\n",
    "        v = v_next\n",
    "\n",
    "    return v\n",
    "\n",
    "#reranker\n",
    "\n",
    "def pagerank_rerank(prompt, vectordb):\n",
    "    adj_matrix = adj_matrix_builder(prompt, vectordb)\n",
    "    pagerank_scores = pagerank_weighted(A = adj_matrix)\n",
    "    top_rank_scores = sorted(range(len(pagerank_scores)), key=lambda i: pagerank_scores[i], reverse=True)[1:11]\n",
    "    df = pd.DataFrame({'id' :vectordb.get()['ids'] , 'documents' : vectordb.get()['documents'], 'metadatas' : vectordb.get()['metadatas']})\n",
    "    reranked_df = df.iloc[top_rank_scores]\n",
    "    return reranked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a2b227-4d2c-407b-b442-06a2296909a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I THINK THIS FRAMEWORK WORKS BETTER\n",
    "\n",
    "\n",
    "#Given the prompt, find the title and corresponding score that is the best match\n",
    "def adj_matrix_builder(docs, scores):\n",
    "    dimension = len(docs)\n",
    "    adj_matrix = np.zeros([dimension, dimension])\n",
    "    pos = 1\n",
    "    for score in scores:\n",
    "        adj_matrix[0][pos] = score\n",
    "        adj_matrix[pos][0] = score\n",
    "        pos += 1\n",
    "    return adj_matrix\n",
    "\n",
    "# Normalize columns of A\n",
    "def normalize_adjacency_matrix(A):\n",
    "    col_sums = A.sum(axis=0)\n",
    "    return A / col_sums[np.newaxis, :]\n",
    "\n",
    "#weighted pagerank algorithm\n",
    "def pagerank_weighted(A, alpha=0.85, tol=1e-6, max_iter=100):\n",
    "    n = A.shape[0]\n",
    "    A_normalized = normalize_adjacency_matrix(A)\n",
    "    v = np.ones(n) / n  # Initial PageRank vector\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        v_next = alpha * A_normalized.dot(v) + (1 - alpha) / n\n",
    "        if np.linalg.norm(v_next - v, 1) < tol:\n",
    "            break\n",
    "        v = v_next\n",
    "\n",
    "    return v\n",
    "\n",
    "#reranker\n",
    "\n",
    "def pagerank_rerank(docs, scores):\n",
    "    adj_matrix = adj_matrix_builder(docs, scores)\n",
    "    pagerank_scores = pagerank_weighted(A = adj_matrix)\n",
    "    top_rank_scores = sorted(range(len(pagerank_scores)), key=lambda i: pagerank_scores[i], reverse=True)[1:11]\n",
    "    reranked_docs = [docs[i] for i in top_rank_scores]\n",
    "    return reranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb2d09-8418-4de0-9a5f-156da3521770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2458e3d-57c2-4889-9aa1-a031b51ea279",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/nfs/turbo/umms-indikar/shared/projects/RAG/papers/EXP2/\"\n",
    "metadata_full = vectordb.get()['metadatas']\n",
    "source_list = [item['source'] for item in metadata_full]   \n",
    "real_source_list = [((item.replace(path, '')).removesuffix('.pdf')).lower() for item in source_list]\n",
    "df = pd.DataFrame({'id' :vectordb.get()['ids'] , 'documents' : vectordb.get()['documents'], 'metadatas' : real_source_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331132ee-2e45-4b72-b4a4-9e3a6f366d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "brad.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d82c6636-4b4b-4c04-80d0-cc3ea5911036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Cosine Similarities:\n",
      "[[1.         0.97463185 0.95941195]\n",
      " [0.97463185 1.         0.99819089]\n",
      " [0.95941195 0.99819089 1.        ]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d80e54-c93c-4b6e-b094-f4c7995cb437",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'brad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95950/2128865677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'brad' is not defined"
     ]
    }
   ],
   "source": [
    "brad.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ccb38-002f-4c2e-afa5-88ec92a45e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
