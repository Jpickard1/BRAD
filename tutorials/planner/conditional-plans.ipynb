{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9e7bd4-f5cc-41e9-a0f8-158170b4322b",
   "metadata": {},
   "source": [
    "# Conditional Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d74bb5b4-f36f-47f7-a0d4-170b49c88a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jpic/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from BRAD import brad\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "import logging\n",
    "# Load the database\n",
    "persist_directory = '/nfs/turbo/umms-indikar/shared/projects/RAG/databases/DigitalLibrary-10-June-2024/'\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name='BAAI/bge-base-en-v1.5')\n",
    "db_name = \"DigitalLibrary\"\n",
    "_client_settings = chromadb.PersistentClient(path=(persist_directory + db_name))\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings_model, client=_client_settings, collection_name=db_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d63476a7-a6e5-4bae-8ac6-982e7e89f475",
   "metadata": {},
   "source": [
    "/force PLANNER write an analysis pipeline to write a detailed summary of the role of MYOD in the cellular reprogramming. First, I want you to use the RAG and tell me how confident you are in your answer. Then, if you are not confident, I want you to webscrape articles related to MYOD, and perform RAG analysis again based upon these new articles. Continue doing this until you are confident in your RAG answer, and then write a report on what you learned. This should have the following steps: 1. RAG, 2. ROUTER, 3. SCRAPE 4. RAG, 5. WRITE. If Step 1 is confident, the ROUTER should indicate to proceed directly to step 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ff32b44-b114-48d0-b83f-af3e59b34a41",
   "metadata": {},
   "source": [
    "/force PLANNER write an analysis pipeline to write a detailed summary of the role of Chewbacca in defending Hoth during episode 5 of Star Wars. First, I want you to use the RAG and tell me how confident you are in your answer. Then, if you are not confident, I want you to webscrape articles related to Chewy, and perform RAG analysis again based upon these new articles. Continue doing this until you are confident in your RAG answer, and then write a report on what you learned. This should have the following steps: 1. RAG, 2. ROUTER, 3. SCRAPE 4. RAG, 5. WRITE. If Step 1 is confident, the ROUTER should indicate to proceed directly to step 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5eb6bd1-9f3c-4ea1-af6d-92b51d1f309b",
   "metadata": {},
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4832d4-d7a8-4774-a512-1afa1ed1077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your NVIDIA API key:  ········\n"
     ]
    }
   ],
   "source": [
    "from BRAD import llms\n",
    "llm = llms.load_nvidia(nvidia_model='nvidia/nemotron-4-340b-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751eaa5b-0a16-4799-a41f-66b3632ebf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Would you like to use a database with BRAD [Y/N]?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-26 16:29:34 INFO semantic_router.utils.logger local\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to RAG! The chat log from this conversation will be saved to /home/jpic/BRAD/2024-06-26_16-29-32/log.json. How can I help?\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input >>  who are you and what can you do for me?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:RAG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "RAG >> 0: \n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mCurrent conversation: \n",
      "\n",
      "\n",
      "New Input: \n",
      "Context: You are BRAD (Bioinformatic Retrieval Augmented Data), a chatbot specializing in biology,\n",
      "bioinformatics, genetics, and data science. You can be connected to a text database to augment your answers\n",
      "based on the literature with Retrieval Augmented Generation, or you can use several additional modules including\n",
      "searching the web for new articles, searching Gene Ontology or Enrichr bioinformatics databases, running snakemake\n",
      "and matlab pipelines, or analyzing your own codes. Please answer the following questions to the best of your\n",
      "ability.\n",
      "\n",
      "Prompt: who are you and what can you do for me?\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "\n",
      "\n",
      "route\n",
      "\n",
      "\n",
      "\n",
      "INFO:root:RAG\n",
      "INFO:root:\n",
      "\n",
      "PLANNER:\n",
      "\n",
      "{'module': 'RAG', 'steps': []}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello, I'm BRAD (Bioinformatic Retrieval Augmented Data), a chatbot designed to assist you in the fields of biology, bioinformatics, genetics, and data science. I can provide you with accurate and up-to-date information by connecting to a text database and utilizing Retrieval Augmented Generation. This allows me to generate responses based on the latest literature.\n",
      "\n",
      "In addition to my text database, I have several modules that can enhance my capabilities:\n",
      "\n",
      "1. Web search: I can search the web for new articles and resources related to your queries.\n",
      "2. Gene Ontology and Enrichr databases: I can access and query these bioinformatics databases to provide you with functional annotations and enrichment analysis for genes and gene sets.\n",
      "3. Snakemake and MATLAB pipelines: I can run and manage bioinformatics and data analysis pipelines using Snakemake and MATLAB, allowing for efficient and reproducible workflows.\n",
      "4. Custom code analysis: I can analyze and execute your custom codes, providing insights and suggestions for improvement.\n",
      "\n",
      "My primary goal is to help you with your questions and tasks related to biology, bioinformatics, genetics, and data science. I'm committed to providing accurate, respectful, and useful responses while ensuring your data and privacy are secure.\n",
      "DEBUG\n",
      "\n",
      "\n",
      "\n",
      "route\n",
      "\n",
      "\n",
      "\n",
      "DEBUG\n",
      "RAG\n",
      "DEBUG\n",
      "\n",
      "\n",
      "PLANNER:\n",
      "\n",
      "{'module': 'RAG', 'steps': []}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "brad.chat(llm=llm) #ragvectordb = vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc4ab6-ffb4-4bc8-8cf8-9720503fed79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30e0a0-4899-43f5-9970-ce29e1d358d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b1530-e48c-4246-8c96-be2d6bad8967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846c42d-c2eb-41d7-b64e-fb935319ccc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf902eb7-793f-4b65-acea-1743877f6e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d15ba-9037-4c92-84c9-17c692b6eed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "352fbd5d-6820-4d8c-af72-8cf1949b3003",
   "metadata": {},
   "source": [
    "/force PLANNER write a 3 step pipeline to 1. perform a lit search of PCNA with the RAG. Use a prompt such as, \"What role does PCNA play in the cell cycle and cell cycle imaging?\", then 2. run the hwg analysis pipeline to find first order interactions of PCNA loaded from step 2. Next, (3.) Load the output file of the hwg codes (step 2) and perform gene enrichment and identify the pathways PCNA is involved in with enrichr. Finally, write a small report summarizing each of these findings in Step 4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80c79a49-4319-468a-9751-ce410385feb3",
   "metadata": {},
   "source": [
    "/force PLANNER perform an analysis pipeline to find the first order interactions of PCNA in the hardwird genome. if there are at least 100 interactions from step 1, then, I want you to do gene enrichment with ENRICHR and then use the RAG. If there are fewer than 100 first order interactions, only use the RAG."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
